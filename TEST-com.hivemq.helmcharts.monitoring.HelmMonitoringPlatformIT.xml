<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="com.hivemq.helmcharts.monitoring.HelmMonitoringPlatformIT" tests="1" skipped="0" failures="0" errors="0" timestamp="2025-01-29T22:14:46" hostname="fv-az1979-562" time="226.443">
  <properties/>
  <testcase name="withPlatformMonitoringEnabled_metricsAndDashboardAvailable()" classname="com.hivemq.helmcharts.monitoring.HelmMonitoringPlatformIT" time="226.443">
    <system-out><![CDATA[2025-01-29 22:14:46,347 INFO c.h.h.t.HelmChartContainer - Creating namespace 'helmmonitoringplatformit-operator'...
2025-01-29 22:14:46,558 INFO c.h.h.t.HelmChartContainer - Namespace 'helmmonitoringplatformit-operator' created
2025-01-29 22:14:46,558 INFO c.h.h.t.HelmChartContainer - Creating namespace 'helmmonitoringplatformit'...
2025-01-29 22:14:46,558 INFO c.h.h.t.HelmChartContainer - [POD] coredns-ff8999cc5-mwqvg [c12af24d-fa2b-4494-91ec-0ade252376b2] in kube-system was ADDED
2025-01-29 22:14:46,560 INFO c.h.h.t.HelmChartContainer - [POD] local-path-provisioner-698b58967b-hngww [cb4d26ec-3af5-46e5-a77d-6fb98e336743] in kube-system was ADDED
2025-01-29 22:14:46,563 INFO c.h.h.t.HelmChartContainer - [POD] metrics-server-8584b5786c-hxmzt [124be842-8139-455b-b757-31bd81010992] in kube-system was ADDED
2025-01-29 22:14:46,569 INFO c.h.h.t.HelmChartContainer - Namespace 'helmmonitoringplatformit' created
2025-01-29 22:14:46,639 DEBUG c.h.h.t.HelmChartContainer - Executing helm command: /bin/helm --kubeconfig /etc/rancher/k3s/k3s.yaml install test-hivemq-platform-operator /charts/hivemq-platform-operator --wait --timeout 5m0s --set image.repository=docker.io/hivemq --set image.name=hivemq-platform-operator-test --set image.initImageName=hivemq-platform-operator-init-test --set image.tag=snapshot --set image.pullPolicy=Never --set logLevel=DEBUG --set resources.cpu=512m --namespace helmmonitoringplatformit-operator
2025-01-29 22:14:49,035 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="helmmonitoringplatformit-operator/hivemq-platform-operator-test-hivemq-platform-operator" clusterIPs={"IPv4":"10.43.229.168"}
2025-01-29 22:14:49,050 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [ScalingReplicaSet] Scaled up replica set hivemq-test-hivemq-platform-operator-6966f96d65 from 0 to 1 [helmmonitoringplatformit-operator:hivemq-test-hivemq-platform-operator]
2025-01-29 22:14:49,058 INFO c.h.h.t.HelmChartContainer - [POD] hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0] in helmmonitoringplatformit-operator was ADDED
2025-01-29 22:14:49,068 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="22.591441ms"
2025-01-29 22:14:49,069 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [helmmonitoringplatformit-operator:hivemq-test-hivemq-platform-operator-6966f96d65]
2025-01-29 22:14:49,075 INFO c.h.h.t.HelmChartContainer - [POD] hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0] in helmmonitoringplatformit-operator was MODIFIED
2025-01-29 22:14:49,089 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65-4twfq to 0cdda8541101 [helmmonitoringplatformit-operator:hivemq-test-hivemq-platform-operator-6966f96d65-4twfq]
2025-01-29 22:14:49,091 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-t75p4\" (UniqueName: \"kubernetes.io/projected/a139d8e3-b51a-4b68-8772-4b488907f5e0-kube-api-access-t75p4\") pod \"hivemq-test-hivemq-platform-operator-6966f96d65-4twfq\" (UID: \"a139d8e3-b51a-4b68-8772-4b488907f5e0\") " pod="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65-4twfq"
2025-01-29 22:14:49,094 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="23.808599ms"
2025-01-29 22:14:49,095 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="47.81µs"
2025-01-29 22:14:49,098 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="57.498µs"
2025-01-29 22:14:49,104 INFO c.h.h.t.HelmChartContainer - [POD] hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0] in helmmonitoringplatformit-operator was MODIFIED
2025-01-29 22:14:49,462 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Container image "docker.io/hivemq/hivemq-platform-operator-test:snapshot" already present on machine [helmmonitoringplatformit-operator:hivemq-test-hivemq-platform-operator-6966f96d65-4twfq]
2025-01-29 22:14:49,463 INFO c.h.h.t.HelmChartContainer - Received Pulled event for container hivemq-platform-operator in pod hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0]
2025-01-29 22:14:49,471 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: hivemq-platform-operator [helmmonitoringplatformit-operator:hivemq-test-hivemq-platform-operator-6966f96d65-4twfq]
2025-01-29 22:14:49,471 INFO c.h.h.t.HelmChartContainer - Received Created event for container hivemq-platform-operator in pod hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0]
2025-01-29 22:14:50,234 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="43.031µs"
2025-01-29 22:14:50,241 INFO c.h.h.t.HelmChartContainer - [POD] hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0] in helmmonitoringplatformit-operator was MODIFIED
2025-01-29 22:14:50,257 INFO c.h.h.t.HelmChartContainer - Started log watcher for hivemq-platform-operator in pod hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0]
2025-01-29 22:14:50,257 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container hivemq-platform-operator [helmmonitoringplatformit-operator:hivemq-test-hivemq-platform-operator-6966f96d65-4twfq]
2025-01-29 22:14:50,257 INFO c.h.h.t.HelmChartContainer - Received Started event for container hivemq-platform-operator in pod hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0]
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] -------------------------------------------------------------------------
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3]                   _    _  _              __  __   ____
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3]                  | |  | |(_)            |  \/  | / __ \
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3]                  | |__| | _ __   __ ___ | \  / || |  | |
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3]                  |  __  || |\ \ / // _ \| |\/| || |  | |
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3]                  | |  | || | \ V /|  __/| |  | || |__| |
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3]                  |_|  |_||_|  \_/  \___||_|  |_| \___\_\
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] -------------------------------------------------------------------------
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3]   HiveMQ Platform Operator Start Script v1.0
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] -------------------------------------------------------------------------
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3]   JAVA_OPTS: -XX:+UnlockExperimentalVMOptions -XX:InitialRAMPercentage=75 -XX:MaxRAMPercentage=75 -Duser.language=en -Duser.region=US
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3]   JAVA_VERSION: 21
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] -------------------------------------------------------------------------
2025-01-29 22:14:50,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 
2025-01-29 22:14:52,866 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:52.821 [main] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider
2025-01-29 22:14:52,976 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:52.975 [main] DEBUG io.smallrye.config - SRCFG01006: Loaded ConfigSource SysPropConfigSource with ordinal 400
2025-01-29 22:14:52,977 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:52.975 [main] DEBUG io.smallrye.config - SRCFG01006: Loaded ConfigSource EnvConfigSource with ordinal 300
2025-01-29 22:14:52,977 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:52.975 [main] DEBUG io.smallrye.config - SRCFG01006: Loaded ConfigSource PropertiesConfigSource[source=jar:file:///opt/hivemq-platform-operator/bin/hivemq-platform-operator.jar!/hivemq-platform-operator.properties] with ordinal 100
2025-01-29 22:14:52,977 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:52.975 [main] DEBUG io.smallrye.config - SRCFG01006: Loaded ConfigSource DefaultValuesConfigSource with ordinal -2147483648
2025-01-29 22:14:53,081 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.080 [main] DEBUG i.m.c.u.i.l.InternalLoggerFactory - Using SLF4J as the default logging framework
2025-01-29 22:14:53,221 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.212 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - HiveMQ Platform Operator 1.7.0-SNAPSHOT (commit: 3bc9484 on branch: HEAD) built on Wed Jan 29 22:06:36 UTC 2025
2025-01-29 22:14:53,223 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.220 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - HiveMQ Platform Operator is running in namespace: helmmonitoringplatformit-operator
2025-01-29 22:14:53,223 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.220 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - Watching all namespaces
2025-01-29 22:14:53,223 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.220 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - Log level: DEBUG
2025-01-29 22:14:53,223 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.220 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - Release name: test-hivemq-platform-operator
2025-01-29 22:14:53,223 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.220 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - HiveMQ Platform Operator Init image: docker.io/hivemq/hivemq-platform-operator-init-test:snapshot
2025-01-29 22:14:53,223 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.220 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - HiveMQ Platform Operator Init App update URL: http://hivemq-platform-operator-test-hivemq-platform-operator.helmmonitoringplatformit-operator.svc:8080/initAppUpdate/hivemq-platform-operator-init-app-1.7.0-SNAPSHOT.jar
2025-01-29 22:14:53,264 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.220 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - Additional imagePullSecret for all Platform deployments: none
2025-01-29 22:14:53,264 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.261 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - Apply HiveMQ Platform CRD: true
2025-01-29 22:14:53,264 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.262 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - Create Platform ServiceAccount: true
2025-01-29 22:14:53,264 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.262 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - Create Platform ServiceAccount permissions: true
2025-01-29 22:14:53,265 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.262 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - Validate Platform ServiceAccount: true
2025-01-29 22:14:53,265 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.262 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - Validate Platform ServiceAccount permissions: true
2025-01-29 22:14:53,412 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:53.410 [main] INFO  c.h.platform.operator.util.CRDUtil - Verifying deployed HiveMQ Platform CRD...
2025-01-29 22:14:55,870 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:55.869 [main] DEBUG c.h.platform.operator.util.CRDUtil - HiveMQ Platform CRD version v1 is up to date
2025-01-29 22:14:55,871 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:55.869 [main] INFO  c.h.platform.operator.util.CRDUtil - HiveMQ Platform CRD is up to date (version: V1_6_0)
2025-01-29 22:14:55,871 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:55.870 [main] INFO  c.h.platform.operator.util.CRDUtil - Waiting 10000 ms for HiveMQ Platform CRD 'hivemq-platforms.hivemq.com' to become ready...
2025-01-29 22:14:56,212 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:56.211 [vert.x-eventloop-thread-1] DEBUG c.h.platform.operator.util.CRDUtil - Checking CRD condition 'NamesAccepted' (status: 'True')
2025-01-29 22:14:56,213 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:56.211 [vert.x-eventloop-thread-1] DEBUG c.h.platform.operator.util.CRDUtil - Checking CRD condition 'Established' (status: 'True')
2025-01-29 22:14:56,213 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:56.212 [main] INFO  c.h.platform.operator.util.CRDUtil - HiveMQ Platform CRD 'hivemq-platforms.hivemq.com' is ready
2025-01-29 22:14:56,326 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:56.324 [main] INFO  c.h.p.o.HiveMQPlatformReconciler - HiveMQ Platform Operator is starting...
2025-01-29 22:14:56,414 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:56.412 [main] WARN  Default ConfigurationService implementation - Configuration for reconciler 'hivemq-controller' was not found. Known reconcilers: None.
2025-01-29 22:14:56,420 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:56.420 [main] INFO  Default ConfigurationService implementation - Created configuration for reconciler com.hivemq.platform.operator.HiveMQPlatformReconciler with name hivemq-controller
2025-01-29 22:14:56,518 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:56.517 [main] DEBUG c.h.p.o.HiveMQPlatformReconciler - HiveMQ Platform Operator is preparing EventSources
2025-01-29 22:14:56,570 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:56.569 [main] INFO  i.javaoperatorsdk.operator.Operator - Registered reconciler: 'hivemq-controller' for resource: 'class com.hivemq.platform.operator.v1.HiveMQPlatform' for namespace(s): [all namespaces]
2025-01-29 22:14:57,171 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:57.170 [main] INFO  c.h.p.operator.webserver.JettyServer - Starting Jetty server on port 8080
2025-01-29 22:14:57,228 INFO c.h.h.t.HelmChartContainer - [POD] metrics-server-8584b5786c-hxmzt [124be842-8139-455b-b757-31bd81010992] in kube-system was MODIFIED
2025-01-29 22:14:57,231 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="5.441549ms"
2025-01-29 22:14:57,231 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="34.966µs"
2025-01-29 22:14:57,270 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:57.268 [main] INFO  i.javaoperatorsdk.operator.Operator - Operator SDK 4.9.7 (commit: 2133d28) built on Wed Nov 20 12:56:20 UTC 2024 starting...
2025-01-29 22:14:57,270 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:57.268 [main] INFO  i.javaoperatorsdk.operator.Operator - Client version: 6.13.5
2025-01-29 22:14:57,270 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:57.270 [Controller Starter for: hivemq-controller] INFO  i.j.operator.processing.Controller - Starting 'hivemq-controller' controller for reconciler: com.hivemq.platform.operator.HiveMQPlatformReconciler, resource: com.hivemq.platform.operator.v1.HiveMQPlatform
2025-01-29 22:14:59,527 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="0cdda8541101"
2025-01-29 22:14:59,713 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:59.711 [Controller Starter for: hivemq-controller] INFO  i.j.operator.processing.Controller - 'hivemq-controller' controller started
2025-01-29 22:14:59,714 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:14:59.712 [main] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - HiveMQ Platform Operator 1.7.0-SNAPSHOT started in 6499 ms
2025-01-29 22:15:01,242 INFO c.h.h.t.HelmChartContainer - [POD] hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0] in helmmonitoringplatformit-operator was MODIFIED
2025-01-29 22:15:01,253 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="11.760996ms"
2025-01-29 22:15:01,253 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="39.614µs"
2025-01-29 22:15:03,326 DEBUG c.h.h.t.HelmChartContainer - Executing helm command: /bin/helm --kubeconfig /etc/rancher/k3s/k3s.yaml repo add prometheus-community https://prometheus-community.github.io/helm-charts
2025-01-29 22:15:04,493 DEBUG c.h.h.t.HelmChartContainer - Executing helm command: /bin/helm --kubeconfig /etc/rancher/k3s/k3s.yaml install monitoring-stack prometheus-community/kube-prometheus-stack --wait --timeout 5m0s --set prometheus-node-exporter.hostRootFsMount.enabled=false -n monitoring --create-namespace
2025-01-29 22:15:12,043 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="0s"
2025-01-29 22:15:12,066 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="1s"
2025-01-29 22:15:12,068 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-create-8q6rc [63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36] in monitoring was ADDED
2025-01-29 22:15:12,074 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: monitoring-stack-kube-prom-admission-create-8q6rc [monitoring:monitoring-stack-kube-prom-admission-create]
2025-01-29 22:15:12,075 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-create-8q6rc [63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36] in monitoring was MODIFIED
2025-01-29 22:15:12,076 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="1s"
2025-01-29 22:15:12,076 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="1s"
2025-01-29 22:15:12,077 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned monitoring/monitoring-stack-kube-prom-admission-create-8q6rc to 0cdda8541101 [monitoring:monitoring-stack-kube-prom-admission-create-8q6rc]
2025-01-29 22:15:12,082 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="1s"
2025-01-29 22:15:12,084 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-create-8q6rc [63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36] in monitoring was MODIFIED
2025-01-29 22:15:12,169 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-w2wkb\" (UniqueName: \"kubernetes.io/projected/63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36-kube-api-access-w2wkb\") pod \"monitoring-stack-kube-prom-admission-create-8q6rc\" (UID: \"63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36\") " pod="monitoring/monitoring-stack-kube-prom-admission-create-8q6rc"
2025-01-29 22:15:12,469 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.1" [monitoring:monitoring-stack-kube-prom-admission-create-8q6rc]
2025-01-29 22:15:13,652 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.1" in 1.183s (1.183s including waiting). Image size: 27079554 bytes. [monitoring:monitoring-stack-kube-prom-admission-create-8q6rc]
2025-01-29 22:15:13,659 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: create [monitoring:monitoring-stack-kube-prom-admission-create-8q6rc]
2025-01-29 22:15:13,719 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container create [monitoring:monitoring-stack-kube-prom-admission-create-8q6rc]
2025-01-29 22:15:14,275 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="1s"
2025-01-29 22:15:14,279 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-create-8q6rc [63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36] in monitoring was MODIFIED
2025-01-29 22:15:15,337 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="1s"
2025-01-29 22:15:15,339 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-create-8q6rc [63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36] in monitoring was MODIFIED
2025-01-29 22:15:15,487 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-w2wkb\" (UniqueName: \"kubernetes.io/projected/63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36-kube-api-access-w2wkb\") pod \"63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36\" (UID: \"63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36\") "
2025-01-29 22:15:15,588 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-w2wkb\" (UniqueName: \"kubernetes.io/projected/63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36-kube-api-access-w2wkb\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:15:16,272 INFO c.h.h.t.HelmChartContainer - [K3S] [pod_container_deletor.go:80] "Container not found in pod's containers" containerID="d397b817a63c30c261eb34785988183e07dac47f5e5d155ce19e3073d7b26615"
2025-01-29 22:15:16,341 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="1s"
2025-01-29 22:15:16,345 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="1s"
2025-01-29 22:15:16,348 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-create-8q6rc [63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36] in monitoring was MODIFIED
2025-01-29 22:15:16,351 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Completed] Job completed [monitoring:monitoring-stack-kube-prom-admission-create]
2025-01-29 22:15:16,358 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-create" delay="0s"
2025-01-29 22:15:16,366 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-create-8q6rc [63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36] in monitoring was MODIFIED
2025-01-29 22:15:16,371 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-create-8q6rc [63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36] in monitoring was DELETED
2025-01-29 22:15:16,556 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="monitoring/monitoring-stack-kube-prom-prometheus" clusterIPs={"IPv4":"10.43.229.131"}
2025-01-29 22:15:16,594 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="monitoring/monitoring-stack-kube-state-metrics" clusterIPs={"IPv4":"10.43.184.17"}
2025-01-29 22:15:16,596 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="monitoring/monitoring-stack-kube-prom-operator" clusterIPs={"IPv4":"10.43.246.213"}
2025-01-29 22:15:16,596 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="monitoring/monitoring-stack-kube-prom-alertmanager" clusterIPs={"IPv4":"10.43.63.159"}
2025-01-29 22:15:16,597 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="monitoring/monitoring-stack-prometheus-node-exporter" clusterIPs={"IPv4":"10.43.19.138"}
2025-01-29 22:15:16,598 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="monitoring/monitoring-stack-grafana" clusterIPs={"IPv4":"10.43.181.60"}
2025-01-29 22:15:16,653 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [ScalingReplicaSet] Scaled up replica set monitoring-stack-kube-state-metrics-5bf5c7b54d from 0 to 1 [monitoring:monitoring-stack-kube-state-metrics]
2025-01-29 22:15:16,654 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-prometheus-node-exporter-stmml [4e490110-cf22-47c7-a300-a4e60efa881a] in monitoring was ADDED
2025-01-29 22:15:16,670 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-prometheus-node-exporter-stmml [4e490110-cf22-47c7-a300-a4e60efa881a] in monitoring was MODIFIED
2025-01-29 22:15:16,670 INFO c.h.h.t.HelmChartContainer - [K3S] [memory_manager.go:355] "RemoveStaleState removing state" podUID="63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36" containerName="create"
2025-01-29 22:15:16,680 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,681 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,692 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: monitoring-stack-prometheus-node-exporter-stmml [monitoring:monitoring-stack-prometheus-node-exporter]
2025-01-29 22:15:16,694 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,696 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,698 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,698 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,699 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [ScalingReplicaSet] Scaled up replica set monitoring-stack-kube-prom-operator-6998896c from 0 to 1 [monitoring:monitoring-stack-kube-prom-operator]
2025-01-29 22:15:16,700 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,700 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,700 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned monitoring/monitoring-stack-prometheus-node-exporter-stmml to 0cdda8541101 [monitoring:monitoring-stack-prometheus-node-exporter-stmml]
2025-01-29 22:15:16,701 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [monitoring:monitoring-stack-kube-state-metrics-5bf5c7b54d]
2025-01-29 22:15:16,706 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [d5c58d83-8550-4040-ad81-22086cd583ee] in monitoring was ADDED
2025-01-29 22:15:16,706 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,706 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,708 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-operator-6998896c-sswcs [5ceb77fa-7275-4c75-8edc-277b9ead7e63] in monitoring was ADDED
2025-01-29 22:15:16,713 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,713 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,713 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,714 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,715 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,715 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,718 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,718 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,718 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,718 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,719 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,719 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,719 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,719 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,719 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="72.288617ms"
2025-01-29 22:15:16,720 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-grafana-64c55fb967-jpjff [bbb8b81c-ba54-4027-96c0-517ac5e6b5b9] in monitoring was ADDED
2025-01-29 22:15:16,727 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,727 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,729 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"proc\" (UniqueName: \"kubernetes.io/host-path/4e490110-cf22-47c7-a300-a4e60efa881a-proc\") pod \"monitoring-stack-prometheus-node-exporter-stmml\" (UID: \"4e490110-cf22-47c7-a300-a4e60efa881a\") " pod="monitoring/monitoring-stack-prometheus-node-exporter-stmml"
2025-01-29 22:15:16,729 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"sys\" (UniqueName: \"kubernetes.io/host-path/4e490110-cf22-47c7-a300-a4e60efa881a-sys\") pod \"monitoring-stack-prometheus-node-exporter-stmml\" (UID: \"4e490110-cf22-47c7-a300-a4e60efa881a\") " pod="monitoring/monitoring-stack-prometheus-node-exporter-stmml"
2025-01-29 22:15:16,731 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,731 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,735 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="88.649386ms"
2025-01-29 22:15:16,737 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,737 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,737 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,738 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,743 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: monitoring-stack-grafana-64c55fb967-jpjff [monitoring:monitoring-stack-grafana-64c55fb967]
2025-01-29 22:15:16,746 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [ScalingReplicaSet] Scaled up replica set monitoring-stack-grafana-64c55fb967 from 0 to 1 [monitoring:monitoring-stack-grafana]
2025-01-29 22:15:16,749 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,750 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,750 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,750 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,750 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-grafana-64c55fb967-jpjff [bbb8b81c-ba54-4027-96c0-517ac5e6b5b9] in monitoring was MODIFIED
2025-01-29 22:15:16,751 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-operator-6998896c-sswcs [5ceb77fa-7275-4c75-8edc-277b9ead7e63] in monitoring was MODIFIED
2025-01-29 22:15:16,752 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [d5c58d83-8550-4040-ad81-22086cd583ee] in monitoring was MODIFIED
2025-01-29 22:15:16,758 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="108.889904ms"
2025-01-29 22:15:16,758 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,758 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,759 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,760 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,761 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,763 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,763 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,763 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,764 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,765 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,766 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,767 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,770 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,770 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,772 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,773 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,774 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,775 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,779 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,779 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,779 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,779 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,779 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,779 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,781 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,781 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,784 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,785 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,790 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,791 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,796 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,796 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,796 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:210] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s": no endpoints available for service "monitoring-stack-kube-prom-operator"
2025-01-29 22:15:16,796 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:214] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/mutate?timeout=10s\": no endpoints available for service \"monitoring-stack-kube-prom-operator\""
2025-01-29 22:15:16,803 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned monitoring/monitoring-stack-grafana-64c55fb967-jpjff to 0cdda8541101 [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:16,810 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="75.583304ms"
2025-01-29 22:15:16,812 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="55.624µs"
2025-01-29 22:15:16,812 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="85.696687ms"
2025-01-29 22:15:16,812 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="181.7µs"
2025-01-29 22:15:16,821 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-prometheus-node-exporter-stmml [4e490110-cf22-47c7-a300-a4e60efa881a] in monitoring was MODIFIED
2025-01-29 22:15:16,828 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: monitoring-stack-kube-prom-operator-6998896c-sswcs [monitoring:monitoring-stack-kube-prom-operator-6998896c]
2025-01-29 22:15:16,830 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="37.921µs"
2025-01-29 22:15:16,841 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv to 0cdda8541101 [monitoring:monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv]
2025-01-29 22:15:16,843 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned monitoring/monitoring-stack-kube-prom-operator-6998896c-sswcs to 0cdda8541101 [monitoring:monitoring-stack-kube-prom-operator-6998896c-sswcs]
2025-01-29 22:15:16,865 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="108.745941ms"
2025-01-29 22:15:16,866 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="61.926µs"
2025-01-29 22:15:16,895 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-grafana-64c55fb967-jpjff [bbb8b81c-ba54-4027-96c0-517ac5e6b5b9] in monitoring was MODIFIED
2025-01-29 22:15:16,899 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="76.854µs"
2025-01-29 22:15:16,920 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [d5c58d83-8550-4040-ad81-22086cd583ee] in monitoring was MODIFIED
2025-01-29 22:15:16,923 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="47.719µs"
2025-01-29 22:15:16,931 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="42.59µs"
2025-01-29 22:15:16,932 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"sc-dashboard-provider\" (UniqueName: \"kubernetes.io/configmap/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-sc-dashboard-provider\") pod \"monitoring-stack-grafana-64c55fb967-jpjff\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") " pod="monitoring/monitoring-stack-grafana-64c55fb967-jpjff"
2025-01-29 22:15:16,932 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"sc-datasources-volume\" (UniqueName: \"kubernetes.io/empty-dir/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-sc-datasources-volume\") pod \"monitoring-stack-grafana-64c55fb967-jpjff\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") " pod="monitoring/monitoring-stack-grafana-64c55fb967-jpjff"
2025-01-29 22:15:16,932 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-9s8d9\" (UniqueName: \"kubernetes.io/projected/5ceb77fa-7275-4c75-8edc-277b9ead7e63-kube-api-access-9s8d9\") pod \"monitoring-stack-kube-prom-operator-6998896c-sswcs\" (UID: \"5ceb77fa-7275-4c75-8edc-277b9ead7e63\") " pod="monitoring/monitoring-stack-kube-prom-operator-6998896c-sswcs"
2025-01-29 22:15:16,932 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config\" (UniqueName: \"kubernetes.io/configmap/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-config\") pod \"monitoring-stack-grafana-64c55fb967-jpjff\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") " pod="monitoring/monitoring-stack-grafana-64c55fb967-jpjff"
2025-01-29 22:15:16,933 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-operator-6998896c-sswcs [5ceb77fa-7275-4c75-8edc-277b9ead7e63] in monitoring was MODIFIED
2025-01-29 22:15:16,933 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-mrmtm\" (UniqueName: \"kubernetes.io/projected/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-kube-api-access-mrmtm\") pod \"monitoring-stack-grafana-64c55fb967-jpjff\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") " pod="monitoring/monitoring-stack-grafana-64c55fb967-jpjff"
2025-01-29 22:15:16,933 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"sc-dashboard-volume\" (UniqueName: \"kubernetes.io/empty-dir/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-sc-dashboard-volume\") pod \"monitoring-stack-grafana-64c55fb967-jpjff\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") " pod="monitoring/monitoring-stack-grafana-64c55fb967-jpjff"
2025-01-29 22:15:16,933 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tls-secret\" (UniqueName: \"kubernetes.io/secret/5ceb77fa-7275-4c75-8edc-277b9ead7e63-tls-secret\") pod \"monitoring-stack-kube-prom-operator-6998896c-sswcs\" (UID: \"5ceb77fa-7275-4c75-8edc-277b9ead7e63\") " pod="monitoring/monitoring-stack-kube-prom-operator-6998896c-sswcs"
2025-01-29 22:15:16,933 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"storage\" (UniqueName: \"kubernetes.io/empty-dir/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-storage\") pod \"monitoring-stack-grafana-64c55fb967-jpjff\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") " pod="monitoring/monitoring-stack-grafana-64c55fb967-jpjff"
2025-01-29 22:15:16,933 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-xbklg\" (UniqueName: \"kubernetes.io/projected/d5c58d83-8550-4040-ad81-22086cd583ee-kube-api-access-xbklg\") pod \"monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv\" (UID: \"d5c58d83-8550-4040-ad81-22086cd583ee\") " pod="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv"
2025-01-29 22:15:17,055 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "quay.io/prometheus/node-exporter:v1.8.2" [monitoring:monitoring-stack-prometheus-node-exporter-stmml]
2025-01-29 22:15:17,174 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "quay.io/kiwigrid/k8s-sidecar:1.28.0" [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:17,176 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36" path="/var/lib/kubelet/pods/63eaf7a9-2914-4caf-b7c9-d52e0bf3ee36/volumes"
2025-01-29 22:15:17,208 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.14.0" [monitoring:monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv]
2025-01-29 22:15:17,211 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "quay.io/prometheus-operator/prometheus-operator:v0.79.2" [monitoring:monitoring-stack-kube-prom-operator-6998896c-sswcs]
2025-01-29 22:15:18,061 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.14.0" in 853ms (853ms including waiting). Image size: 15427061 bytes. [monitoring:monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv]
2025-01-29 22:15:18,069 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: kube-state-metrics [monitoring:monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv]
2025-01-29 22:15:18,143 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container kube-state-metrics [monitoring:monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv]
2025-01-29 22:15:18,289 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="46.367µs"
2025-01-29 22:15:18,294 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [d5c58d83-8550-4040-ad81-22086cd583ee] in monitoring was MODIFIED
2025-01-29 22:15:18,653 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "quay.io/prometheus/node-exporter:v1.8.2" in 1.597s (1.597s including waiting). Image size: 12041464 bytes. [monitoring:monitoring-stack-prometheus-node-exporter-stmml]
2025-01-29 22:15:18,661 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: node-exporter [monitoring:monitoring-stack-prometheus-node-exporter-stmml]
2025-01-29 22:15:18,712 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container node-exporter [monitoring:monitoring-stack-prometheus-node-exporter-stmml]
2025-01-29 22:15:19,021 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "quay.io/prometheus-operator/prometheus-operator:v0.79.2" in 1.809s (1.809s including waiting). Image size: 19140913 bytes. [monitoring:monitoring-stack-kube-prom-operator-6998896c-sswcs]
2025-01-29 22:15:19,028 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: kube-prometheus-stack [monitoring:monitoring-stack-kube-prom-operator-6998896c-sswcs]
2025-01-29 22:15:19,092 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container kube-prometheus-stack [monitoring:monitoring-stack-kube-prom-operator-6998896c-sswcs]
2025-01-29 22:15:19,317 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-operator-6998896c-sswcs [5ceb77fa-7275-4c75-8edc-277b9ead7e63] in monitoring was MODIFIED
2025-01-29 22:15:19,328 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-operator-6998896c-sswcs [5ceb77fa-7275-4c75-8edc-277b9ead7e63] in monitoring was MODIFIED
2025-01-29 22:15:19,400 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-prometheus-node-exporter-stmml [4e490110-cf22-47c7-a300-a4e60efa881a] in monitoring was MODIFIED
2025-01-29 22:15:19,419 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="58.673244ms"
2025-01-29 22:15:19,424 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="54.231µs"
2025-01-29 22:15:19,564 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] create Pod alertmanager-monitoring-stack-kube-prom-alertmanager-0 in StatefulSet alertmanager-monitoring-stack-kube-prom-alertmanager successful [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager]
2025-01-29 22:15:19,570 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned monitoring/alertmanager-monitoring-stack-kube-prom-alertmanager-0 to 0cdda8541101 [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:19,575 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was ADDED
2025-01-29 22:15:19,578 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was MODIFIED
2025-01-29 22:15:19,607 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was MODIFIED
2025-01-29 22:15:19,716 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] create Pod prometheus-monitoring-stack-kube-prom-prometheus-0 in StatefulSet prometheus-monitoring-stack-kube-prom-prometheus successful [monitoring:prometheus-monitoring-stack-kube-prom-prometheus]
2025-01-29 22:15:19,727 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was ADDED
2025-01-29 22:15:19,741 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned monitoring/prometheus-monitoring-stack-kube-prom-prometheus-0 to 0cdda8541101 [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:19,752 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:15:19,763 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/788aac66-49cf-4129-be04-1178b7c2a3fd-tls-assets\") pod \"prometheus-monitoring-stack-kube-prom-prometheus-0\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") " pod="monitoring/prometheus-monitoring-stack-kube-prom-prometheus-0"
2025-01-29 22:15:19,763 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/788aac66-49cf-4129-be04-1178b7c2a3fd-web-config\") pod \"prometheus-monitoring-stack-kube-prom-prometheus-0\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") " pod="monitoring/prometheus-monitoring-stack-kube-prom-prometheus-0"
2025-01-29 22:15:19,764 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-web-config\") pod \"alertmanager-monitoring-stack-kube-prom-alertmanager-0\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") " pod="monitoring/alertmanager-monitoring-stack-kube-prom-alertmanager-0"
2025-01-29 22:15:19,764 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"alertmanager-monitoring-stack-kube-prom-alertmanager-db\" (UniqueName: \"kubernetes.io/empty-dir/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-alertmanager-monitoring-stack-kube-prom-alertmanager-db\") pod \"alertmanager-monitoring-stack-kube-prom-alertmanager-0\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") " pod="monitoring/alertmanager-monitoring-stack-kube-prom-alertmanager-0"
2025-01-29 22:15:19,765 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/788aac66-49cf-4129-be04-1178b7c2a3fd-config-out\") pod \"prometheus-monitoring-stack-kube-prom-prometheus-0\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") " pod="monitoring/prometheus-monitoring-stack-kube-prom-prometheus-0"
2025-01-29 22:15:19,765 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config\" (UniqueName: \"kubernetes.io/secret/788aac66-49cf-4129-be04-1178b7c2a3fd-config\") pod \"prometheus-monitoring-stack-kube-prom-prometheus-0\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") " pod="monitoring/prometheus-monitoring-stack-kube-prom-prometheus-0"
2025-01-29 22:15:19,765 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-tls-assets\") pod \"alertmanager-monitoring-stack-kube-prom-alertmanager-0\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") " pod="monitoring/alertmanager-monitoring-stack-kube-prom-alertmanager-0"
2025-01-29 22:15:19,765 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-lj86t\" (UniqueName: \"kubernetes.io/projected/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-kube-api-access-lj86t\") pod \"alertmanager-monitoring-stack-kube-prom-alertmanager-0\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") " pod="monitoring/alertmanager-monitoring-stack-kube-prom-alertmanager-0"
2025-01-29 22:15:19,765 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-lf8g5\" (UniqueName: \"kubernetes.io/projected/788aac66-49cf-4129-be04-1178b7c2a3fd-kube-api-access-lf8g5\") pod \"prometheus-monitoring-stack-kube-prom-prometheus-0\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") " pod="monitoring/prometheus-monitoring-stack-kube-prom-prometheus-0"
2025-01-29 22:15:19,765 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-config-out\") pod \"alertmanager-monitoring-stack-kube-prom-alertmanager-0\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") " pod="monitoring/alertmanager-monitoring-stack-kube-prom-alertmanager-0"
2025-01-29 22:15:19,765 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"prometheus-monitoring-stack-kube-prom-prometheus-rulefiles-0\" (UniqueName: \"kubernetes.io/configmap/788aac66-49cf-4129-be04-1178b7c2a3fd-prometheus-monitoring-stack-kube-prom-prometheus-rulefiles-0\") pod \"prometheus-monitoring-stack-kube-prom-prometheus-0\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") " pod="monitoring/prometheus-monitoring-stack-kube-prom-prometheus-0"
2025-01-29 22:15:19,765 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/secret/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-config-volume\") pod \"alertmanager-monitoring-stack-kube-prom-alertmanager-0\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") " pod="monitoring/alertmanager-monitoring-stack-kube-prom-alertmanager-0"
2025-01-29 22:15:19,765 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"prometheus-monitoring-stack-kube-prom-prometheus-db\" (UniqueName: \"kubernetes.io/empty-dir/788aac66-49cf-4129-be04-1178b7c2a3fd-prometheus-monitoring-stack-kube-prom-prometheus-db\") pod \"prometheus-monitoring-stack-kube-prom-prometheus-0\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") " pod="monitoring/prometheus-monitoring-stack-kube-prom-prometheus-0"
2025-01-29 22:15:19,787 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:15:20,193 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "quay.io/prometheus-operator/prometheus-config-reloader:v0.79.2" [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:20,337 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "quay.io/prometheus-operator/prometheus-config-reloader:v0.79.2" [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:20,932 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "quay.io/kiwigrid/k8s-sidecar:1.28.0" in 3.757s (3.757s including waiting). Image size: 23059632 bytes. [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:20,942 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: grafana-sc-dashboard [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:21,006 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container grafana-sc-dashboard [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:21,007 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Container image "quay.io/kiwigrid/k8s-sidecar:1.28.0" already present on machine [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:21,016 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: grafana-sc-datasources [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:21,088 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container grafana-sc-datasources [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:21,088 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "docker.io/grafana/grafana:11.4.0" [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:21,733 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "quay.io/prometheus-operator/prometheus-config-reloader:v0.79.2" in 1.395s (1.395s including waiting). Image size: 14945849 bytes. [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:21,737 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "quay.io/prometheus-operator/prometheus-config-reloader:v0.79.2" in 1.539s (1.539s including waiting). Image size: 14945849 bytes. [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:21,756 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: init-config-reloader [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:21,769 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: init-config-reloader [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:21,859 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container init-config-reloader [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:21,868 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container init-config-reloader [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:22,331 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:15:22,375 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was MODIFIED
2025-01-29 22:15:23,328 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "quay.io/prometheus/alertmanager:v0.28.0" [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:23,331 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulling] Pulling image "quay.io/prometheus/prometheus:v3.1.0" [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:23,358 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was MODIFIED
2025-01-29 22:15:23,380 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:15:25,412 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "quay.io/prometheus/alertmanager:v0.28.0" in 2.088s (2.088s including waiting). Image size: 35012199 bytes. [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:25,425 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: alertmanager [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:25,512 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container alertmanager [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:25,514 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Container image "quay.io/prometheus-operator/prometheus-config-reloader:v0.79.2" already present on machine [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:25,529 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: config-reloader [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:25,618 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container config-reloader [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:15:26,344 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was MODIFIED
2025-01-29 22:15:26,359 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "quay.io/prometheus/prometheus:v3.1.0" in 3.029s (3.029s including waiting). Image size: 116764168 bytes. [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:26,374 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: prometheus [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:26,478 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container prometheus [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:26,479 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Container image "quay.io/prometheus-operator/prometheus-config-reloader:v0.79.2" already present on machine [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:26,489 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: config-reloader [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:26,581 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container config-reloader [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:15:27,345 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:15:27,691 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "docker.io/grafana/grafana:11.4.0" in 6.607s (6.607s including waiting). Image size: 132825227 bytes. [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:27,701 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: grafana [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:27,764 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container grafana [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:28,349 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="52.848µs"
2025-01-29 22:15:28,350 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-grafana-64c55fb967-jpjff [bbb8b81c-ba54-4027-96c0-517ac5e6b5b9] in monitoring was MODIFIED
2025-01-29 22:15:29,141 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="1cac5fe00063b46c9c4badb329e591e0512ec2c1ebb96f3b80656d865035a805"
2025-01-29 22:15:29,305 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [d5c58d83-8550-4040-ad81-22086cd583ee] in monitoring was MODIFIED
2025-01-29 22:15:29,310 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="7.428916ms"
2025-01-29 22:15:29,310 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="46.246µs"
2025-01-29 22:15:29,337 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: Get "http://10.42.0.7:3000/api/health": dial tcp 10.42.0.7:3000: connect: connection refused [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:15:30,352 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-grafana-64c55fb967-jpjff [bbb8b81c-ba54-4027-96c0-517ac5e6b5b9] in monitoring was MODIFIED
2025-01-29 22:15:30,361 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="13.307652ms"
2025-01-29 22:15:30,361 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="73.167µs"
2025-01-29 22:15:30,406 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="0cdda8541101"
2025-01-29 22:15:31,964 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="0s"
2025-01-29 22:15:31,973 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:31,981 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-patch-tllpf [d94ad40e-ea8b-4b53-a76b-8689428ab6e0] in monitoring was ADDED
2025-01-29 22:15:31,983 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:31,983 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:31,986 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: monitoring-stack-kube-prom-admission-patch-tllpf [monitoring:monitoring-stack-kube-prom-admission-patch]
2025-01-29 22:15:31,987 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-patch-tllpf [d94ad40e-ea8b-4b53-a76b-8689428ab6e0] in monitoring was MODIFIED
2025-01-29 22:15:31,991 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned monitoring/monitoring-stack-kube-prom-admission-patch-tllpf to 0cdda8541101 [monitoring:monitoring-stack-kube-prom-admission-patch-tllpf]
2025-01-29 22:15:31,995 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:32,000 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-patch-tllpf [d94ad40e-ea8b-4b53-a76b-8689428ab6e0] in monitoring was MODIFIED
2025-01-29 22:15:32,048 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-qxz22\" (UniqueName: \"kubernetes.io/projected/d94ad40e-ea8b-4b53-a76b-8689428ab6e0-kube-api-access-qxz22\") pod \"monitoring-stack-kube-prom-admission-patch-tllpf\" (UID: \"d94ad40e-ea8b-4b53-a76b-8689428ab6e0\") " pod="monitoring/monitoring-stack-kube-prom-admission-patch-tllpf"
2025-01-29 22:15:32,355 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was MODIFIED
2025-01-29 22:15:32,405 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Container image "registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.1" already present on machine [monitoring:monitoring-stack-kube-prom-admission-patch-tllpf]
2025-01-29 22:15:32,413 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: patch [monitoring:monitoring-stack-kube-prom-admission-patch-tllpf]
2025-01-29 22:15:32,474 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container patch [monitoring:monitoring-stack-kube-prom-admission-patch-tllpf]
2025-01-29 22:15:33,351 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:33,353 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-patch-tllpf [d94ad40e-ea8b-4b53-a76b-8689428ab6e0] in monitoring was MODIFIED
2025-01-29 22:15:34,355 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:35,062 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:15:35,356 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-patch-tllpf [d94ad40e-ea8b-4b53-a76b-8689428ab6e0] in monitoring was MODIFIED
2025-01-29 22:15:35,357 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:35,374 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:15:36,361 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:36,434 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:36,435 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-patch-tllpf [d94ad40e-ea8b-4b53-a76b-8689428ab6e0] in monitoring was MODIFIED
2025-01-29 22:15:36,473 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-qxz22\" (UniqueName: \"kubernetes.io/projected/d94ad40e-ea8b-4b53-a76b-8689428ab6e0-kube-api-access-qxz22\") pod \"d94ad40e-ea8b-4b53-a76b-8689428ab6e0\" (UID: \"d94ad40e-ea8b-4b53-a76b-8689428ab6e0\") "
2025-01-29 22:15:36,574 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-qxz22\" (UniqueName: \"kubernetes.io/projected/d94ad40e-ea8b-4b53-a76b-8689428ab6e0-kube-api-access-qxz22\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:15:37,350 INFO c.h.h.t.HelmChartContainer - [K3S] [pod_container_deletor.go:80] "Container not found in pod's containers" containerID="63ffef48e3ec65dbbafe32d3b2d98eda822751fb547da34f86b23d8c269e92c7"
2025-01-29 22:15:37,366 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:37,379 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="1s"
2025-01-29 22:15:37,381 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-patch-tllpf [d94ad40e-ea8b-4b53-a76b-8689428ab6e0] in monitoring was MODIFIED
2025-01-29 22:15:37,387 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Completed] Job completed [monitoring:monitoring-stack-kube-prom-admission-patch]
2025-01-29 22:15:37,393 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:598] "enqueueing job" key="monitoring/monitoring-stack-kube-prom-admission-patch" delay="0s"
2025-01-29 22:15:37,400 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-patch-tllpf [d94ad40e-ea8b-4b53-a76b-8689428ab6e0] in monitoring was MODIFIED
2025-01-29 22:15:37,407 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-admission-patch-tllpf [d94ad40e-ea8b-4b53-a76b-8689428ab6e0] in monitoring was DELETED
2025-01-29 22:15:37,574 INFO com.hivemq.helmcharts.util.K8sUtil - Pod 'monitoring-stack-kube-prom-operator-6998896c-sswcs' is ready
2025-01-29 22:15:37,574 INFO com.hivemq.helmcharts.util.K8sUtil - Pod 'monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv' is ready
2025-01-29 22:15:37,574 INFO com.hivemq.helmcharts.util.K8sUtil - Pod 'monitoring-stack-prometheus-node-exporter-stmml' is ready
2025-01-29 22:15:37,574 INFO com.hivemq.helmcharts.util.K8sUtil - Pod 'monitoring-stack-grafana-64c55fb967-jpjff' is ready
2025-01-29 22:15:37,574 INFO com.hivemq.helmcharts.util.K8sUtil - Pod 'monitoring-stack-grafana-64c55fb967-jpjff' is ready
2025-01-29 22:15:37,574 INFO com.hivemq.helmcharts.util.K8sUtil - Pod 'monitoring-stack-grafana-64c55fb967-jpjff' is ready
2025-01-29 22:15:37,657 DEBUG c.h.h.t.HelmChartContainer - Executing helm command: /bin/helm --kubeconfig /etc/rancher/k3s/k3s.yaml install test-hivemq-platform /charts/hivemq-platform --wait --timeout 5m0s --set image.repository=docker.io/hivemq --set image.tag=4.36.0 --set image.pullPolicy=Never --set nodes.resources.cpu=512m -f /files/platform-monitoring-enabled-values.yaml --namespace helmmonitoringplatformit
2025-01-29 22:15:38,130 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.128 [-2082509879-pool-1-thread-2] WARN  i.m.p.PrometheusMeterRegistry - The meter (MeterId{name='operator.sdk.events.received', tags=[tag(action=ADDED),tag(event=ResourceEvent),tag(group=hivemq.com),tag(kind=HiveMQPlatform),tag(name=test-hivemq-platform),tag(namespace=helmmonitoringplatformit),tag(scope=namespace),tag(version=v1)]}) registration has failed: Prometheus requires that all meters with the same name have the same set of tag keys. There is already an existing meter named 'operator.sdk.events.received' containing tag keys [event, group, kind, name, namespace, scope, version]. The meter you are attempting to register has keys [action, event, group, kind, name, namespace, scope, version]. Note that subsequent logs will be logged at debug level.
2025-01-29 22:15:38,530 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.529 [pool-6-thread-3] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:15:38,531 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.530 [pool-6-thread-3] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:15:38,531 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.530 [pool-6-thread-3] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:15:38,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.532 [pool-6-thread-3] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Create PodInfo ConfigMap
2025-01-29 22:15:38,717 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.712 [pool-6-thread-5] DEBUG c.h.p.o.dependants.PodRoleResource - [helmmoni] Create Role: Role(apiVersion=rbac.authorization.k8s.io/v1, kind=Role, metadata=ObjectMeta(annotations={meta.helm.sh/release-name=test-hivemq-platform, meta.helm.sh/release-namespace=helmmonitoringplatformit}, creationTimestamp=null, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={helm.sh/chart=hivemq-platform-0.2.32, app.kubernetes.io/managed-by=Helm, app.kubernetes.io/name=hivemq-platform, hivemq-platform=test-hivemq-platform, app.kubernetes.io/instance=test-hivemq-platform, app.kubernetes.io/version=4.36.0}, managedFields=[], name=hivemq-platform-role-test-hivemq-platform, namespace=helmmonitoringplatformit, ownerReferences=[OwnerReference(apiVersion=hivemq.com/v1, blockOwnerDeletion=null, controller=null, kind=HiveMQPlatform, name=test-hivemq-platform, uid=9623397e-4f3a-40ad-82b2-624081320717, additionalProperties={})], resourceVersion=null, selfLink=null, uid=null, additionalProperties={}), rules=[PolicyRule(apiGroups=[], nonResourceURLs=[], resourceNames=[], resources=[pods], verbs=[get, patch, update], additionalProperties={})], additionalProperties={})
2025-01-29 22:15:38,816 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.813 [pool-6-thread-7] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:15:38,816 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.814 [pool-6-thread-7] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Create ServiceAccount 'hivemq-platform-pod-test-hivemq-platform'
2025-01-29 22:15:38,919 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.918 [pool-6-thread-10] DEBUG c.h.p.o.d.PodRoleBindingResource - [helmmoni] Create RoleBinding: RoleBinding(apiVersion=rbac.authorization.k8s.io/v1, kind=RoleBinding, metadata=ObjectMeta(annotations={meta.helm.sh/release-name=test-hivemq-platform, meta.helm.sh/release-namespace=helmmonitoringplatformit}, creationTimestamp=null, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, labels={helm.sh/chart=hivemq-platform-0.2.32, app.kubernetes.io/managed-by=Helm, app.kubernetes.io/name=hivemq-platform, hivemq-platform=test-hivemq-platform, app.kubernetes.io/instance=test-hivemq-platform, app.kubernetes.io/version=4.36.0}, managedFields=[], name=hivemq-platform-role-binding-test-hivemq-platform, namespace=helmmonitoringplatformit, ownerReferences=[OwnerReference(apiVersion=hivemq.com/v1, blockOwnerDeletion=null, controller=null, kind=HiveMQPlatform, name=test-hivemq-platform, uid=9623397e-4f3a-40ad-82b2-624081320717, additionalProperties={})], resourceVersion=null, selfLink=null, uid=null, additionalProperties={}), roleRef=RoleRef(apiGroup=rbac.authorization.k8s.io, kind=Role, name=hivemq-platform-role-test-hivemq-platform, additionalProperties={}), subjects=[Subject(apiGroup=null, kind=ServiceAccount, name=hivemq-platform-pod-test-hivemq-platform, namespace=helmmonitoringplatformit, additionalProperties={})], additionalProperties={})
2025-01-29 22:15:38,967 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.965 [ReconcilerExecutor-hivemq-controller-56] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:15:38,967 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.966 [ReconcilerExecutor-hivemq-controller-56] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status CREATED - HiveMQ Platform was created (READY)
2025-01-29 22:15:38,967 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:38.966 [ReconcilerExecutor-hivemq-controller-56] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:15:39,013 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:39.012 [ReconcilerExecutor-hivemq-controller-56] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting
2025-01-29 22:15:39,066 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:39.065 [ReconcilerExecutor-hivemq-controller-56] DEBUG c.h.p.operator.event.EventSender - [helmmoni] Creating K8s event hivemq-platform-starting: [Start] HiveMQ Platform is starting
2025-01-29 22:15:39,118 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Start] HiveMQ Platform is starting [helmmonitoringplatformit:test-hivemq-platform]
2025-01-29 22:15:39,122 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:39.120 [ReconcilerExecutor-hivemq-controller-56] INFO  c.h.p.o.h.AbstractHiveMQReconcilerStateHandler - [helmmoni] Update HiveMQ Platform Status (CREATED [READY] -> STARTING [READY]): HiveMQ Platform is starting
2025-01-29 22:15:39,168 DEBUG com.hivemq.helmcharts.util.K8sUtil - Comparing actual state 'STARTING' and waiting for 'RUNNING'
2025-01-29 22:15:39,175 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="d94ad40e-ea8b-4b53-a76b-8689428ab6e0" path="/var/lib/kubelet/pods/d94ad40e-ea8b-4b53-a76b-8689428ab6e0/volumes"
2025-01-29 22:15:49,224 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.219 [pool-6-thread-12] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:15:49,225 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.220 [pool-6-thread-13] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:15:49,225 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.220 [pool-6-thread-13] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:15:49,225 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.221 [pool-6-thread-13] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:15:49,228 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.227 [pool-6-thread-17] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:15:49,237 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.236 [pool-6-thread-13] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Update PodInfo ConfigMap
2025-01-29 22:15:49,325 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="helmmonitoringplatformit/hivemq-test-hivemq-platform-mqtt-1883" clusterIPs={"IPv4":"10.43.248.177"}
2025-01-29 22:15:49,419 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="helmmonitoringplatformit/hivemq-test-hivemq-platform-metrics-9399" clusterIPs={"IPv4":"10.43.92.240"}
2025-01-29 22:15:49,431 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="helmmonitoringplatformit/hivemq-test-hivemq-platform-cc-8080" clusterIPs={"IPv4":"10.43.98.222"}
2025-01-29 22:15:49,515 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.513 [pool-6-thread-20] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:15:49,529 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.528 [pool-6-thread-20] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Create StatefulSet
2025-01-29 22:15:49,629 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.628 [ReconcilerExecutor-hivemq-controller-67] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:15:49,629 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.628 [ReconcilerExecutor-hivemq-controller-67] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:15:49,630 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.629 [ReconcilerExecutor-hivemq-controller-67] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:15:49,637 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.633 [ReconcilerExecutor-hivemq-controller-67] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: null, replicas: 0, available: 0, ready: 0, current: 0, updated: 0)
2025-01-29 22:15:49,637 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.633 [ReconcilerExecutor-hivemq-controller-67] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:15:49,640 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] create Pod test-hivemq-platform-0 in StatefulSet test-hivemq-platform successful [helmmonitoringplatformit:test-hivemq-platform]
2025-01-29 22:15:49,641 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was ADDED
2025-01-29 22:15:49,644 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:15:49,645 INFO c.h.h.t.HelmChartContainer - [K3S] [memory_manager.go:355] "RemoveStaleState removing state" podUID="d94ad40e-ea8b-4b53-a76b-8689428ab6e0" containerName="patch"
2025-01-29 22:15:49,648 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned helmmonitoringplatformit/test-hivemq-platform-0 to 0cdda8541101 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:15:49,659 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:15:49,714 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.711 [ReconcilerExecutor-hivemq-controller-67] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:15:49,719 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.717 [pool-6-thread-22] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:15:49,722 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.721 [pool-6-thread-23] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:15:49,724 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.723 [pool-6-thread-23] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:15:49,725 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.723 [pool-6-thread-23] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:15:49,746 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"broker-configuration\" (UniqueName: \"kubernetes.io/configmap/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-broker-configuration\") pod \"test-hivemq-platform-0\" (UID: \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\") " pod="helmmonitoringplatformit/test-hivemq-platform-0"
2025-01-29 22:15:49,746 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pod-info\" (UniqueName: \"kubernetes.io/configmap/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-pod-info\") pod \"test-hivemq-platform-0\" (UID: \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\") " pod="helmmonitoringplatformit/test-hivemq-platform-0"
2025-01-29 22:15:49,746 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"operator-init\" (UniqueName: \"kubernetes.io/empty-dir/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-operator-init\") pod \"test-hivemq-platform-0\" (UID: \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\") " pod="helmmonitoringplatformit/test-hivemq-platform-0"
2025-01-29 22:15:49,746 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-gvp74\" (UniqueName: \"kubernetes.io/projected/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-kube-api-access-gvp74\") pod \"test-hivemq-platform-0\" (UID: \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\") " pod="helmmonitoringplatformit/test-hivemq-platform-0"
2025-01-29 22:15:49,813 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.723 [pool-6-thread-27] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:15:49,819 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.817 [pool-6-thread-30] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:15:49,912 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.911 [ReconcilerExecutor-hivemq-controller-78] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:15:49,912 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.911 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:15:49,912 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.911 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:15:49,916 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.915 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 1, available: 0, ready: 0, current: 1, updated: 1)
2025-01-29 22:15:49,918 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.915 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:15:49,928 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.927 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Pending
2025-01-29 22:15:49,929 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.928 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'PodReadyToStartContainers': False
2025-01-29 22:15:49,929 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.928 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'Initialized': False
2025-01-29 22:15:49,929 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.928 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'Ready': False
2025-01-29 22:15:49,930 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.928 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'ContainersReady': False
2025-01-29 22:15:49,930 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.928 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'PodScheduled': True
2025-01-29 22:15:49,930 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.929 [ReconcilerExecutor-hivemq-controller-78] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' containerStatus 'hivemq' (started: false) (ready: false) (waiting: [PodInitializing] null)
2025-01-29 22:15:49,931 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:49.930 [ReconcilerExecutor-hivemq-controller-78] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:15:50,015 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.013 [pool-6-thread-32] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:15:50,017 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.016 [pool-6-thread-33] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:15:50,018 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.016 [pool-6-thread-33] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:15:50,019 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.016 [pool-6-thread-33] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:15:50,019 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.017 [pool-6-thread-37] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:15:50,026 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.024 [pool-6-thread-40] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:15:50,029 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.028 [ReconcilerExecutor-hivemq-controller-89] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:15:50,030 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.028 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:15:50,032 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.028 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:15:50,043 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Container image "docker.io/hivemq/hivemq-platform-operator-init-test:snapshot" already present on machine [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:15:50,051 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: hivemq-platform-operator-init [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:15:50,102 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container hivemq-platform-operator-init [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:15:50,112 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.110 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 1, available: 0, ready: 0, current: 1, updated: 1)
2025-01-29 22:15:50,112 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.110 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:15:50,116 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.113 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Pending
2025-01-29 22:15:50,116 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.114 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'PodReadyToStartContainers': False
2025-01-29 22:15:50,117 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.114 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'Initialized': False
2025-01-29 22:15:50,117 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.114 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'Ready': False
2025-01-29 22:15:50,117 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.114 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'ContainersReady': False
2025-01-29 22:15:50,117 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.114 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'PodScheduled': True
2025-01-29 22:15:50,117 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.114 [ReconcilerExecutor-hivemq-controller-89] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' containerStatus 'hivemq' (started: false) (ready: false) (waiting: [PodInitializing] null)
2025-01-29 22:15:50,117 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.115 [ReconcilerExecutor-hivemq-controller-89] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:15:50,377 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Container image "docker.io/hivemq/hivemq4:4.36.0" already present on machine [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:15:50,377 INFO c.h.h.t.HelmChartContainer - Received Pulled event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:15:50,385 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:15:50,406 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: hivemq [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:15:50,407 INFO c.h.h.t.HelmChartContainer - Received Created event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:15:50,441 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.429 [pool-6-thread-42] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:15:50,441 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.432 [pool-6-thread-43] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:15:50,441 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.432 [pool-6-thread-43] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:15:50,441 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.432 [pool-6-thread-43] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:15:50,511 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.510 [pool-6-thread-47] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:15:50,519 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.518 [pool-6-thread-49] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:15:50,526 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.524 [ReconcilerExecutor-hivemq-controller-100] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:15:50,528 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.524 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:15:50,528 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.524 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:15:50,529 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.526 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 1, available: 0, ready: 0, current: 1, updated: 1)
2025-01-29 22:15:50,529 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.526 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:15:50,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.529 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Pending
2025-01-29 22:15:50,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.530 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'PodReadyToStartContainers': True
2025-01-29 22:15:50,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.530 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'Initialized': True
2025-01-29 22:15:50,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.530 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'Ready': False
2025-01-29 22:15:50,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.530 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'ContainersReady': False
2025-01-29 22:15:50,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.530 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' condition 'PodScheduled': True
2025-01-29 22:15:50,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.530 [ReconcilerExecutor-hivemq-controller-100] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' containerStatus 'hivemq' (started: false) (ready: false) (waiting: [PodInitializing] null)
2025-01-29 22:15:50,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:50.531 [ReconcilerExecutor-hivemq-controller-100] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:15:51,395 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:15:51,396 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.389 [pool-6-thread-8] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:15:51,396 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.391 [pool-6-thread-9] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:15:51,396 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.391 [pool-6-thread-9] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:15:51,396 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.391 [pool-6-thread-9] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:15:51,396 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.393 [pool-6-thread-6] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:15:51,410 INFO c.h.h.t.HelmChartContainer - Started log watcher for hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:15:51,410 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] Adding pre-installed HiveMQ Platform Operator extensions
2025-01-29 22:15:51,410 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container hivemq [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:15:51,410 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.405 [pool-6-thread-3] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:15:51,410 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] Running as user 10000
2025-01-29 22:15:51,411 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] Starting HiveMQ Platform Operator Init
2025-01-29 22:15:51,411 INFO c.h.h.t.HelmChartContainer - Received Started event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:15:51,471 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.464 [ReconcilerExecutor-hivemq-controller-111] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:15:51,471 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.465 [ReconcilerExecutor-hivemq-controller-111] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:15:51,471 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.465 [ReconcilerExecutor-hivemq-controller-111] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:15:51,471 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.469 [ReconcilerExecutor-hivemq-controller-111] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 1, available: 0, ready: 0, current: 1, updated: 1)
2025-01-29 22:15:51,471 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.469 [ReconcilerExecutor-hivemq-controller-111] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:15:51,475 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.474 [ReconcilerExecutor-hivemq-controller-111] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:15:51,477 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:15:51.476 [ReconcilerExecutor-hivemq-controller-111] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:15:51,671 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init 1.7.0-SNAPSHOT] HiveMQ Platform Operator Init 1.7.0-SNAPSHOT (commit: 3bc9484 on branch: HEAD) built on Wed Jan 29 22:06:36 UTC 2025
2025-01-29 22:15:52,794 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Using bind address 10.42.0.13 from environment variable
2025-01-29 22:15:53,769 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT (commit: 3bc9484 on branch: HEAD) built on Wed Jan 29 22:06:36 UTC 2025
2025-01-29 22:15:53,769 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] PodInfo ConfigMap directory: /etc/podinfo
2025-01-29 22:15:53,769 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ home directory: /opt/hivemq
2025-01-29 22:15:53,769 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ Logback folder: /opt/hivemq/conf
2025-01-29 22:15:53,769 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ Config folder: /opt/hivemq/conf-k8s
2025-01-29 22:15:53,769 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting HiveMQ Platform Operator Init App
2025-01-29 22:15:53,769 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting Pod reconciler
2025-01-29 22:15:55,065 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Pod reconciler is scheduled (interval: 5000 ms)
2025-01-29 22:15:55,065 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting the REST API on 10.42.0.13:7979
2025-01-29 22:15:55,068 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Waiting up to 600s for at most 2 HiveMQ nodes in cluster service hivemq-test-hivemq-platform-cluster.helmmonitoringplatformit.svc
2025-01-29 22:15:55,412 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Resolved 1 IP addresses: [10.42.0.13]
2025-01-29 22:15:55,412 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ node count of 1 is within threshold of 2
2025-01-29 22:15:55,412 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Proceeding with container start
2025-01-29 22:15:55,473 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Initializing HiveMQ Platform extensions with initial configuration: {hivemq-allow-all-extension={start-priority=-1, skip-https-hostname-verification=false, restart=true, config-version=0, header-version=0, c-uri=, priority=-1, uri=preinstalled, skip-https-certificate-validation=false, enabled=true}, hivemq-prometheus-extension={request-header-path=no-request-headers, uri=preinstalled, skip-https-certificate-validation=false, skip-https-hostname-verification=false, c-uri=, start-priority=-1, priority=-1, restart=true, enabled=true}}
2025-01-29 22:15:56,009 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Extension hivemq-allow-all-extension was already enabled
2025-01-29 22:15:56,060 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Successfully enabled extension hivemq-prometheus-extension
2025-01-29 22:15:56,061 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting HiveMQ Platform version 4.36.0 (4.36.0)
2025-01-29 22:15:56,061 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Configuring the HiveMQ Platform
2025-01-29 22:15:56,114 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Changed logback.xml file scan period to 20 seconds
2025-01-29 22:15:56,162 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting the HiveMQ Platform
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] -------------------------------------------------------------------------
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] 
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]                   _    _  _              __  __   ____
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]                  | |  | |(_)            |  \/  | / __ \
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]                  | |__| | _ __   __ ___ | \  / || |  | |
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]                  |  __  || |\ \ / // _ \| |\/| || |  | |
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]                  | |  | || | \ V /|  __/| |  | || |__| |
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]                  |_|  |_||_|  \_/  \___||_|  |_| \___\_\
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] 
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] -------------------------------------------------------------------------
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] 
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]   HiveMQ Start Script for Linux/Unix v1.14
2025-01-29 22:15:56,166 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] 
2025-01-29 22:15:56,270 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] -------------------------------------------------------------------------
2025-01-29 22:15:56,271 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] 
2025-01-29 22:15:56,271 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]   HIVEMQ_HOME: /opt/hivemq
2025-01-29 22:15:56,271 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] 
2025-01-29 22:15:56,271 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]   JAVA_OPTS: -XX:+UnlockExperimentalVMOptions -XX:InitialRAMPercentage=50 -XX:MaxRAMPercentage=50 -Djava.net.preferIPv4Stack=true --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/sun.nio.ch=ALL-UNNAMED --add-opens jdk.management/com.sun.management.internal=ALL-UNNAMED --add-exports java.base/jdk.internal.misc=ALL-UNNAMED -Djava.security.egd=file:/dev/./urandom -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9010 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Duser.language=en -Duser.region=US -XX:+CrashOnOutOfMemoryError -XX:+HeapDumpOnOutOfMemoryError
2025-01-29 22:15:56,271 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] 
2025-01-29 22:15:56,271 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e]   JAVA_VERSION: 21
2025-01-29 22:15:56,271 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] 
2025-01-29 22:15:56,271 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] -------------------------------------------------------------------------
2025-01-29 22:15:56,271 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] 
2025-01-29 22:15:57,464 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning default Health API response 503 for readiness
2025-01-29 22:15:57,770 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:15:57,770 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:15:58,918 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Starting HiveMQ Enterprise Server
2025-01-29 22:15:58,964 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - HiveMQ version: 4.36.0
2025-01-29 22:15:58,964 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - HiveMQ home directory: /opt/hivemq
2025-01-29 22:15:58,965 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Log Configuration was overridden by /opt/hivemq/conf/logback.xml
2025-01-29 22:16:00,411 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Successfully loaded configuration from '/opt/hivemq/conf-k8s/config.xml'.
2025-01-29 22:16:01,484 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.482 [pool-6-thread-11] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:01,486 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.483 [pool-6-thread-15] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:01,486 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.483 [pool-6-thread-16] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:01,486 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.484 [pool-6-thread-16] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:01,486 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.485 [pool-6-thread-16] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:01,491 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.490 [pool-6-thread-11] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:01,495 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.494 [ReconcilerExecutor-hivemq-controller-112] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:01,495 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.494 [ReconcilerExecutor-hivemq-controller-112] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:01,495 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.494 [ReconcilerExecutor-hivemq-controller-112] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:01,496 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.496 [ReconcilerExecutor-hivemq-controller-112] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 1, available: 0, ready: 0, current: 1, updated: 1)
2025-01-29 22:16:01,496 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.496 [ReconcilerExecutor-hivemq-controller-112] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:01,498 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.497 [ReconcilerExecutor-hivemq-controller-112] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:01,499 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:01.498 [ReconcilerExecutor-hivemq-controller-112] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:16:01,561 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - This node's ID is 0kK8f
2025-01-29 22:16:01,561 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Clustering is enabled
2025-01-29 22:16:02,664 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:16:02,676 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:16:02,676 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:16:05,410 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] Jan 29, 2025 10:16:05 PM io.vertx.core.impl.BlockedThreadChecker
2025-01-29 22:16:05,410 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARNING: Thread Thread[vert.x-eventloop-thread-1,5,main] has been blocked for 2595 ms, time limit is 2000 ms
2025-01-29 22:16:05,619 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Updating Pod HiveMQ Platform Operator Init App version annotation (version: 1.7.0-SNAPSHOT)
2025-01-29 22:16:06,424 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:16:06,427 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.426 [pool-6-thread-21] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:06,430 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.428 [pool-6-thread-27] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:06,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.427 [pool-6-thread-24] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:06,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.430 [pool-6-thread-24] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:06,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.430 [pool-6-thread-24] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:06,438 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.435 [pool-6-thread-21] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:06,441 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.440 [ReconcilerExecutor-hivemq-controller-113] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:06,441 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.440 [ReconcilerExecutor-hivemq-controller-113] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:06,442 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.440 [ReconcilerExecutor-hivemq-controller-113] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:06,464 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:16:06,469 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:16:06,469 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:16:06,513 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Successfully updated Pod HiveMQ Platform Operator Init App version annotation (version: 1.7.0-SNAPSHOT)
2025-01-29 22:16:06,515 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.511 [ReconcilerExecutor-hivemq-controller-113] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 1, available: 0, ready: 0, current: 1, updated: 1)
2025-01-29 22:16:06,515 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.511 [ReconcilerExecutor-hivemq-controller-113] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:06,515 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.513 [ReconcilerExecutor-hivemq-controller-113] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:06,515 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:06.513 [ReconcilerExecutor-hivemq-controller-113] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:16:11,462 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:16:11,466 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:16:11,466 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:16:16,462 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:16:16,466 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:16:16,466 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:16:16,521 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.517 [pool-6-thread-35] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:16,522 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.519 [pool-6-thread-37] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:16,522 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.519 [pool-6-thread-37] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:16,522 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.519 [pool-6-thread-37] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:16,524 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.521 [pool-6-thread-36] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:16,527 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.526 [pool-6-thread-35] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:16,531 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.530 [ReconcilerExecutor-hivemq-controller-114] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:16,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.530 [ReconcilerExecutor-hivemq-controller-114] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:16,533 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.530 [ReconcilerExecutor-hivemq-controller-114] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:16,536 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.532 [ReconcilerExecutor-hivemq-controller-114] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 1, available: 0, ready: 0, current: 1, updated: 1)
2025-01-29 22:16:16,536 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.532 [ReconcilerExecutor-hivemq-controller-114] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:16,536 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.533 [ReconcilerExecutor-hivemq-controller-114] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:16,536 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:16.534 [ReconcilerExecutor-hivemq-controller-114] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:16:19,859 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - No valid license file found. Using trial license, restricted to 25 connections.
2025-01-29 22:16:19,961 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for liveness: null
2025-01-29 22:16:19,961 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning default Health API response 200 for liveness
2025-01-29 22:16:21,463 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:16:21,467 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:16:21,467 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:16:23,610 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - No valid license file for Data Hub found. Using free license, restricted to 1 policy.
2025-01-29 22:16:24,761 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Audit Logger started.
2025-01-29 22:16:25,128 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - This node uses '1' CPU cores.
2025-01-29 22:16:25,159 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Starting HiveMQ Health API on address 0.0.0.0 and port 8889
2025-01-29 22:16:26,161 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Started HiveMQ Health API in 1001ms
2025-01-29 22:16:26,542 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.538 [pool-6-thread-45] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:26,543 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.540 [pool-6-thread-46] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:26,543 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.540 [pool-6-thread-46] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:26,543 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.540 [pool-6-thread-46] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:26,544 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.543 [pool-6-thread-47] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:26,549 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.548 [pool-6-thread-47] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:26,620 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.615 [ReconcilerExecutor-hivemq-controller-115] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:26,620 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.615 [ReconcilerExecutor-hivemq-controller-115] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:26,620 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.615 [ReconcilerExecutor-hivemq-controller-115] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:26,620 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.619 [ReconcilerExecutor-hivemq-controller-115] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 1, available: 0, ready: 0, current: 1, updated: 1)
2025-01-29 22:16:26,620 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.619 [ReconcilerExecutor-hivemq-controller-115] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:26,625 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.623 [ReconcilerExecutor-hivemq-controller-115] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:26,625 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:26.623 [ReconcilerExecutor-hivemq-controller-115] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:16:27,361 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning Health API response 503 for readiness
2025-01-29 22:16:27,365 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:16:27,365 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:16:27,612 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Starting HiveMQ extension system.
2025-01-29 22:16:28,016 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Starting extension with id "hivemq-dns-cluster-discovery" at /opt/hivemq/extensions/hivemq-dns-cluster-discovery
2025-01-29 22:16:28,563 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Using TCP cluster transport on address 10.42.0.13 and port 7000
2025-01-29 22:16:28,613 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Using extension cluster discovery
2025-01-29 22:16:28,618 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Extension "DNS Cluster Discovery Extension" version 4.3.2 started successfully.
2025-01-29 22:16:28,618 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Starting extension with id "hivemq-prometheus-extension" at /opt/hivemq/extensions/hivemq-prometheus-extension
2025-01-29 22:16:29,174 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="4ff3b4d67a1ea495eddf2f350814694a2858e750806f6ff52a08e6c2b3ffde66"
2025-01-29 22:16:29,762 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Started Jetty Server exposing Prometheus Servlet on URI http://0.0.0.0:9399/
2025-01-29 22:16:29,762 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Extension "Prometheus Monitoring Extension" version 4.0.12 started successfully.
2025-01-29 22:16:29,762 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Starting extension with id "hivemq-allow-all-extension" at /opt/hivemq/extensions/hivemq-allow-all-extension
2025-01-29 22:16:29,762 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - 
2025-01-29 22:16:29,762 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] ################################################################################################################
2025-01-29 22:16:29,762 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] # This HiveMQ deployment is not secure! You are lacking Authentication and Authorization.                      #
2025-01-29 22:16:29,763 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] # Right now any MQTT client can connect to the broker with a full set of permissions.                          #
2025-01-29 22:16:29,763 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] # For production usage, add an appropriate security extension and remove the hivemq-allow-all extension.       #
2025-01-29 22:16:29,763 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] # You can download security extensions from the HiveMQ Marketplace (https://www.hivemq.com/extensions/).       #
2025-01-29 22:16:29,763 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] ################################################################################################################
2025-01-29 22:16:29,763 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Extension "Allow All Extension" version 1.1.1 started successfully.
2025-01-29 22:16:31,430 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:16:31,430 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:16:31,560 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - 0kK8f: no members discovered after 2446 ms: creating cluster as first member
2025-01-29 22:16:31,566 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Cluster nodes found by discovery: [0kK8f|0] (1) [0kK8f].
2025-01-29 22:16:31,664 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - No user for HiveMQ Control Center configured. Starting with default user
2025-01-29 22:16:31,664 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Starting HiveMQ Control Center on address 0.0.0.0 and port 8080
2025-01-29 22:16:31,666 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Mounting HiveMQ Control Center V2 Preview
2025-01-29 22:16:32,370 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Started HiveMQ Control Center in 708ms
2025-01-29 22:16:32,467 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Starting TCP listener on address 0.0.0.0 and port 1883
2025-01-29 22:16:32,563 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Started TCP Listener on address 0.0.0.0 and on port 1883.
2025-01-29 22:16:32,564 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Started HiveMQ in 33994ms
2025-01-29 22:16:36,426 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning Health API response 200 for readiness
2025-01-29 22:16:36,438 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:16:36,446 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.439 [pool-6-thread-1] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:36,446 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.442 [pool-6-thread-4] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:36,446 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.440 [pool-6-thread-9] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:36,446 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.444 [pool-6-thread-9] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:36,446 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.444 [pool-6-thread-9] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:36,458 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.447 [pool-6-thread-1] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:36,458 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.450 [ReconcilerExecutor-hivemq-controller-116] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:36,458 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.450 [ReconcilerExecutor-hivemq-controller-116] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:36,458 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.450 [ReconcilerExecutor-hivemq-controller-116] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:36,458 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.451 [ReconcilerExecutor-hivemq-controller-116] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 1, available: 0, ready: 0, current: 1, updated: 1)
2025-01-29 22:16:36,458 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.451 [ReconcilerExecutor-hivemq-controller-116] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:36,458 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.452 [ReconcilerExecutor-hivemq-controller-116] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:36,458 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.453 [ReconcilerExecutor-hivemq-controller-116] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 0 of 2 replicas are ready
2025-01-29 22:16:36,470 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was ADDED
2025-01-29 22:16:36,472 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:16:36,476 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [SuccessfulCreate] create Pod test-hivemq-platform-1 in StatefulSet test-hivemq-platform successful [helmmonitoringplatformit:test-hivemq-platform]
2025-01-29 22:16:36,476 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned helmmonitoringplatformit/test-hivemq-platform-1 to 0cdda8541101 [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:36,493 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:16:36,516 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.514 [pool-6-thread-15] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:36,519 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.516 [pool-6-thread-14] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:36,520 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.519 [pool-6-thread-14] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:36,523 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.521 [pool-6-thread-14] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:36,524 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.518 [pool-6-thread-17] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:36,526 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.525 [pool-6-thread-14] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:36,531 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.530 [ReconcilerExecutor-hivemq-controller-117] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:36,563 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.530 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:36,563 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.561 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:36,612 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.611 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 1, ready: 1, current: 2, updated: 2)
2025-01-29 22:16:36,613 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.611 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:36,614 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.613 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Pending
2025-01-29 22:16:36,614 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.613 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'PodReadyToStartContainers': False
2025-01-29 22:16:36,614 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.613 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'Initialized': False
2025-01-29 22:16:36,614 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.613 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'Ready': False
2025-01-29 22:16:36,614 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.613 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'ContainersReady': False
2025-01-29 22:16:36,614 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.613 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'PodScheduled': True
2025-01-29 22:16:36,614 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.613 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' containerStatus 'hivemq' (started: false) (ready: false) (waiting: [PodInitializing] null)
2025-01-29 22:16:36,616 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.614 [ReconcilerExecutor-hivemq-controller-117] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:36,616 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.616 [ReconcilerExecutor-hivemq-controller-117] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 1 of 2 replicas are ready
2025-01-29 22:16:36,621 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.619 [pool-6-thread-23] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:36,621 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.619 [pool-6-thread-23] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:36,621 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.619 [pool-6-thread-23] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:36,621 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.619 [pool-6-thread-28] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:36,621 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.620 [pool-6-thread-29] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:36,626 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.625 [pool-6-thread-29] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:36,629 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.628 [ReconcilerExecutor-hivemq-controller-118] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:36,630 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.628 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:36,630 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.628 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:36,637 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"broker-configuration\" (UniqueName: \"kubernetes.io/configmap/c69a8da4-4968-4949-9947-7beef49c4373-broker-configuration\") pod \"test-hivemq-platform-1\" (UID: \"c69a8da4-4968-4949-9947-7beef49c4373\") " pod="helmmonitoringplatformit/test-hivemq-platform-1"
2025-01-29 22:16:36,637 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"operator-init\" (UniqueName: \"kubernetes.io/empty-dir/c69a8da4-4968-4949-9947-7beef49c4373-operator-init\") pod \"test-hivemq-platform-1\" (UID: \"c69a8da4-4968-4949-9947-7beef49c4373\") " pod="helmmonitoringplatformit/test-hivemq-platform-1"
2025-01-29 22:16:36,637 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-qk5h9\" (UniqueName: \"kubernetes.io/projected/c69a8da4-4968-4949-9947-7beef49c4373-kube-api-access-qk5h9\") pod \"test-hivemq-platform-1\" (UID: \"c69a8da4-4968-4949-9947-7beef49c4373\") " pod="helmmonitoringplatformit/test-hivemq-platform-1"
2025-01-29 22:16:36,637 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pod-info\" (UniqueName: \"kubernetes.io/configmap/c69a8da4-4968-4949-9947-7beef49c4373-pod-info\") pod \"test-hivemq-platform-1\" (UID: \"c69a8da4-4968-4949-9947-7beef49c4373\") " pod="helmmonitoringplatformit/test-hivemq-platform-1"
2025-01-29 22:16:36,712 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.710 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 1, ready: 1, current: 2, updated: 2)
2025-01-29 22:16:36,713 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.711 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:36,715 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.712 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Pending
2025-01-29 22:16:36,715 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.712 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'PodReadyToStartContainers': False
2025-01-29 22:16:36,715 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.712 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'Initialized': False
2025-01-29 22:16:36,715 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.713 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'Ready': False
2025-01-29 22:16:36,715 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.713 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'ContainersReady': False
2025-01-29 22:16:36,715 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.713 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'PodScheduled': True
2025-01-29 22:16:36,715 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.713 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' containerStatus 'hivemq' (started: false) (ready: false) (waiting: [PodInitializing] null)
2025-01-29 22:16:36,717 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.716 [ReconcilerExecutor-hivemq-controller-118] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:36,718 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:36.717 [ReconcilerExecutor-hivemq-controller-118] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 1 of 2 replicas are ready
2025-01-29 22:16:36,866 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Container image "docker.io/hivemq/hivemq-platform-operator-init-test:snapshot" already present on machine [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:36,874 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: hivemq-platform-operator-init [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:36,925 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container hivemq-platform-operator-init [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:37,464 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Pulled] Container image "docker.io/hivemq/hivemq4:4.36.0" already present on machine [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:37,464 INFO c.h.h.t.HelmChartContainer - Received Pulled event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:16:37,471 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:16:37,490 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.479 [pool-6-thread-36] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:37,492 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.481 [pool-6-thread-39] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:37,490 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Created] Created container: hivemq [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:37,494 INFO c.h.h.t.HelmChartContainer - Received Created event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:16:37,495 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.481 [pool-6-thread-39] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:37,495 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.481 [pool-6-thread-39] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:37,495 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.482 [pool-6-thread-33] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:37,501 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.496 [pool-6-thread-36] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:37,505 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.499 [ReconcilerExecutor-hivemq-controller-119] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:37,505 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.500 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:37,505 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.500 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:37,508 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.505 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 1, ready: 1, current: 2, updated: 2)
2025-01-29 22:16:37,509 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.505 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:37,573 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.567 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Pending
2025-01-29 22:16:37,573 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.567 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'PodReadyToStartContainers': True
2025-01-29 22:16:37,573 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.567 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'Initialized': True
2025-01-29 22:16:37,573 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.567 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'Ready': False
2025-01-29 22:16:37,573 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.567 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'ContainersReady': False
2025-01-29 22:16:37,573 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.567 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' condition 'PodScheduled': True
2025-01-29 22:16:37,573 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.567 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' containerStatus 'hivemq' (started: false) (ready: false) (waiting: [PodInitializing] null)
2025-01-29 22:16:37,573 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.568 [ReconcilerExecutor-hivemq-controller-119] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:37,573 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:37.569 [ReconcilerExecutor-hivemq-controller-119] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 1 of 2 replicas are ready
2025-01-29 22:16:38,472 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:16:38,481 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.479 [pool-6-thread-48] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:38,483 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.480 [pool-6-thread-42] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:38,484 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.482 [pool-6-thread-42] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:38,484 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.482 [pool-6-thread-42] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:38,484 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Started] Started container hivemq [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:38,484 INFO c.h.h.t.HelmChartContainer - Started log watcher for hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:16:38,484 INFO c.h.h.t.HelmChartContainer - Received Started event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:16:38,485 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] Adding pre-installed HiveMQ Platform Operator extensions
2025-01-29 22:16:38,485 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] Running as user 10000
2025-01-29 22:16:38,485 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] Starting HiveMQ Platform Operator Init
2025-01-29 22:16:38,488 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.485 [pool-6-thread-44] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:38,491 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.491 [pool-6-thread-43] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:38,496 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.495 [ReconcilerExecutor-hivemq-controller-120] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:38,496 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.495 [ReconcilerExecutor-hivemq-controller-120] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:38,496 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.495 [ReconcilerExecutor-hivemq-controller-120] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:38,501 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.496 [ReconcilerExecutor-hivemq-controller-120] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 1, ready: 1, current: 2, updated: 2)
2025-01-29 22:16:38,501 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.497 [ReconcilerExecutor-hivemq-controller-120] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:38,501 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.498 [ReconcilerExecutor-hivemq-controller-120] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:16:38,501 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.499 [ReconcilerExecutor-hivemq-controller-120] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:38,501 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:38.500 [ReconcilerExecutor-hivemq-controller-120] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 1 of 2 replicas are ready
2025-01-29 22:16:38,851 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init 1.7.0-SNAPSHOT] HiveMQ Platform Operator Init 1.7.0-SNAPSHOT (commit: 3bc9484 on branch: HEAD) built on Wed Jan 29 22:06:36 UTC 2025
2025-01-29 22:16:40,063 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Using bind address 10.42.0.14 from environment variable
2025-01-29 22:16:41,048 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT (commit: 3bc9484 on branch: HEAD) built on Wed Jan 29 22:06:36 UTC 2025
2025-01-29 22:16:41,048 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] PodInfo ConfigMap directory: /etc/podinfo
2025-01-29 22:16:41,048 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ home directory: /opt/hivemq
2025-01-29 22:16:41,048 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ Logback folder: /opt/hivemq/conf
2025-01-29 22:16:41,048 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ Config folder: /opt/hivemq/conf-k8s
2025-01-29 22:16:41,048 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting HiveMQ Platform Operator Init App
2025-01-29 22:16:41,049 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting Pod reconciler
2025-01-29 22:16:42,316 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Pod reconciler is scheduled (interval: 5000 ms)
2025-01-29 22:16:42,317 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting the REST API on 10.42.0.14:7979
2025-01-29 22:16:42,345 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Waiting up to 600s for at most 2 HiveMQ nodes in cluster service hivemq-test-hivemq-platform-cluster.helmmonitoringplatformit.svc
2025-01-29 22:16:42,657 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Resolved 2 IP addresses: [10.42.0.14, 10.42.0.13]
2025-01-29 22:16:42,657 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] HiveMQ node count of 2 is within threshold of 2
2025-01-29 22:16:42,657 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Proceeding with container start
2025-01-29 22:16:42,748 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Initializing HiveMQ Platform extensions with initial configuration: {hivemq-allow-all-extension={start-priority=-1, skip-https-hostname-verification=false, restart=true, config-version=0, header-version=0, c-uri=, priority=-1, uri=preinstalled, skip-https-certificate-validation=false, enabled=true}, hivemq-prometheus-extension={priority=-1, restart=true, enabled=true, request-header-path=no-request-headers, uri=preinstalled, skip-https-certificate-validation=false, skip-https-hostname-verification=false, c-uri=, start-priority=-1}}
2025-01-29 22:16:43,244 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Extension hivemq-allow-all-extension was already enabled
2025-01-29 22:16:43,256 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Successfully enabled extension hivemq-prometheus-extension
2025-01-29 22:16:43,317 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting HiveMQ Platform version 4.36.0 (4.36.0)
2025-01-29 22:16:43,317 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Configuring the HiveMQ Platform
2025-01-29 22:16:43,352 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Changed logback.xml file scan period to 20 seconds
2025-01-29 22:16:43,450 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Starting the HiveMQ Platform
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] -------------------------------------------------------------------------
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] 
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]                   _    _  _              __  __   ____
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]                  | |  | |(_)            |  \/  | / __ \
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]                  | |__| | _ __   __ ___ | \  / || |  | |
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]                  |  __  || |\ \ / // _ \| |\/| || |  | |
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]                  | |  | || | \ V /|  __/| |  | || |__| |
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]                  |_|  |_||_|  \_/  \___||_|  |_| \___\_\
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] 
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] -------------------------------------------------------------------------
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] 
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]   HiveMQ Start Script for Linux/Unix v1.14
2025-01-29 22:16:43,455 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] 
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] -------------------------------------------------------------------------
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] 
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]   HIVEMQ_HOME: /opt/hivemq
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] 
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]   JAVA_OPTS: -XX:+UnlockExperimentalVMOptions -XX:InitialRAMPercentage=50 -XX:MaxRAMPercentage=50 -Djava.net.preferIPv4Stack=true --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/sun.nio.ch=ALL-UNNAMED --add-opens jdk.management/com.sun.management.internal=ALL-UNNAMED --add-exports java.base/jdk.internal.misc=ALL-UNNAMED -Djava.security.egd=file:/dev/./urandom -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9010 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Duser.language=en -Duser.region=US -XX:+CrashOnOutOfMemoryError -XX:+HeapDumpOnOutOfMemoryError
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] 
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4]   JAVA_VERSION: 21
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] 
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] -------------------------------------------------------------------------
2025-01-29 22:16:43,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] 
2025-01-29 22:16:44,643 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning default Health API response 503 for readiness
2025-01-29 22:16:44,863 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:44,863 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:16:46,151 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Starting HiveMQ Enterprise Server
2025-01-29 22:16:46,157 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - HiveMQ version: 4.36.0
2025-01-29 22:16:46,158 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - HiveMQ home directory: /opt/hivemq
2025-01-29 22:16:46,158 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Log Configuration was overridden by /opt/hivemq/conf/logback.xml
2025-01-29 22:16:47,646 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Successfully loaded configuration from '/opt/hivemq/conf-k8s/config.xml'.
2025-01-29 22:16:48,243 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - This node's ID is DvxZU
2025-01-29 22:16:48,244 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Clustering is enabled
2025-01-29 22:16:48,506 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.503 [pool-6-thread-6] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:48,507 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.504 [pool-6-thread-7] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:48,507 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.504 [pool-6-thread-8] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:48,507 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.504 [pool-6-thread-8] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:48,507 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.504 [pool-6-thread-8] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:48,508 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.508 [pool-6-thread-6] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:48,516 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.514 [ReconcilerExecutor-hivemq-controller-121] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:48,516 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.514 [ReconcilerExecutor-hivemq-controller-121] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:48,517 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.514 [ReconcilerExecutor-hivemq-controller-121] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:48,517 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.517 [ReconcilerExecutor-hivemq-controller-121] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 1, ready: 1, current: 2, updated: 2)
2025-01-29 22:16:48,519 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.517 [ReconcilerExecutor-hivemq-controller-121] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:48,519 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.518 [ReconcilerExecutor-hivemq-controller-121] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:16:48,520 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.519 [ReconcilerExecutor-hivemq-controller-121] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:48,521 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:48.520 [ReconcilerExecutor-hivemq-controller-121] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 1 of 2 replicas are ready
2025-01-29 22:16:49,943 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:16:49,956 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:49,956 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:16:49,961 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning Health API response 200 for liveness
2025-01-29 22:16:52,653 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] Jan 29, 2025 10:16:52 PM io.vertx.core.impl.BlockedThreadChecker
2025-01-29 22:16:52,653 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARNING: Thread Thread[vert.x-eventloop-thread-1,5,main] has been blocked for 2297 ms, time limit is 2000 ms
2025-01-29 22:16:53,343 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Updating Pod HiveMQ Platform Operator Init App version annotation (version: 1.7.0-SNAPSHOT)
2025-01-29 22:16:53,863 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:16:53,865 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.865 [pool-6-thread-19] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:16:53,868 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.866 [pool-6-thread-18] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:16:53,869 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.866 [pool-6-thread-13] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:16:53,870 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.868 [pool-6-thread-13] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:16:53,870 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.868 [pool-6-thread-13] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:16:53,871 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.870 [pool-6-thread-13] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:16:53,874 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.873 [ReconcilerExecutor-hivemq-controller-122] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:16:53,874 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.873 [ReconcilerExecutor-hivemq-controller-122] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:16:53,874 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.873 [ReconcilerExecutor-hivemq-controller-122] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:16:53,875 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.874 [ReconcilerExecutor-hivemq-controller-122] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 1, ready: 1, current: 2, updated: 2)
2025-01-29 22:16:53,875 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.874 [ReconcilerExecutor-hivemq-controller-122] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:16:53,877 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.875 [ReconcilerExecutor-hivemq-controller-122] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:16:53,880 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.879 [ReconcilerExecutor-hivemq-controller-122] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:16:53,880 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:16:53.879 [ReconcilerExecutor-hivemq-controller-122] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 1 of 2 replicas are ready
2025-01-29 22:16:53,948 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:16:53,953 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Successfully updated Pod HiveMQ Platform Operator Init App version annotation (version: 1.7.0-SNAPSHOT)
2025-01-29 22:16:53,957 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:53,957 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:16:58,943 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:16:58,948 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:16:58,948 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:17:03,886 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.882 [pool-6-thread-22] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:17:03,886 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.882 [pool-6-thread-28] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:17:03,886 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.883 [pool-6-thread-28] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:17:03,886 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.883 [pool-6-thread-28] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:17:03,886 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.883 [pool-6-thread-23] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:17:03,888 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.888 [pool-6-thread-22] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:17:03,892 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.891 [ReconcilerExecutor-hivemq-controller-123] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:17:03,892 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.891 [ReconcilerExecutor-hivemq-controller-123] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:17:03,892 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.891 [ReconcilerExecutor-hivemq-controller-123] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:17:03,893 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.892 [ReconcilerExecutor-hivemq-controller-123] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 1, ready: 1, current: 2, updated: 2)
2025-01-29 22:17:03,894 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.892 [ReconcilerExecutor-hivemq-controller-123] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:17:03,895 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.894 [ReconcilerExecutor-hivemq-controller-123] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:17:03,896 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.895 [ReconcilerExecutor-hivemq-controller-123] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:17:03,896 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:03.895 [ReconcilerExecutor-hivemq-controller-123] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 1 of 2 replicas are ready
2025-01-29 22:17:03,946 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:17:03,952 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:17:03,952 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:17:05,644 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - No valid license file found. Using trial license, restricted to 25 connections.
2025-01-29 22:17:06,846 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for liveness: null
2025-01-29 22:17:06,846 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning default Health API response 200 for liveness
2025-01-29 22:17:08,817 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - No valid license file for Data Hub found. Using free license, restricted to 1 policy.
2025-01-29 22:17:08,952 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Cannot connect to Health API for readiness: null
2025-01-29 22:17:08,954 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:17:08,954 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:17:10,143 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Audit Logger started.
2025-01-29 22:17:10,373 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - This node uses '1' CPU cores.
2025-01-29 22:17:10,377 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Starting HiveMQ Health API on address 0.0.0.0 and port 8889
2025-01-29 22:17:11,146 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Started HiveMQ Health API in 769ms
2025-01-29 22:17:11,669 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Starting HiveMQ extension system.
2025-01-29 22:17:11,952 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Starting extension with id "hivemq-dns-cluster-discovery" at /opt/hivemq/extensions/hivemq-dns-cluster-discovery
2025-01-29 22:17:12,453 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Using TCP cluster transport on address 10.42.0.14 and port 7000
2025-01-29 22:17:12,456 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Extension "DNS Cluster Discovery Extension" version 4.3.2 started successfully.
2025-01-29 22:17:12,456 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Starting extension with id "hivemq-prometheus-extension" at /opt/hivemq/extensions/hivemq-prometheus-extension
2025-01-29 22:17:12,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Using extension cluster discovery
2025-01-29 22:17:13,551 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Started Jetty Server exposing Prometheus Servlet on URI http://0.0.0.0:9399/
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Extension "Prometheus Monitoring Extension" version 4.0.12 started successfully.
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Starting extension with id "hivemq-allow-all-extension" at /opt/hivemq/extensions/hivemq-allow-all-extension
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARN  - 
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] ################################################################################################################
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] # This HiveMQ deployment is not secure! You are lacking Authentication and Authorization.                      #
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] # Right now any MQTT client can connect to the broker with a full set of permissions.                          #
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] # For production usage, add an appropriate security extension and remove the hivemq-allow-all extension.       #
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] # You can download security extensions from the HiveMQ Marketplace (https://www.hivemq.com/extensions/).       #
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] ################################################################################################################
2025-01-29 22:17:13,552 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Extension "Allow All Extension" version 1.1.1 started successfully.
2025-01-29 22:17:13,647 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Cluster nodes found by discovery: [0kK8f|1] (2) [0kK8f, DvxZU].
2025-01-29 22:17:13,660 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Cluster nodes found by discovery: [0kK8f|1] (2) [0kK8f, DvxZU].
2025-01-29 22:17:13,851 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Cluster size = 1, members : [0kK8f].
2025-01-29 22:17:13,900 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.899 [pool-6-thread-34] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:17:13,902 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.900 [pool-6-thread-39] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:17:13,902 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.900 [pool-6-thread-32] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:17:13,902 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.901 [pool-6-thread-32] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:17:13,902 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.901 [pool-6-thread-32] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:17:13,906 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.905 [pool-6-thread-34] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:17:13,913 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.909 [ReconcilerExecutor-hivemq-controller-124] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:17:13,913 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.909 [ReconcilerExecutor-hivemq-controller-124] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:17:13,914 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.909 [ReconcilerExecutor-hivemq-controller-124] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:17:13,914 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.911 [ReconcilerExecutor-hivemq-controller-124] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 1, ready: 1, current: 2, updated: 2)
2025-01-29 22:17:13,915 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.911 [ReconcilerExecutor-hivemq-controller-124] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:17:13,915 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.912 [ReconcilerExecutor-hivemq-controller-124] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:17:13,915 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.913 [ReconcilerExecutor-hivemq-controller-124] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:17:13,915 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:13.914 [ReconcilerExecutor-hivemq-controller-124] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform is starting, 1 of 2 replicas are ready
2025-01-29 22:17:14,746 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Starting cluster join process. This may take a while. Please do not shut down HiveMQ.
2025-01-29 22:17:14,747 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning Health API response 503 for readiness
2025-01-29 22:17:14,751 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Cluster join process is still ongoing. Please do not shut down HiveMQ.
2025-01-29 22:17:14,757 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:17:14,757 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:17:16,759 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Cluster size = 2, members : [DvxZU, 0kK8f].
2025-01-29 22:17:16,768 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Cluster size = 2, members : [DvxZU, 0kK8f].
2025-01-29 22:17:16,844 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Finished cluster join process successfully.
2025-01-29 22:17:16,849 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARN  - No user for HiveMQ Control Center configured. Starting with default user
2025-01-29 22:17:16,849 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Starting HiveMQ Control Center on address 0.0.0.0 and port 8080
2025-01-29 22:17:16,853 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Mounting HiveMQ Control Center V2 Preview
2025-01-29 22:17:17,546 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Started HiveMQ Control Center in 702ms
2025-01-29 22:17:17,561 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Starting TCP listener on address 0.0.0.0 and port 1883
2025-01-29 22:17:17,654 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Started TCP Listener on address 0.0.0.0 and on port 1883.
2025-01-29 22:17:17,654 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Started HiveMQ in 31808ms
2025-01-29 22:17:18,867 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning Health API response 200 for readiness
2025-01-29 22:17:18,878 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:17:18,893 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.887 [pool-6-thread-44] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:17:18,899 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.888 [pool-6-thread-45] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:17:18,899 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.895 [pool-6-thread-45] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:17:18,899 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.895 [pool-6-thread-45] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:17:18,906 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.890 [pool-6-thread-50] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:17:18,906 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.902 [pool-6-thread-45] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status STARTING (READY)
2025-01-29 22:17:18,917 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.913 [ReconcilerExecutor-hivemq-controller-125] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:17:18,917 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.913 [ReconcilerExecutor-hivemq-controller-125] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status STARTING - HiveMQ Platform is starting (READY)
2025-01-29 22:17:18,920 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.913 [ReconcilerExecutor-hivemq-controller-125] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:17:18,920 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.914 [ReconcilerExecutor-hivemq-controller-125] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 2, ready: 2, current: 2, updated: 2)
2025-01-29 22:17:18,920 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.914 [ReconcilerExecutor-hivemq-controller-125] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:17:18,924 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.923 [ReconcilerExecutor-hivemq-controller-125] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:17:18,965 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.963 [ReconcilerExecutor-hivemq-controller-125] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:17:18,965 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:18.964 [ReconcilerExecutor-hivemq-controller-125] INFO  c.h.p.o.h.HiveMQPlatformReconcilerBaseHandler - [helmmoni] HiveMQ Platform started successfully
2025-01-29 22:17:19,064 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.063 [ReconcilerExecutor-hivemq-controller-125] DEBUG c.h.p.operator.event.EventSender - [helmmoni] Creating K8s event hivemq-platform-ready: [Ready] HiveMQ Platform is ready
2025-01-29 22:17:19,073 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Ready] HiveMQ Platform is ready [helmmonitoringplatformit:test-hivemq-platform]
2025-01-29 22:17:19,075 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.073 [ReconcilerExecutor-hivemq-controller-125] INFO  c.h.p.o.h.AbstractHiveMQReconcilerStateHandler - [helmmoni] Update HiveMQ Platform Status (STARTING [READY] -> RUNNING [READY]): HiveMQ Platform is ready
2025-01-29 22:17:19,083 DEBUG com.hivemq.helmcharts.util.K8sUtil - Comparing actual state 'RUNNING' and waiting for 'RUNNING'
2025-01-29 22:17:19,114 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.112 [pool-6-thread-8] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:17:19,114 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.113 [pool-6-thread-4] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:17:19,162 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.112 [pool-6-thread-5] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:17:19,163 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.161 [pool-6-thread-5] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:17:19,163 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.162 [pool-6-thread-5] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:17:19,163 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.162 [pool-6-thread-5] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Update PodInfo ConfigMap
2025-01-29 22:17:19,175 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.174 [pool-6-thread-5] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status RUNNING (READY)
2025-01-29 22:17:19,179 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.178 [ReconcilerExecutor-hivemq-controller-126] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:17:19,179 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.178 [ReconcilerExecutor-hivemq-controller-126] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status RUNNING - HiveMQ Platform is ready (READY)
2025-01-29 22:17:19,179 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.178 [ReconcilerExecutor-hivemq-controller-126] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:17:19,212 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.211 [ReconcilerExecutor-hivemq-controller-126] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 2, ready: 2, current: 2, updated: 2)
2025-01-29 22:17:19,212 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.211 [ReconcilerExecutor-hivemq-controller-126] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:17:19,215 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.212 [ReconcilerExecutor-hivemq-controller-126] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:17:19,215 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:19.214 [ReconcilerExecutor-hivemq-controller-126] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
Request method:	GET
Request URI:	http://localhost:45403/api/v1/query?query=com_hivemq_cluster_nodes_count
Proxy:			<none>
Request params:	query=com_hivemq_cluster_nodes_count
Query params:	<none>
Form params:	<none>
Path params:	<none>
Headers:		Accept=*/*
Cookies:		<none>
Multiparts:		<none>
Body:			<none>
HTTP/1.1 200 OK
Content-Encoding: gzip
Content-Type: application/json
Date: Wed, 29 Jan 2025 22:17:24 GMT
Content-Length: 268

{
    "status": "success",
    "data": {
        "resultType": "vector",
        "result": [
            {
                "metric": {
                    "__name__": "com_hivemq_cluster_nodes_count",
                    "container": "hivemq",
                    "endpoint": "metrics-9399",
                    "instance": "10.42.0.13:9399",
                    "job": "hivemq-test-hivemq-platform-metrics-9399",
                    "namespace": "helmmonitoringplatformit",
                    "pod": "test-hivemq-platform-0",
                    "service": "hivemq-test-hivemq-platform-metrics-9399"
                },
                "value": [
                    1738189044.766,
                    "2"
                ]
            },
            {
                "metric": {
                    "__name__": "com_hivemq_cluster_nodes_count",
                    "container": "hivemq",
                    "endpoint": "metrics-9399",
                    "instance": "10.42.0.14:9399",
                    "job": "hivemq-test-hivemq-platform-metrics-9399",
                    "namespace": "helmmonitoringplatformit",
                    "pod": "test-hivemq-platform-1",
                    "service": "hivemq-test-hivemq-platform-metrics-9399"
                },
                "value": [
                    1738189044.766,
                    "1"
                ]
            }
        ]
    }
}
2025-01-29 22:17:29,220 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.217 [pool-6-thread-16] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:17:29,220 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.217 [pool-6-thread-19] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:17:29,221 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.220 [pool-6-thread-18] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:17:29,221 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.220 [pool-6-thread-18] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:17:29,221 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.220 [pool-6-thread-18] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:17:29,223 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.223 [pool-6-thread-18] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status RUNNING (READY)
2025-01-29 22:17:29,227 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.226 [ReconcilerExecutor-hivemq-controller-127] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:17:29,227 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.226 [ReconcilerExecutor-hivemq-controller-127] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status RUNNING - HiveMQ Platform is ready (READY)
2025-01-29 22:17:29,227 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.226 [ReconcilerExecutor-hivemq-controller-127] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:17:29,228 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.227 [ReconcilerExecutor-hivemq-controller-127] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 2, ready: 2, current: 2, updated: 2)
2025-01-29 22:17:29,229 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.228 [ReconcilerExecutor-hivemq-controller-127] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:17:29,230 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.229 [ReconcilerExecutor-hivemq-controller-127] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:17:29,231 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:29.230 [ReconcilerExecutor-hivemq-controller-127] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
Request method:	GET
Request URI:	http://localhost:34189/api/v1/query?query=com_hivemq_cluster_nodes_count
Proxy:			<none>
Request params:	query=com_hivemq_cluster_nodes_count
Query params:	<none>
Form params:	<none>
Path params:	<none>
Headers:		Accept=*/*
Cookies:		<none>
Multiparts:		<none>
Body:			<none>
HTTP/1.1 200 OK
Content-Encoding: gzip
Content-Type: application/json
Date: Wed, 29 Jan 2025 22:17:29 GMT
Content-Length: 264

{
    "status": "success",
    "data": {
        "resultType": "vector",
        "result": [
            {
                "metric": {
                    "__name__": "com_hivemq_cluster_nodes_count",
                    "container": "hivemq",
                    "endpoint": "metrics-9399",
                    "instance": "10.42.0.13:9399",
                    "job": "hivemq-test-hivemq-platform-metrics-9399",
                    "namespace": "helmmonitoringplatformit",
                    "pod": "test-hivemq-platform-0",
                    "service": "hivemq-test-hivemq-platform-metrics-9399"
                },
                "value": [
                    1738189049.945,
                    "2"
                ]
            },
            {
                "metric": {
                    "__name__": "com_hivemq_cluster_nodes_count",
                    "container": "hivemq",
                    "endpoint": "metrics-9399",
                    "instance": "10.42.0.14:9399",
                    "job": "hivemq-test-hivemq-platform-metrics-9399",
                    "namespace": "helmmonitoringplatformit",
                    "pod": "test-hivemq-platform-1",
                    "service": "hivemq-test-hivemq-platform-metrics-9399"
                },
                "value": [
                    1738189049.945,
                    "2"
                ]
            }
        ]
    }
}
Request method:	GET
Request URI:	http://localhost:33183/api/search
Proxy:			<none>
Request params:	<none>
Query params:	<none>
Form params:	<none>
Path params:	<none>
Headers:		Authorization=Basic YWRtaW46cHJvbS1vcGVyYXRvcg==
				Accept=*/*
Cookies:		<none>
Multiparts:		<none>
Body:			<none>
HTTP/1.1 200 OK
Cache-Control: no-store
Content-Type: application/json
X-Content-Type-Options: nosniff
X-Frame-Options: deny
X-Xss-Protection: 1; mode=block
Date: Wed, 29 Jan 2025 22:17:35 GMT
Transfer-Encoding: chunked

[
    {
        "id": 1,
        "uid": "alertmanager-overview",
        "title": "Alertmanager / Overview",
        "uri": "db/alertmanager-overview",
        "url": "/d/alertmanager-overview/alertmanager-overview",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "alertmanager-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 7,
        "uid": "vkQ0UHxik",
        "title": "CoreDNS",
        "uri": "db/coredns",
        "url": "/d/vkQ0UHxik/coredns",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "coredns",
            "dns"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 5,
        "uid": "c2f4e12cdf69feb95caa41a5a1b423d9",
        "title": "etcd",
        "uri": "db/etcd",
        "url": "/d/c2f4e12cdf69feb95caa41a5a1b423d9/etcd",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "etcd-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 6,
        "uid": "6be0s85Mk",
        "title": "Grafana Overview",
        "uri": "db/grafana-overview",
        "url": "/d/6be0s85Mk/grafana-overview",
        "slug": "",
        "type": "dash-db",
        "tags": [
            
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 29,
        "uid": "aebhs08tnu1vkc",
        "title": "HiveMQ Platform (Prometheus)",
        "uri": "db/hivemq-platform-prometheus",
        "url": "/d/aebhs08tnu1vkc/hivemq-platform-prometheus",
        "slug": "",
        "type": "dash-db",
        "tags": [
            
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 2,
        "uid": "09ec8aa1e996d6ffcd6817bbaff4db1b",
        "title": "Kubernetes / API server",
        "uri": "db/kubernetes-api-server",
        "url": "/d/09ec8aa1e996d6ffcd6817bbaff4db1b/kubernetes-api-server",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 9,
        "uid": "b59e6c9f2fcbe2e16d77fc492374cc4f",
        "title": "Kubernetes / Compute Resources /  Multi-Cluster",
        "uri": "db/kubernetes-compute-resources-multi-cluster",
        "url": "/d/b59e6c9f2fcbe2e16d77fc492374cc4f/kubernetes-compute-resources-multi-cluster",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 8,
        "uid": "efa86fd1d0c121a26444b636a3f509a8",
        "title": "Kubernetes / Compute Resources / Cluster",
        "uri": "db/kubernetes-compute-resources-cluster",
        "url": "/d/efa86fd1d0c121a26444b636a3f509a8/kubernetes-compute-resources-cluster",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 10,
        "uid": "85a562078cdf77779eaa1add43ccec1e",
        "title": "Kubernetes / Compute Resources / Namespace (Pods)",
        "uri": "db/kubernetes-compute-resources-namespace-pods",
        "url": "/d/85a562078cdf77779eaa1add43ccec1e/kubernetes-compute-resources-namespace-pods",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 14,
        "uid": "a87fb0d919ec0ea5f6543124e16c42a5",
        "title": "Kubernetes / Compute Resources / Namespace (Workloads)",
        "uri": "db/kubernetes-compute-resources-namespace-workloads",
        "url": "/d/a87fb0d919ec0ea5f6543124e16c42a5/kubernetes-compute-resources-namespace-workloads",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 11,
        "uid": "200ac8fdbfbb74b39aff88118e4d1c2c",
        "title": "Kubernetes / Compute Resources / Node (Pods)",
        "uri": "db/kubernetes-compute-resources-node-pods",
        "url": "/d/200ac8fdbfbb74b39aff88118e4d1c2c/kubernetes-compute-resources-node-pods",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 12,
        "uid": "6581e46e4e5c7ba40a07646395ef7b23",
        "title": "Kubernetes / Compute Resources / Pod",
        "uri": "db/kubernetes-compute-resources-pod",
        "url": "/d/6581e46e4e5c7ba40a07646395ef7b23/kubernetes-compute-resources-pod",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 13,
        "uid": "a164a7f0339f99e89cea5cb47e9be617",
        "title": "Kubernetes / Compute Resources / Workload",
        "uri": "db/kubernetes-compute-resources-workload",
        "url": "/d/a164a7f0339f99e89cea5cb47e9be617/kubernetes-compute-resources-workload",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 4,
        "uid": "72e0e05bef5099e5f049b05fdc429ed4",
        "title": "Kubernetes / Controller Manager",
        "uri": "db/kubernetes-controller-manager",
        "url": "/d/72e0e05bef5099e5f049b05fdc429ed4/kubernetes-controller-manager",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 15,
        "uid": "3138fa155d5915769fbded898ac09fd9",
        "title": "Kubernetes / Kubelet",
        "uri": "db/kubernetes-kubelet",
        "url": "/d/3138fa155d5915769fbded898ac09fd9/kubernetes-kubelet",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 3,
        "uid": "ff635a025bcfea7bc3dd4f508990a3e9",
        "title": "Kubernetes / Networking / Cluster",
        "uri": "db/kubernetes-networking-cluster",
        "url": "/d/ff635a025bcfea7bc3dd4f508990a3e9/kubernetes-networking-cluster",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 16,
        "uid": "8b7a8b326d7a6f1f04244066368c67af",
        "title": "Kubernetes / Networking / Namespace (Pods)",
        "uri": "db/kubernetes-networking-namespace-pods",
        "url": "/d/8b7a8b326d7a6f1f04244066368c67af/kubernetes-networking-namespace-pods",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 17,
        "uid": "bbb2a765a623ae38130206c7d94a160f",
        "title": "Kubernetes / Networking / Namespace (Workload)",
        "uri": "db/kubernetes-networking-namespace-workload",
        "url": "/d/bbb2a765a623ae38130206c7d94a160f/kubernetes-networking-namespace-workload",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 24,
        "uid": "7a18067ce943a40ae25454675c19ff5c",
        "title": "Kubernetes / Networking / Pod",
        "uri": "db/kubernetes-networking-pod",
        "url": "/d/7a18067ce943a40ae25454675c19ff5c/kubernetes-networking-pod",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 28,
        "uid": "728bf77cc1166d2f3133bf25846876cc",
        "title": "Kubernetes / Networking / Workload",
        "uri": "db/kubernetes-networking-workload",
        "url": "/d/728bf77cc1166d2f3133bf25846876cc/kubernetes-networking-workload",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 23,
        "uid": "919b92a8e8041bd567af9edab12c840c",
        "title": "Kubernetes / Persistent Volumes",
        "uri": "db/kubernetes-persistent-volumes",
        "url": "/d/919b92a8e8041bd567af9edab12c840c/kubernetes-persistent-volumes",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 26,
        "uid": "632e265de029684c40b21cb76bca4f94",
        "title": "Kubernetes / Proxy",
        "uri": "db/kubernetes-proxy",
        "url": "/d/632e265de029684c40b21cb76bca4f94/kubernetes-proxy",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 27,
        "uid": "2e6b6a3b4bddf1427b3a55aa1311c656",
        "title": "Kubernetes / Scheduler",
        "uri": "db/kubernetes-scheduler",
        "url": "/d/2e6b6a3b4bddf1427b3a55aa1311c656/kubernetes-scheduler",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "kubernetes-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 21,
        "uid": "7e0a61e486f727d763fb1d86fdd629c2",
        "title": "Node Exporter / AIX",
        "uri": "db/node-exporter-aix",
        "url": "/d/7e0a61e486f727d763fb1d86fdd629c2/node-exporter-aix",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "node-exporter-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 22,
        "uid": "629701ea43bf69291922ea45f4a87d37",
        "title": "Node Exporter / MacOS",
        "uri": "db/node-exporter-macos",
        "url": "/d/629701ea43bf69291922ea45f4a87d37/node-exporter-macos",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "node-exporter-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 20,
        "uid": "7d57716318ee0dddbac5a7f451fb7753",
        "title": "Node Exporter / Nodes",
        "uri": "db/node-exporter-nodes",
        "url": "/d/7d57716318ee0dddbac5a7f451fb7753/node-exporter-nodes",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "node-exporter-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 18,
        "uid": "3e97d1d02672cdd0861f4c97c64f89b2",
        "title": "Node Exporter / USE Method / Cluster",
        "uri": "db/node-exporter-use-method-cluster",
        "url": "/d/3e97d1d02672cdd0861f4c97c64f89b2/node-exporter-use-method-cluster",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "node-exporter-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 19,
        "uid": "fac67cfbe174d3ef53eb473d73d9212f",
        "title": "Node Exporter / USE Method / Node",
        "uri": "db/node-exporter-use-method-node",
        "url": "/d/fac67cfbe174d3ef53eb473d73d9212f/node-exporter-use-method-node",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "node-exporter-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    },
    {
        "id": 25,
        "uid": "debhrzxhaxmv4e",
        "title": "Prometheus / Overview",
        "uri": "db/prometheus-overview",
        "url": "/d/debhrzxhaxmv4e/prometheus-overview",
        "slug": "",
        "type": "dash-db",
        "tags": [
            "prometheus-mixin"
        ],
        "isStarred": false,
        "sortMeta": 0,
        "isDeleted": false
    }
]
2025-01-29 22:17:35,101 INFO c.h.h.t.HelmChartContainer - Uninstalling release 'monitoring-stack' in namespace 'monitoring'...
2025-01-29 22:17:35,101 DEBUG c.h.h.t.HelmChartContainer - Executing helm command: /bin/helm --kubeconfig /etc/rancher/k3s/k3s.yaml uninstall monitoring-stack  --wait --timeout 5m0s --cascade foreground --namespace monitoring
2025-01-29 22:17:36,785 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning Health API response 200 for liveness
2025-01-29 22:17:36,933 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="3.73773ms"
2025-01-29 22:17:36,933 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="39.925µs"
2025-01-29 22:17:37,057 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="3.049347ms"
2025-01-29 22:17:37,057 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="38.231µs"
2025-01-29 22:17:37,083 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="4.499565ms"
2025-01-29 22:17:37,084 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="36.619µs"
2025-01-29 22:17:37,209 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-prometheus-node-exporter-stmml [4e490110-cf22-47c7-a300-a4e60efa881a] in monitoring was MODIFIED
2025-01-29 22:17:37,211 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container node-exporter [monitoring:monitoring-stack-prometheus-node-exporter-stmml]
2025-01-29 22:17:37,312 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-prometheus-node-exporter-stmml [4e490110-cf22-47c7-a300-a4e60efa881a] in monitoring was MODIFIED
2025-01-29 22:17:37,434 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"sys\" (UniqueName: \"kubernetes.io/host-path/4e490110-cf22-47c7-a300-a4e60efa881a-sys\") pod \"4e490110-cf22-47c7-a300-a4e60efa881a\" (UID: \"4e490110-cf22-47c7-a300-a4e60efa881a\") "
2025-01-29 22:17:37,434 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"proc\" (UniqueName: \"kubernetes.io/host-path/4e490110-cf22-47c7-a300-a4e60efa881a-proc\") pod \"4e490110-cf22-47c7-a300-a4e60efa881a\" (UID: \"4e490110-cf22-47c7-a300-a4e60efa881a\") "
2025-01-29 22:17:37,535 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"sys\" (UniqueName: \"kubernetes.io/host-path/4e490110-cf22-47c7-a300-a4e60efa881a-sys\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:37,535 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"proc\" (UniqueName: \"kubernetes.io/host-path/4e490110-cf22-47c7-a300-a4e60efa881a-proc\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:37,561 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="9757fa0722373bbad42befebda726766dc128f654b84a2297b4267831f0ed32c"
2025-01-29 22:17:37,566 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="9757fa0722373bbad42befebda726766dc128f654b84a2297b4267831f0ed32c"
2025-01-29 22:17:37,575 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-prometheus-node-exporter-stmml [4e490110-cf22-47c7-a300-a4e60efa881a] in monitoring was MODIFIED
2025-01-29 22:17:37,577 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-prometheus-node-exporter-stmml [4e490110-cf22-47c7-a300-a4e60efa881a] in monitoring was DELETED
2025-01-29 22:17:39,176 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="4e490110-cf22-47c7-a300-a4e60efa881a" path="/var/lib/kubelet/pods/4e490110-cf22-47c7-a300-a4e60efa881a/volumes"
2025-01-29 22:17:39,238 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.234 [pool-6-thread-30] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:17:39,238 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.234 [pool-6-thread-30] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:17:39,238 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.234 [pool-6-thread-30] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:17:39,238 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.234 [pool-6-thread-26] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:17:39,238 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.235 [pool-6-thread-24] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:17:39,239 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.238 [pool-6-thread-24] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status RUNNING (READY)
2025-01-29 22:17:39,242 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.241 [ReconcilerExecutor-hivemq-controller-128] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:17:39,243 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.241 [ReconcilerExecutor-hivemq-controller-128] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status RUNNING - HiveMQ Platform is ready (READY)
2025-01-29 22:17:39,243 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.241 [ReconcilerExecutor-hivemq-controller-128] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:17:39,244 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.243 [ReconcilerExecutor-hivemq-controller-128] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 2, ready: 2, current: 2, updated: 2)
2025-01-29 22:17:39,244 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.243 [ReconcilerExecutor-hivemq-controller-128] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:17:39,246 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.245 [ReconcilerExecutor-hivemq-controller-128] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:17:39,247 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:39.246 [ReconcilerExecutor-hivemq-controller-128] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:17:42,302 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:42,303 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:42,328 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:42,328 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:42,380 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:42,380 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:42,527 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:42,527 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:42,629 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:42,629 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:42,754 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:42,754 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:42,777 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:42,778 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:42,928 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:42,928 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,055 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,055 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,077 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,078 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,153 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,153 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,202 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,203 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,352 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,352 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,403 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,403 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,455 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,455 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,477 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,477 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,503 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,503 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,603 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,603 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,677 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,678 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,727 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,728 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,803 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,803 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,827 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,827 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:43,878 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:43,878 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,028 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,028 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,127 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,127 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,252 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,252 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,278 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,278 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,429 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,429 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,553 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,553 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,578 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,578 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,652 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,652 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,703 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,703 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,854 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,854 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,905 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,905 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:44,954 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:205] Failed calling webhook, failing open prometheusrulemutate.monitoring.coreos.com: failed calling webhook "prometheusrulemutate.monitoring.coreos.com": failed to call webhook: Post "https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s": service "monitoring-stack-kube-prom-operator" not found
2025-01-29 22:17:44,954 INFO c.h.h.t.HelmChartContainer - [K3S] [dispatcher.go:213] "Unhandled Error" err="failed calling webhook \"prometheusrulemutate.monitoring.coreos.com\": failed to call webhook: Post \"https://monitoring-stack-kube-prom-operator.monitoring.svc:443/admission-prometheusrules/validate?timeout=10s\": service \"monitoring-stack-kube-prom-operator\" not found"
2025-01-29 22:17:45,933 INFO c.h.h.t.HelmChartContainer - [K3S] [authentication.go:74] "Unable to authenticate the request" err="[invalid bearer token, serviceaccounts \"monitoring-stack-kube-prom-operator\" not found]"
2025-01-29 22:17:45,939 INFO c.h.h.t.HelmChartContainer - [K3S] [authentication.go:74] "Unable to authenticate the request" err="[invalid bearer token, serviceaccounts \"monitoring-stack-kube-prom-operator\" not found]"
2025-01-29 22:17:46,706 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-operator-6998896c-sswcs [5ceb77fa-7275-4c75-8edc-277b9ead7e63] in monitoring was MODIFIED
2025-01-29 22:17:46,718 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="13.487386ms"
2025-01-29 22:17:46,720 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container kube-prometheus-stack [monitoring:monitoring-stack-kube-prom-operator-6998896c-sswcs]
2025-01-29 22:17:46,721 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="40.716µs"
2025-01-29 22:17:46,809 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [d5c58d83-8550-4040-ad81-22086cd583ee] in monitoring was MODIFIED
2025-01-29 22:17:46,813 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container kube-state-metrics [monitoring:monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv]
2025-01-29 22:17:46,816 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="8.805003ms"
2025-01-29 22:17:46,817 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="79.018µs"
2025-01-29 22:17:46,877 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="59.612µs"
2025-01-29 22:17:46,881 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-operator-6998896c-sswcs [5ceb77fa-7275-4c75-8edc-277b9ead7e63] in monitoring was MODIFIED
2025-01-29 22:17:46,888 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-grafana-64c55fb967-jpjff [bbb8b81c-ba54-4027-96c0-517ac5e6b5b9] in monitoring was MODIFIED
2025-01-29 22:17:46,897 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container grafana-sc-dashboard [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:17:46,901 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="14.63953ms"
2025-01-29 22:17:46,906 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="68.348µs"
2025-01-29 22:17:46,915 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container grafana [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:17:46,915 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container grafana-sc-datasources [monitoring:monitoring-stack-grafana-64c55fb967-jpjff]
2025-01-29 22:17:46,987 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"tls-secret\" (UniqueName: \"kubernetes.io/secret/5ceb77fa-7275-4c75-8edc-277b9ead7e63-tls-secret\") pod \"5ceb77fa-7275-4c75-8edc-277b9ead7e63\" (UID: \"5ceb77fa-7275-4c75-8edc-277b9ead7e63\") "
2025-01-29 22:17:46,987 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-9s8d9\" (UniqueName: \"kubernetes.io/projected/5ceb77fa-7275-4c75-8edc-277b9ead7e63-kube-api-access-9s8d9\") pod \"5ceb77fa-7275-4c75-8edc-277b9ead7e63\" (UID: \"5ceb77fa-7275-4c75-8edc-277b9ead7e63\") "
2025-01-29 22:17:47,024 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [d5c58d83-8550-4040-ad81-22086cd583ee] in monitoring was MODIFIED
2025-01-29 22:17:47,027 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="55.884µs"
2025-01-29 22:17:47,089 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-xbklg\" (UniqueName: \"kubernetes.io/projected/d5c58d83-8550-4040-ad81-22086cd583ee-kube-api-access-xbklg\") pod \"d5c58d83-8550-4040-ad81-22086cd583ee\" (UID: \"d5c58d83-8550-4040-ad81-22086cd583ee\") "
2025-01-29 22:17:47,089 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"tls-secret\" (UniqueName: \"kubernetes.io/secret/5ceb77fa-7275-4c75-8edc-277b9ead7e63-tls-secret\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,089 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-9s8d9\" (UniqueName: \"kubernetes.io/projected/5ceb77fa-7275-4c75-8edc-277b9ead7e63-kube-api-access-9s8d9\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,189 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-xbklg\" (UniqueName: \"kubernetes.io/projected/d5c58d83-8550-4040-ad81-22086cd583ee-kube-api-access-xbklg\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,201 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container alertmanager [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:17:47,204 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was MODIFIED
2025-01-29 22:17:47,244 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container config-reloader [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:17:47,333 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: Get "http://10.42.0.11:9093/-/ready": dial tcp 10.42.0.11:9093: connect: connection refused [monitoring:alertmanager-monitoring-stack-kube-prom-alertmanager-0]
2025-01-29 22:17:47,339 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="97.482µs"
2025-01-29 22:17:47,345 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-grafana-64c55fb967-jpjff [bbb8b81c-ba54-4027-96c0-517ac5e6b5b9] in monitoring was MODIFIED
2025-01-29 22:17:47,351 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:17:47,361 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container prometheus [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:17:47,374 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container config-reloader [monitoring:prometheus-monitoring-stack-kube-prom-prometheus-0]
2025-01-29 22:17:47,399 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"sc-dashboard-provider\" (UniqueName: \"kubernetes.io/configmap/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-sc-dashboard-provider\") pod \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") "
2025-01-29 22:17:47,400 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-mrmtm\" (UniqueName: \"kubernetes.io/projected/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-kube-api-access-mrmtm\") pod \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") "
2025-01-29 22:17:47,400 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"sc-datasources-volume\" (UniqueName: \"kubernetes.io/empty-dir/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-sc-datasources-volume\") pod \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") "
2025-01-29 22:17:47,400 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"sc-dashboard-volume\" (UniqueName: \"kubernetes.io/empty-dir/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-sc-dashboard-volume\") pod \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") "
2025-01-29 22:17:47,400 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"config\" (UniqueName: \"kubernetes.io/configmap/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-config\") pod \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") "
2025-01-29 22:17:47,400 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"storage\" (UniqueName: \"kubernetes.io/empty-dir/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-storage\") pod \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\" (UID: \"bbb8b81c-ba54-4027-96c0-517ac5e6b5b9\") "
2025-01-29 22:17:47,498 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"sc-dashboard-volume\" (UniqueName: \"kubernetes.io/empty-dir/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-sc-dashboard-volume\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,498 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"config\" (UniqueName: \"kubernetes.io/configmap/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-config\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,499 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"storage\" (UniqueName: \"kubernetes.io/empty-dir/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-storage\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,499 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"sc-dashboard-provider\" (UniqueName: \"kubernetes.io/configmap/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-sc-dashboard-provider\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,499 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-mrmtm\" (UniqueName: \"kubernetes.io/projected/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-kube-api-access-mrmtm\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,499 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"sc-datasources-volume\" (UniqueName: \"kubernetes.io/empty-dir/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9-sc-datasources-volume\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,512 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was MODIFIED
2025-01-29 22:17:47,564 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:17:47,578 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="b877f2739a560d18058f91b0b50ae98a2726985c8408409c0bfe2a0c7422d005"
2025-01-29 22:17:47,583 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="b877f2739a560d18058f91b0b50ae98a2726985c8408409c0bfe2a0c7422d005"
2025-01-29 22:17:47,584 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="0cf21c320ff6f5579ae19b7ebd26237ff28b43f043fbb5417094a4c8e42b8c03"
2025-01-29 22:17:47,589 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="52.197µs"
2025-01-29 22:17:47,591 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-operator-6998896c-sswcs [5ceb77fa-7275-4c75-8edc-277b9ead7e63] in monitoring was MODIFIED
2025-01-29 22:17:47,594 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="38.432µs"
2025-01-29 22:17:47,595 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="0cf21c320ff6f5579ae19b7ebd26237ff28b43f043fbb5417094a4c8e42b8c03"
2025-01-29 22:17:47,596 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-prom-operator-6998896c-sswcs [5ceb77fa-7275-4c75-8edc-277b9ead7e63] in monitoring was DELETED
2025-01-29 22:17:47,601 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/788aac66-49cf-4129-be04-1178b7c2a3fd-tls-assets\") pod \"788aac66-49cf-4129-be04-1178b7c2a3fd\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") "
2025-01-29 22:17:47,602 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-config-out\") pod \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") "
2025-01-29 22:17:47,602 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/788aac66-49cf-4129-be04-1178b7c2a3fd-web-config\") pod \"788aac66-49cf-4129-be04-1178b7c2a3fd\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") "
2025-01-29 22:17:47,602 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"config\" (UniqueName: \"kubernetes.io/secret/788aac66-49cf-4129-be04-1178b7c2a3fd-config\") pod \"788aac66-49cf-4129-be04-1178b7c2a3fd\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") "
2025-01-29 22:17:47,602 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-tls-assets\") pod \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") "
2025-01-29 22:17:47,603 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"prometheus-monitoring-stack-kube-prom-prometheus-rulefiles-0\" (UniqueName: \"kubernetes.io/configmap/788aac66-49cf-4129-be04-1178b7c2a3fd-prometheus-monitoring-stack-kube-prom-prometheus-rulefiles-0\") pod \"788aac66-49cf-4129-be04-1178b7c2a3fd\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") "
2025-01-29 22:17:47,604 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"prometheus-monitoring-stack-kube-prom-prometheus-db\" (UniqueName: \"kubernetes.io/empty-dir/788aac66-49cf-4129-be04-1178b7c2a3fd-prometheus-monitoring-stack-kube-prom-prometheus-db\") pod \"788aac66-49cf-4129-be04-1178b7c2a3fd\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") "
2025-01-29 22:17:47,604 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="a0ab228f228c1647a5abf0552aadfc1a9e46ec38259677bf436334db383e38dd"
2025-01-29 22:17:47,604 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-web-config\") pod \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") "
2025-01-29 22:17:47,604 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"alertmanager-monitoring-stack-kube-prom-alertmanager-db\" (UniqueName: \"kubernetes.io/empty-dir/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-alertmanager-monitoring-stack-kube-prom-alertmanager-db\") pod \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") "
2025-01-29 22:17:47,605 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-lf8g5\" (UniqueName: \"kubernetes.io/projected/788aac66-49cf-4129-be04-1178b7c2a3fd-kube-api-access-lf8g5\") pod \"788aac66-49cf-4129-be04-1178b7c2a3fd\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") "
2025-01-29 22:17:47,605 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/secret/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-config-volume\") pod \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") "
2025-01-29 22:17:47,605 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/788aac66-49cf-4129-be04-1178b7c2a3fd-config-out\") pod \"788aac66-49cf-4129-be04-1178b7c2a3fd\" (UID: \"788aac66-49cf-4129-be04-1178b7c2a3fd\") "
2025-01-29 22:17:47,605 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-lj86t\" (UniqueName: \"kubernetes.io/projected/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-kube-api-access-lj86t\") pod \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\" (UID: \"3ec312a8-49ee-42cb-a91c-b7e9d302d4ee\") "
2025-01-29 22:17:47,605 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/788aac66-49cf-4129-be04-1178b7c2a3fd-tls-assets\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,619 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="c9f65fe1c6bf79d306f5ff62b81095f5919242ba483e1ef6f9751b9a81a72e72"
2025-01-29 22:17:47,628 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="9f6edc7429254b14dad7517c316ff3d13996644f263624f1c6bdc5c82d5f5a97"
2025-01-29 22:17:47,628 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="51.026µs"
2025-01-29 22:17:47,633 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="47.559µs"
2025-01-29 22:17:47,634 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [d5c58d83-8550-4040-ad81-22086cd583ee] in monitoring was MODIFIED
2025-01-29 22:17:47,638 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-kube-state-metrics-5bf5c7b54d-sbhlv [d5c58d83-8550-4040-ad81-22086cd583ee] in monitoring was DELETED
2025-01-29 22:17:47,641 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="a0ab228f228c1647a5abf0552aadfc1a9e46ec38259677bf436334db383e38dd"
2025-01-29 22:17:47,642 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="c9f65fe1c6bf79d306f5ff62b81095f5919242ba483e1ef6f9751b9a81a72e72"
2025-01-29 22:17:47,646 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="9f6edc7429254b14dad7517c316ff3d13996644f263624f1c6bdc5c82d5f5a97"
2025-01-29 22:17:47,646 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="a0ab228f228c1647a5abf0552aadfc1a9e46ec38259677bf436334db383e38dd"
2025-01-29 22:17:47,647 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="c9f65fe1c6bf79d306f5ff62b81095f5919242ba483e1ef6f9751b9a81a72e72"
2025-01-29 22:17:47,649 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="9f6edc7429254b14dad7517c316ff3d13996644f263624f1c6bdc5c82d5f5a97"
2025-01-29 22:17:47,650 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="a0ab228f228c1647a5abf0552aadfc1a9e46ec38259677bf436334db383e38dd"
2025-01-29 22:17:47,650 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="c9f65fe1c6bf79d306f5ff62b81095f5919242ba483e1ef6f9751b9a81a72e72"
2025-01-29 22:17:47,654 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="9f6edc7429254b14dad7517c316ff3d13996644f263624f1c6bdc5c82d5f5a97"
2025-01-29 22:17:47,654 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="908b471cd1f9ae0313111b3d30795286a91e7194cd1757758672cdf32b7bd7e0"
2025-01-29 22:17:47,656 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="19526d3946696e32b8184552f61031117981a7f1d24e46a3318f77ce3f667e4f"
2025-01-29 22:17:47,687 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="71.624µs"
2025-01-29 22:17:47,689 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="861e635d0befb11b2c50d233636bdb9d215dc6ff3828b19d89fdb0cb4f9314a8"
2025-01-29 22:17:47,691 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-grafana-64c55fb967-jpjff [bbb8b81c-ba54-4027-96c0-517ac5e6b5b9] in monitoring was MODIFIED
2025-01-29 22:17:47,696 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="51.586µs"
2025-01-29 22:17:47,700 INFO c.h.h.t.HelmChartContainer - [POD] monitoring-stack-grafana-64c55fb967-jpjff [bbb8b81c-ba54-4027-96c0-517ac5e6b5b9] in monitoring was DELETED
2025-01-29 22:17:47,704 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="908b471cd1f9ae0313111b3d30795286a91e7194cd1757758672cdf32b7bd7e0"
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="19526d3946696e32b8184552f61031117981a7f1d24e46a3318f77ce3f667e4f"
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-lf8g5\" (UniqueName: \"kubernetes.io/projected/788aac66-49cf-4129-be04-1178b7c2a3fd-kube-api-access-lf8g5\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"config-volume\" (UniqueName: \"kubernetes.io/secret/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-config-volume\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"alertmanager-monitoring-stack-kube-prom-alertmanager-db\" (UniqueName: \"kubernetes.io/empty-dir/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-alertmanager-monitoring-stack-kube-prom-alertmanager-db\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/788aac66-49cf-4129-be04-1178b7c2a3fd-config-out\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-lj86t\" (UniqueName: \"kubernetes.io/projected/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-kube-api-access-lj86t\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-config-out\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/788aac66-49cf-4129-be04-1178b7c2a3fd-web-config\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"config\" (UniqueName: \"kubernetes.io/secret/788aac66-49cf-4129-be04-1178b7c2a3fd-config\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-tls-assets\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,705 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"prometheus-monitoring-stack-kube-prom-prometheus-db\" (UniqueName: \"kubernetes.io/empty-dir/788aac66-49cf-4129-be04-1178b7c2a3fd-prometheus-monitoring-stack-kube-prom-prometheus-db\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,706 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"prometheus-monitoring-stack-kube-prom-prometheus-rulefiles-0\" (UniqueName: \"kubernetes.io/configmap/788aac66-49cf-4129-be04-1178b7c2a3fd-prometheus-monitoring-stack-kube-prom-prometheus-rulefiles-0\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,706 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee-web-config\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:17:47,707 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="861e635d0befb11b2c50d233636bdb9d215dc6ff3828b19d89fdb0cb4f9314a8"
2025-01-29 22:17:47,709 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="908b471cd1f9ae0313111b3d30795286a91e7194cd1757758672cdf32b7bd7e0"
2025-01-29 22:17:47,711 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="19526d3946696e32b8184552f61031117981a7f1d24e46a3318f77ce3f667e4f"
2025-01-29 22:17:47,711 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="861e635d0befb11b2c50d233636bdb9d215dc6ff3828b19d89fdb0cb4f9314a8"
2025-01-29 22:17:47,711 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="265d5412e97e405dee98b0df64acd4f265b0ad183c83ad2c94f84c1ab9472241"
2025-01-29 22:17:47,718 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="d18fc8e177de5920b40d83458fa89b53036a7dae6f46afac275f5d3ad24cdddc"
2025-01-29 22:17:47,721 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="332d36d62644a4089bf85e8dfa0fd8e6d531e6ee6947a6adab33284b34d2514e"
2025-01-29 22:17:47,727 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="265d5412e97e405dee98b0df64acd4f265b0ad183c83ad2c94f84c1ab9472241"
2025-01-29 22:17:47,729 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="d18fc8e177de5920b40d83458fa89b53036a7dae6f46afac275f5d3ad24cdddc"
2025-01-29 22:17:47,729 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="332d36d62644a4089bf85e8dfa0fd8e6d531e6ee6947a6adab33284b34d2514e"
2025-01-29 22:17:47,730 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="265d5412e97e405dee98b0df64acd4f265b0ad183c83ad2c94f84c1ab9472241"
2025-01-29 22:17:47,731 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="d18fc8e177de5920b40d83458fa89b53036a7dae6f46afac275f5d3ad24cdddc"
2025-01-29 22:17:47,731 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="332d36d62644a4089bf85e8dfa0fd8e6d531e6ee6947a6adab33284b34d2514e"
2025-01-29 22:17:47,911 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was MODIFIED
2025-01-29 22:17:47,913 INFO c.h.h.t.HelmChartContainer - [POD] prometheus-monitoring-stack-kube-prom-prometheus-0 [788aac66-49cf-4129-be04-1178b7c2a3fd] in monitoring was DELETED
2025-01-29 22:17:47,924 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was MODIFIED
2025-01-29 22:17:47,930 INFO c.h.h.t.HelmChartContainer - [POD] alertmanager-monitoring-stack-kube-prom-alertmanager-0 [3ec312a8-49ee-42cb-a91c-b7e9d302d4ee] in monitoring was DELETED
2025-01-29 22:17:48,281 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-prom-operator-6998896c" duration="6.712µs"
2025-01-29 22:17:48,305 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-kube-state-metrics-5bf5c7b54d" duration="6.712µs"
2025-01-29 22:17:48,332 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="monitoring/monitoring-stack-grafana-64c55fb967" duration="6.452µs"
2025-01-29 22:17:48,657 INFO c.h.h.t.HelmChartContainer - [K3S] [stateful_set.go:466] "StatefulSet has been deleted" key="monitoring/alertmanager-monitoring-stack-kube-prom-alertmanager"
2025-01-29 22:17:48,681 INFO c.h.h.t.HelmChartContainer - [K3S] [stateful_set.go:466] "StatefulSet has been deleted" key="monitoring/prometheus-monitoring-stack-kube-prom-prometheus"
2025-01-29 22:17:49,176 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="3ec312a8-49ee-42cb-a91c-b7e9d302d4ee" path="/var/lib/kubelet/pods/3ec312a8-49ee-42cb-a91c-b7e9d302d4ee/volumes"
2025-01-29 22:17:49,177 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="5ceb77fa-7275-4c75-8edc-277b9ead7e63" path="/var/lib/kubelet/pods/5ceb77fa-7275-4c75-8edc-277b9ead7e63/volumes"
2025-01-29 22:17:49,178 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="788aac66-49cf-4129-be04-1178b7c2a3fd" path="/var/lib/kubelet/pods/788aac66-49cf-4129-be04-1178b7c2a3fd/volumes"
2025-01-29 22:17:49,178 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="bbb8b81c-ba54-4027-96c0-517ac5e6b5b9" path="/var/lib/kubelet/pods/bbb8b81c-ba54-4027-96c0-517ac5e6b5b9/volumes"
2025-01-29 22:17:49,179 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="d5c58d83-8550-4040-ad81-22086cd583ee" path="/var/lib/kubelet/pods/d5c58d83-8550-4040-ad81-22086cd583ee/volumes"
2025-01-29 22:17:49,252 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.250 [pool-6-thread-31] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:17:49,252 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.250 [pool-6-thread-40] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:17:49,252 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.250 [pool-6-thread-40] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:17:49,252 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.251 [pool-6-thread-40] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:17:49,252 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.251 [pool-6-thread-40] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:17:49,258 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.256 [pool-6-thread-31] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status RUNNING (READY)
2025-01-29 22:17:49,265 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.259 [ReconcilerExecutor-hivemq-controller-129] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:17:49,265 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.260 [ReconcilerExecutor-hivemq-controller-129] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status RUNNING - HiveMQ Platform is ready (READY)
2025-01-29 22:17:49,265 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.260 [ReconcilerExecutor-hivemq-controller-129] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:17:49,265 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.261 [ReconcilerExecutor-hivemq-controller-129] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Status (revision: test-hivemq-platform-64db946475, replicas: 2, available: 2, ready: 2, current: 2, updated: 2)
2025-01-29 22:17:49,265 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.261 [ReconcilerExecutor-hivemq-controller-129] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] StatefulSet Spec (replicas: 2, init containers: 1, containers: 1, volumes: 3)
2025-01-29 22:17:49,265 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.264 [ReconcilerExecutor-hivemq-controller-129] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-1' phase Running
2025-01-29 22:17:49,266 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:49.265 [ReconcilerExecutor-hivemq-controller-129] DEBUG c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Pod 'test-hivemq-platform-0' phase Running
2025-01-29 22:17:50,533 INFO c.h.h.t.HelmChartContainer - Deleting namespace 'monitoring'...
2025-01-29 22:17:55,959 INFO c.h.h.t.HelmChartContainer - Namespace 'monitoring' deleted
2025-01-29 22:17:55,959 INFO c.h.h.t.HelmChartContainer - Release 'monitoring-stack' in namespace 'monitoring' is uninstalled
2025-01-29 22:17:55,959 INFO c.h.h.t.HelmChartContainer - Uninstalling release 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'...
2025-01-29 22:17:55,959 DEBUG c.h.h.t.HelmChartContainer - Executing helm command: /bin/helm --kubeconfig /etc/rancher/k3s/k3s.yaml uninstall test-hivemq-platform  --wait --timeout 5m0s --cascade foreground --namespace helmmonitoringplatformit
2025-01-29 22:17:56,230 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.224 [pool-6-thread-42] DEBUG c.h.p.o.d.PlatformServiceResource - [helmmoni] Desired Platform services (3 services)
2025-01-29 22:17:56,231 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.227 [pool-6-thread-41] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (1 extensions) (1 enabled)
2025-01-29 22:17:56,231 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.227 [pool-6-thread-41] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (metrics port: 9399) (metrics path: /)
2025-01-29 22:17:56,231 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.227 [pool-6-thread-41] DEBUG c.h.p.o.dependants.PodInfoConfigMap - [helmmoni] Desired PodInfo ConfigMap (extension state hash: -1817474005)
2025-01-29 22:17:56,234 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.229 [pool-6-thread-49] DEBUG c.h.p.o.d.PodServiceAccountResource - [helmmoni] Desired PodServiceAccountResource (serviceAccountName: hivemq-platform-pod-test-hivemq-platform)
2025-01-29 22:17:56,237 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.234 [pool-6-thread-45] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Desired StatefulSet (2 replicas) for status RUNNING (READY)
2025-01-29 22:17:56,240 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.238 [pool-6-thread-45] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Update StatefulSet (replicas: 2 -> 2)
2025-01-29 22:17:56,246 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.239 [pool-6-thread-45] DEBUG c.h.p.o.d.StatefulSetResource - [helmmoni] Detected change in StatefulSet specification (path: /template/metadata/annotations/kubernetes-resource-versions) (actual value: {broker-configuration-v2=-2089688360}) (target value: {broker-configuration-v2=0})
2025-01-29 22:17:56,246 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.239 [pool-6-thread-45] INFO  c.h.p.o.d.StatefulSetResource - [helmmoni] StatefulSet spec was updated, triggering rolling restart
2025-01-29 22:17:56,314 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.311 [ReconcilerExecutor-hivemq-controller-130] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Reconciling HiveMQ Platform 'test-hivemq-platform' in namespace 'helmmonitoringplatformit'
2025-01-29 22:17:56,314 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.312 [ReconcilerExecutor-hivemq-controller-130] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Status RUNNING - HiveMQ Platform is ready (READY) (reconciliation requests: ROLLING_RESTART, REQUESTS_UPDATED)
2025-01-29 22:17:56,314 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.312 [ReconcilerExecutor-hivemq-controller-130] DEBUG c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Custom Resource Spec (replicas: 2) (extensions: 1)
2025-01-29 22:17:56,314 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.312 [ReconcilerExecutor-hivemq-controller-130] WARN  c.h.p.o.h.HiveMQPlatformReconcilerErrorHandler - [helmmoni] Could not find ConfigMap 'hivemq-configuration-test-hivemq-platform' for HiveMQ Platform configuration
2025-01-29 22:17:56,334 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.333 [ReconcilerExecutor-hivemq-controller-130] DEBUG c.h.p.operator.event.EventSender - [helmmoni] Creating K8s event hivemq-platform-invalid-configuration: [Start] Could not find ConfigMap 'hivemq-configuration-test-hivemq-platform' for HiveMQ Platform configuration
2025-01-29 22:17:56,415 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Start] Could not find ConfigMap 'hivemq-configuration-test-hivemq-platform' for HiveMQ Platform configuration [helmmonitoringplatformit:test-hivemq-platform]
2025-01-29 22:17:56,416 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.415 [ReconcilerExecutor-hivemq-controller-130] INFO  c.h.p.o.h.AbstractHiveMQReconcilerStateHandler - [helmmoni] Update HiveMQ Platform Status (RUNNING [READY] -> ERROR [INVALID_CONFIG_MAP]): Could not find ConfigMap 'hivemq-configuration-test-hivemq-platform' for HiveMQ Platform configuration (reconciliation requests: ROLLING_RESTART)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.424 [ReconcilerExecutor-hivemq-controller-130] ERROR i.j.o.p.event.EventProcessor - Error during event processing ExecutionScope{ resource id: ResourceID{name='test-hivemq-platform', namespace='helmmonitoringplatformit'}, version: 1120}
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: PUT at: https://10.43.0.1:443/apis/hivemq.com/v1/namespaces/helmmonitoringplatformit/hivemq-platforms/test-hivemq-platform/status. Message: Operation cannot be fulfilled on hivemq-platforms.hivemq.com "test-hivemq-platform": the object has been modified; please apply your changes to the latest version and try again. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=hivemq.com, kind=hivemq-platforms, name=test-hivemq-platform, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=Operation cannot be fulfilled on hivemq-platforms.hivemq.com "test-hivemq-platform": the object has been modified; please apply your changes to the latest version and try again, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=Conflict, status=Failure, additionalProperties={}).
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.KubernetesClientException.copyAsCause(KubernetesClientException.java:238)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.waitForResult(OperationSupport.java:507)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.handleResponse(OperationSupport.java:524)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.handleUpdate(OperationSupport.java:358)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.BaseOperation.handleUpdate(BaseOperation.java:759)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.HasMetadataOperation.update(HasMetadataOperation.java:138)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.HasMetadataOperation.update(HasMetadataOperation.java:121)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.HasMetadataOperation.updateStatus(HasMetadataOperation.java:126)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.HasMetadataOperation.updateStatus(HasMetadataOperation.java:44)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.javaoperatorsdk.operator.processing.event.ReconciliationDispatcher$CustomResourceFacade.updateStatus(ReconciliationDispatcher.java:408)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.javaoperatorsdk.operator.processing.event.ReconciliationDispatcher.updateStatusGenerationAware(ReconciliationDispatcher.java:228)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.javaoperatorsdk.operator.processing.event.ReconciliationDispatcher.reconcileExecution(ReconciliationDispatcher.java:150)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.javaoperatorsdk.operator.processing.event.ReconciliationDispatcher.handleReconcile(ReconciliationDispatcher.java:117)
2025-01-29 22:17:56,429 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.javaoperatorsdk.operator.processing.event.ReconciliationDispatcher.handleDispatch(ReconciliationDispatcher.java:91)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.javaoperatorsdk.operator.processing.event.ReconciliationDispatcher.handleExecution(ReconciliationDispatcher.java:64)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.javaoperatorsdk.operator.processing.event.EventProcessor$ReconcilerExecutor.run(EventProcessor.java:452)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.lang.Thread.run(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] Caused by: io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: PUT at: https://10.43.0.1:443/apis/hivemq.com/v1/namespaces/helmmonitoringplatformit/hivemq-platforms/test-hivemq-platform/status. Message: Operation cannot be fulfilled on hivemq-platforms.hivemq.com "test-hivemq-platform": the object has been modified; please apply your changes to the latest version and try again. Received status: Status(apiVersion=v1, code=409, details=StatusDetails(causes=[], group=hivemq.com, kind=hivemq-platforms, name=test-hivemq-platform, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=Operation cannot be fulfilled on hivemq-platforms.hivemq.com "test-hivemq-platform": the object has been modified; please apply your changes to the latest version and try again, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=Conflict, status=Failure, additionalProperties={}).
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.requestFailure(OperationSupport.java:660)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.requestFailure(OperationSupport.java:640)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.assertResponseCode(OperationSupport.java:589)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.lambda$handleResponse$0(OperationSupport.java:549)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture.postComplete(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture.complete(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.http.StandardHttpClient.lambda$completeOrCancel$10(StandardHttpClient.java:141)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture.postComplete(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture.complete(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.http.ByteArrayBodyHandler.onBodyDone(ByteArrayBodyHandler.java:51)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture.postComplete(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at java.base/java.util.concurrent.CompletableFuture.complete(Unknown Source)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.fabric8.kubernetes.client.vertx.VertxHttpRequest.lambda$null$1(VertxHttpRequest.java:121)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:279)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.impl.ContextInternal.dispatch(ContextInternal.java:261)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.http.impl.HttpEventHandler.handleEnd(HttpEventHandler.java:76)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.http.impl.HttpClientResponseImpl.handleEnd(HttpClientResponseImpl.java:250)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.http.impl.Http1xClientConnection$StreamImpl.lambda$new$0(Http1xClientConnection.java:421)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.streams.impl.InboundBuffer.handleEvent(InboundBuffer.java:279)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.streams.impl.InboundBuffer.write(InboundBuffer.java:157)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.http.impl.Http1xClientConnection$StreamImpl.handleEnd(Http1xClientConnection.java:709)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.impl.ContextImpl.execute(ContextImpl.java:313)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.impl.ContextImpl.execute(ContextImpl.java:293)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.http.impl.Http1xClientConnection.handleResponseEnd(Http1xClientConnection.java:940)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.http.impl.Http1xClientConnection.handleHttpMessage(Http1xClientConnection.java:810)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.http.impl.Http1xClientConnection.handleMessage(Http1xClientConnection.java:774)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.net.impl.ConnectionBase.read(ConnectionBase.java:159)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.vertx.core.net.impl.VertxHandler.channelRead(VertxHandler.java:153)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:318)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1475)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1338)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1387)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:530)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:469)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1407)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:918)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
2025-01-29 22:17:56,432 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
2025-01-29 22:17:56,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
2025-01-29 22:17:56,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
2025-01-29 22:17:56,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
2025-01-29 22:17:56,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
2025-01-29 22:17:56,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
2025-01-29 22:17:56,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
2025-01-29 22:17:56,433 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 	... 1 common frames omitted
2025-01-29 22:17:56,438 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:17:56.433 [ReconcilerExecutor-hivemq-controller-138] INFO  c.h.p.o.HiveMQPlatformReconciler - [helmmoni] Cleanup test-hivemq-platform - helmmonitoringplatformit HiveMQ Platform is shut down
2025-01-29 22:17:57,000 INFO c.h.h.t.HelmChartContainer - [K3S] [authentication.go:74] "Unable to authenticate the request" err="[invalid bearer token, serviceaccounts \"hivemq-platform-pod-test-hivemq-platform\" not found]"
2025-01-29 22:17:57,023 INFO c.h.h.t.HelmChartContainer - [K3S] [authentication.go:74] "Unable to authenticate the request" err="[invalid bearer token, serviceaccounts \"hivemq-platform-pod-test-hivemq-platform\" not found]"
2025-01-29 22:17:57,064 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Could not update Pod annotations: Failure executing: GET at: https://10.43.0.1:443/api/v1/namespaces/helmmonitoringplatformit/pods/test-hivemq-platform-0. Message: Unauthorized. Received status: Status(apiVersion=v1, code=401, details=null, kind=Status, message=Unauthorized, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=Unauthorized, status=Failure, additionalProperties={}).
2025-01-29 22:17:57,157 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:17:57,159 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container hivemq [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:17:57,159 INFO c.h.h.t.HelmChartContainer - Received Killing event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:17:57,159 INFO c.h.h.t.HelmChartContainer - Container [test-hivemq-platform-0] [hivemq] [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] was terminated
2025-01-29 22:17:57,161 INFO c.h.h.t.HelmChartContainer - Stopped log watcher for hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:17:57,163 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Shutting down
2025-01-29 22:17:57,164 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Stopping the HiveMQ Platform
2025-01-29 22:17:57,202 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:17:57,211 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container hivemq [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:17:57,212 INFO c.h.h.t.HelmChartContainer - Received Killing event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:17:57,212 INFO c.h.h.t.HelmChartContainer - Container [test-hivemq-platform-1] [hivemq] [c69a8da4-4968-4949-9947-7beef49c4373] was terminated
2025-01-29 22:17:57,212 INFO c.h.h.t.HelmChartContainer - Stopped log watcher for hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:17:57,214 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Shutting down
2025-01-29 22:17:57,214 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Stopping the HiveMQ Platform
2025-01-29 22:17:57,333 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Shutting down HiveMQ. Please wait, this could take a while...
2025-01-29 22:17:57,364 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Shutting down HiveMQ. Please wait, this could take a while...
2025-01-29 22:17:57,368 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Shutting down listeners and clients
2025-01-29 22:17:57,370 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Shutdown of listeners is done
2025-01-29 22:17:57,370 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - No clients are connected, proceeding with shutdown
2025-01-29 22:17:57,416 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Shutting down listeners and clients
2025-01-29 22:17:57,417 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Shutdown of listeners is done
2025-01-29 22:17:57,418 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - No clients are connected, proceeding with shutdown
2025-01-29 22:17:58,332 INFO c.h.h.t.HelmChartContainer - Deleting namespace 'helmmonitoringplatformit'...
2025-01-29 22:17:58,864 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning shutdown Health API response 503 for readiness
2025-01-29 22:17:58,868 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-1]
2025-01-29 22:17:58,868 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373]
2025-01-29 22:17:59,329 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Could not update Pod annotations: Failure executing: GET at: https://10.43.0.1:443/api/v1/namespaces/helmmonitoringplatformit/pods/test-hivemq-platform-1. Message: pods "test-hivemq-platform-1" is forbidden: User "system:serviceaccount:helmmonitoringplatformit:hivemq-platform-pod-test-hivemq-platform" cannot get resource "pods" in API group "" in the namespace "helmmonitoringplatformit". Received status: Status(apiVersion=v1, code=403, details=StatusDetails(causes=[], group=null, kind=pods, name=test-hivemq-platform-1, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=pods "test-hivemq-platform-1" is forbidden: User "system:serviceaccount:helmmonitoringplatformit:hivemq-platform-pod-test-hivemq-platform" cannot get resource "pods" in API group "" in the namespace "helmmonitoringplatformit", metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=Forbidden, status=Failure, additionalProperties={}).
2025-01-29 22:18:00,624 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Shutting down extension system
2025-01-29 22:18:00,626 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Stopping extension with id hivemq-dns-cluster-discovery
2025-01-29 22:18:00,627 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Extension "DNS Cluster Discovery Extension" version 4.3.2 stopped successfully.
2025-01-29 22:18:00,628 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Stopping extension with id hivemq-prometheus-extension
2025-01-29 22:18:00,631 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Extension "Prometheus Monitoring Extension" version 4.0.12 stopped successfully.
2025-01-29 22:18:00,631 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Stopping extension with id hivemq-allow-all-extension
2025-01-29 22:18:00,632 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Extension "Allow All Extension" version 1.1.1 stopped successfully.
2025-01-29 22:18:00,639 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Cluster nodes found by discovery: [DvxZU|2] (1) [DvxZU].
2025-01-29 22:18:00,643 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Cluster size = 1, members : [DvxZU].
2025-01-29 22:18:00,757 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Shutting down extension system
2025-01-29 22:18:00,815 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Stopping extension with id hivemq-dns-cluster-discovery
2025-01-29 22:18:00,816 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Extension "DNS Cluster Discovery Extension" version 4.3.2 stopped successfully.
2025-01-29 22:18:00,816 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Stopping extension with id hivemq-prometheus-extension
2025-01-29 22:18:00,819 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Extension "Prometheus Monitoring Extension" version 4.0.12 stopped successfully.
2025-01-29 22:18:00,820 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Stopping extension with id hivemq-allow-all-extension
2025-01-29 22:18:00,820 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Extension "Allow All Extension" version 1.1.1 stopped successfully.
2025-01-29 22:18:00,921 INFO c.h.h.t.HelmChartContainer - [K3S] [namespace_controller.go:187] "Namespace has been deleted" namespace="monitoring"
2025-01-29 22:18:01,422 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Returning shutdown Health API response 503 for readiness
2025-01-29 22:18:01,426 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: HTTP probe failed with statuscode: 503 [helmmonitoringplatformit:test-hivemq-platform-0]
2025-01-29 22:18:01,426 INFO c.h.h.t.HelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276]
2025-01-29 22:18:02,068 INFO c.h.h.t.HelmChartContainer - [K3S] [authentication.go:74] "Unable to authenticate the request" err="[invalid bearer token, serviceaccounts \"hivemq-platform-pod-test-hivemq-platform\" not found]"
2025-01-29 22:18:02,083 INFO c.h.h.t.HelmChartContainer - [K3S] [authentication.go:74] "Unable to authenticate the request" err="[invalid bearer token, serviceaccounts \"hivemq-platform-pod-test-hivemq-platform\" not found]"
2025-01-29 22:18:02,085 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] WARN  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Could not update Pod annotations: Failure executing: GET at: https://10.43.0.1:443/api/v1/namespaces/helmmonitoringplatformit/pods/test-hivemq-platform-0. Message: Unauthorized. Received status: Status(apiVersion=v1, code=401, details=null, kind=Status, message=Unauthorized, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=Unauthorized, status=Failure, additionalProperties={}).
2025-01-29 22:18:02,966 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - Shutdown completed.
2025-01-29 22:18:03,119 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - Shutdown completed.
2025-01-29 22:18:03,315 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] The HiveMQ Platform exited with code 143
2025-01-29 22:18:03,315 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Stopping the REST API
2025-01-29 22:18:03,359 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [2eec4b6e] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Shutdown complete
2025-01-29 22:18:03,475 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] The HiveMQ Platform exited with code 143
2025-01-29 22:18:03,475 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Stopping the REST API
2025-01-29 22:18:03,486 INFO c.h.h.t.HelmChartContainer - [K3S] [stateful_set.go:466] "StatefulSet has been deleted" key="helmmonitoringplatformit/test-hivemq-platform"
2025-01-29 22:18:03,518 INFO c.h.h.t.HelmChartContainer - [test-hivemq-platform] [hivemq] [c69a8da4] INFO  - [HiveMQ Platform Operator Init App 1.7.0-SNAPSHOT] Shutdown complete
2025-01-29 22:18:03,866 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:18:03,899 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"broker-configuration\" (UniqueName: \"kubernetes.io/configmap/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-broker-configuration\") pod \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\" (UID: \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\") "
2025-01-29 22:18:03,899 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"pod-info\" (UniqueName: \"kubernetes.io/configmap/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-pod-info\") pod \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\" (UID: \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\") "
2025-01-29 22:18:03,899 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"operator-init\" (UniqueName: \"kubernetes.io/empty-dir/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-operator-init\") pod \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\" (UID: \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\") "
2025-01-29 22:18:03,900 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-gvp74\" (UniqueName: \"kubernetes.io/projected/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-kube-api-access-gvp74\") pod \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\" (UID: \"2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276\") "
2025-01-29 22:18:03,958 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:18:04,000 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"pod-info\" (UniqueName: \"kubernetes.io/configmap/c69a8da4-4968-4949-9947-7beef49c4373-pod-info\") pod \"c69a8da4-4968-4949-9947-7beef49c4373\" (UID: \"c69a8da4-4968-4949-9947-7beef49c4373\") "
2025-01-29 22:18:04,000 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"operator-init\" (UniqueName: \"kubernetes.io/empty-dir/c69a8da4-4968-4949-9947-7beef49c4373-operator-init\") pod \"c69a8da4-4968-4949-9947-7beef49c4373\" (UID: \"c69a8da4-4968-4949-9947-7beef49c4373\") "
2025-01-29 22:18:04,000 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"broker-configuration\" (UniqueName: \"kubernetes.io/configmap/c69a8da4-4968-4949-9947-7beef49c4373-broker-configuration\") pod \"c69a8da4-4968-4949-9947-7beef49c4373\" (UID: \"c69a8da4-4968-4949-9947-7beef49c4373\") "
2025-01-29 22:18:04,000 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-qk5h9\" (UniqueName: \"kubernetes.io/projected/c69a8da4-4968-4949-9947-7beef49c4373-kube-api-access-qk5h9\") pod \"c69a8da4-4968-4949-9947-7beef49c4373\" (UID: \"c69a8da4-4968-4949-9947-7beef49c4373\") "
2025-01-29 22:18:04,000 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-gvp74\" (UniqueName: \"kubernetes.io/projected/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-kube-api-access-gvp74\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:18:04,001 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"broker-configuration\" (UniqueName: \"kubernetes.io/configmap/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-broker-configuration\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:18:04,001 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"operator-init\" (UniqueName: \"kubernetes.io/empty-dir/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-operator-init\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:18:04,001 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"pod-info\" (UniqueName: \"kubernetes.io/configmap/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276-pod-info\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:18:04,100 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"pod-info\" (UniqueName: \"kubernetes.io/configmap/c69a8da4-4968-4949-9947-7beef49c4373-pod-info\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:18:04,100 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"operator-init\" (UniqueName: \"kubernetes.io/empty-dir/c69a8da4-4968-4949-9947-7beef49c4373-operator-init\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:18:04,100 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"broker-configuration\" (UniqueName: \"kubernetes.io/configmap/c69a8da4-4968-4949-9947-7beef49c4373-broker-configuration\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:18:04,100 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-qk5h9\" (UniqueName: \"kubernetes.io/projected/c69a8da4-4968-4949-9947-7beef49c4373-kube-api-access-qk5h9\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:18:04,628 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="2f06588e9030cff62ea35784cee50e2023100ea9d8c4b2bd02d90c4fe4833c16"
2025-01-29 22:18:04,644 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:18:04,647 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-0 [2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276] in helmmonitoringplatformit was DELETED
2025-01-29 22:18:04,656 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was MODIFIED
2025-01-29 22:18:04,664 INFO c.h.h.t.HelmChartContainer - [POD] test-hivemq-platform-1 [c69a8da4-4968-4949-9947-7beef49c4373] in helmmonitoringplatformit was DELETED
2025-01-29 22:18:04,731 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="92403e6a747c8e905f6e6490240f8a91bddd085294701fce413bbc7d52b59a3a"
2025-01-29 22:18:04,734 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="2f06588e9030cff62ea35784cee50e2023100ea9d8c4b2bd02d90c4fe4833c16"
2025-01-29 22:18:04,734 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="92403e6a747c8e905f6e6490240f8a91bddd085294701fce413bbc7d52b59a3a"
2025-01-29 22:18:04,735 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="03dfe32b2dcd2009a7e17961781ad6868f07babe0b8dc3b28bca0d881b574769"
2025-01-29 22:18:04,840 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="8bc8920b5e45f6212dbd6ed671337d5db5b767d676db144b78dd6897bbe47047"
2025-01-29 22:18:04,844 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="03dfe32b2dcd2009a7e17961781ad6868f07babe0b8dc3b28bca0d881b574769"
2025-01-29 22:18:04,844 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="8bc8920b5e45f6212dbd6ed671337d5db5b767d676db144b78dd6897bbe47047"
2025-01-29 22:18:05,176 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276" path="/var/lib/kubelet/pods/2eec4b6e-b7b4-4fcd-b5c9-3ebed3b28276/volumes"
2025-01-29 22:18:05,176 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="c69a8da4-4968-4949-9947-7beef49c4373" path="/var/lib/kubelet/pods/c69a8da4-4968-4949-9947-7beef49c4373/volumes"
2025-01-29 22:18:08,768 INFO c.h.h.t.HelmChartContainer - Namespace 'helmmonitoringplatformit' deleted
2025-01-29 22:18:08,768 INFO c.h.h.t.HelmChartContainer - Release 'test-hivemq-platform' in namespace 'helmmonitoringplatformit' is uninstalled
2025-01-29 22:18:08,768 INFO c.h.h.t.HelmChartContainer - Uninstalling release 'test-hivemq-platform-operator' in namespace 'helmmonitoringplatformit-operator'...
2025-01-29 22:18:08,768 DEBUG c.h.h.t.HelmChartContainer - Executing helm command: /bin/helm --kubeconfig /etc/rancher/k3s/k3s.yaml uninstall test-hivemq-platform-operator  --wait --timeout 5m0s --cascade foreground --namespace helmmonitoringplatformit-operator
2025-01-29 22:18:08,943 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="9.828227ms"
2025-01-29 22:18:08,944 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="86.351µs"
2025-01-29 22:18:08,958 INFO c.h.h.t.HelmChartContainer - [POD] hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0] in helmmonitoringplatformit-operator was MODIFIED
2025-01-29 22:18:08,968 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Killing] Stopping container hivemq-platform-operator [helmmonitoringplatformit-operator:hivemq-test-hivemq-platform-operator-6966f96d65-4twfq]
2025-01-29 22:18:08,968 INFO c.h.h.t.HelmChartContainer - Received Killing event for container hivemq-platform-operator in pod hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0]
2025-01-29 22:18:08,968 INFO c.h.h.t.HelmChartContainer - Container [hivemq-test-hivemq-platform-operator-6966f96d65-4twfq] [hivemq-platform-operator] [a139d8e3-b51a-4b68-8772-4b488907f5e0] was terminated
2025-01-29 22:18:08,968 INFO c.h.h.t.HelmChartContainer - Stopped log watcher for hivemq-platform-operator in pod hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0]
2025-01-29 22:18:08,971 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="9.792959ms"
2025-01-29 22:18:08,972 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="41.468µs"
2025-01-29 22:18:08,975 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:18:08.973 [application-shutdown-thread] INFO  c.h.p.o.HiveMQPlatformOperatorApplication - HiveMQ Platform Operator is stopping...
2025-01-29 22:18:08,975 INFO c.h.h.t.HelmChartContainer - [hivemq-test-hivemq-platform] [hivemq-platform-operator] [a139d8e3] 22:18:08.973 [application-shutdown-thread] INFO  i.javaoperatorsdk.operator.Operator - Operator SDK 4.9.7 is shutting down...
2025-01-29 22:18:09,506 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="43.381µs"
2025-01-29 22:18:09,507 INFO c.h.h.t.HelmChartContainer - [POD] hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0] in helmmonitoringplatformit-operator was MODIFIED
2025-01-29 22:18:09,628 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-t75p4\" (UniqueName: \"kubernetes.io/projected/a139d8e3-b51a-4b68-8772-4b488907f5e0-kube-api-access-t75p4\") pod \"a139d8e3-b51a-4b68-8772-4b488907f5e0\" (UID: \"a139d8e3-b51a-4b68-8772-4b488907f5e0\") "
2025-01-29 22:18:09,639 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="bbc8dc2d4fddd40953aeb93c340472f1dca0f89c27b803554f2be89581a9a936"
2025-01-29 22:18:09,643 INFO c.h.h.t.HelmChartContainer - [K3S] [scope.go:117] "RemoveContainer" containerID="bbc8dc2d4fddd40953aeb93c340472f1dca0f89c27b803554f2be89581a9a936"
2025-01-29 22:18:09,651 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="39.774µs"
2025-01-29 22:18:09,652 INFO c.h.h.t.HelmChartContainer - [POD] hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0] in helmmonitoringplatformit-operator was MODIFIED
2025-01-29 22:18:09,653 INFO c.h.h.t.HelmChartContainer - [POD] hivemq-test-hivemq-platform-operator-6966f96d65-4twfq [a139d8e3-b51a-4b68-8772-4b488907f5e0] in helmmonitoringplatformit-operator was DELETED
2025-01-29 22:18:09,655 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="24.166µs"
2025-01-29 22:18:09,665 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="helmmonitoringplatformit-operator/hivemq-test-hivemq-platform-operator-6966f96d65" duration="7.264µs"
2025-01-29 22:18:09,729 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:299] "Volume detached for volume \"kube-api-access-t75p4\" (UniqueName: \"kubernetes.io/projected/a139d8e3-b51a-4b68-8772-4b488907f5e0-kube-api-access-t75p4\") on node \"0cdda8541101\" DevicePath \"\""
2025-01-29 22:18:10,992 INFO c.h.h.t.HelmChartContainer - Deleting namespace 'helmmonitoringplatformit-operator'...
2025-01-29 22:18:11,175 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="a139d8e3-b51a-4b68-8772-4b488907f5e0" path="/var/lib/kubelet/pods/a139d8e3-b51a-4b68-8772-4b488907f5e0/volumes"
2025-01-29 22:18:13,665 INFO c.h.h.t.HelmChartContainer - [K3S] [namespace_controller.go:187] "Namespace has been deleted" namespace="helmmonitoringplatformit"
2025-01-29 22:18:16,212 INFO c.h.h.t.HelmChartContainer - Namespace 'helmmonitoringplatformit-operator' deleted
2025-01-29 22:18:16,212 INFO c.h.h.t.HelmChartContainer - Release 'test-hivemq-platform-operator' in namespace 'helmmonitoringplatformit-operator' is uninstalled
2025-01-29 22:18:17,456 INFO c.h.helmcharts.AbstractHelmChartIT - Removed unused containers:

2025-01-29 22:18:21,158 INFO c.h.h.t.HelmChartContainer - [K3S] [namespace_controller.go:187] "Namespace has been deleted" namespace="helmmonitoringplatformit-operator"
2025-01-29 22:18:32,779 INFO c.h.helmcharts.AbstractHelmChartIT - Removed unused snapshots:
Removing snapshot sha256:03af251906410714c5aef9fa705b63f6bbc39c4a5e787de7361eeb18886c2ed2
Removing snapshot sha256:0c46b3b43cce082ce5ec34ffc6c294e0417d17b9d1e6f366d114b6aadc4f96dc
Removing snapshot sha256:0ce761beee59082d6ed5bcebd3a805b8ddd9b3426b617e4809e7fb7c6587ffec
Removing snapshot sha256:0df91287303208332c8ff6ba40ae4710105201739addbfbddfb955f1ad593664
Removing snapshot sha256:0f30b4526626599ad6853b13d715ed5f11e4dac30bdf22795ee36d8b73285c01
Removing snapshot sha256:1021ef88c7974bfff89c5a0ec4fd3160daac6c48a075f74cff721f85dd104e68
Removing snapshot sha256:10aba4953ddc18145dd38e3704709bc464aa20af60b56fe52caaff4b68411e62
Removing snapshot sha256:17b3230dbaa15b80ea4c59d385a510a1c6c669d654d4445b25f4122988ddf932
Removing snapshot sha256:1ab0a79eb9ae3bab99382d18e27cb1c587196d2929db9c8d1c79088bd5a8fa18
Removing snapshot sha256:1e604deea57dbda554a168861cff1238f93b8c6c69c863c43aed37d9d99c5fed
Removing snapshot sha256:2330d1b95992fe4dfdab1ed70e86e349f3f37a80a92140a1ec441a9c3169bcb7
Removing snapshot sha256:2573e0d8158209ed54ab25c87bcdcb00bd3d2539246960a3d592a1c599d70465
Removing snapshot sha256:3102b3958924e454ee4c19fe49136c5727bea4a438945b9d85ed7525ae7ad17a
Removing snapshot sha256:362a8a37f8bbc31925a8146adcf7cf51f9882f5c1dcbef67c5baa03a297543c0
Removing snapshot sha256:371a4f848700cbcc1dd3002bda74c8865f57c7f7f3a3141ab9b131acc3bc33c8
Removing snapshot sha256:38300cd41e4e7621f1880dc17df1510a0b41c3700bba086c7d13695c2852c906
Removing snapshot sha256:3aea2e5ee60f1f0173fafb64e361c34847c160a755964b223b571f112b206391
Removing snapshot sha256:3d737060823899829eb7827e20ddb4021f5c31c4e7e348a380b528903c9051ae
Removing snapshot sha256:42508696bab4cddb098661270605482768f11b222c3b338a84e17c388a573539
Removing snapshot sha256:42b3566bfb67a7e1e92c7fb9a9d9fd9d5d1c68fb9234b2e7e8d57e3894c584c6
Removing snapshot sha256:43a7c979bbaba6838bc3102d6b10a1459f3ab050b87ccdfef84ef90cf43d3058
Removing snapshot sha256:43e32e0401181ce446773595aa5b45dd3de52a62bd17ce6321e472661bef46fc
Removing snapshot sha256:48b6a6f6ccdf8122eac27190b84b40cf2052a9a05edbe309b4a1479b45695bfb
Removing snapshot sha256:4ab04491cdf0d3267f08206fe30bd48f49f94b9cab2f016d6739220f722a64af
Removing snapshot sha256:4b6068250e89c96f263060261819c7d912855bfbd64b3eb4c4a8483299b8c295
Removing snapshot sha256:4e4a4c2a9fcafd941707917d9cb4c348229dcda7e6a77d20a5c9e977659e2acb
Removing snapshot sha256:580e69a0a8034ede1921139bbd2bfb72a69ebf276d008281896c32dd8bf74775
Removing snapshot sha256:597fcac6b802be96dede6dae530b1fd3d80ee2191e3c39bd5c3dfb528309801e
Removing snapshot sha256:59860db8e524598ca0913cb5a7821a1a1c1e56f61dec4fe619ad8a278bfd44c2
Removing snapshot sha256:5a9ba96b94a7acc2c16f45d7113265f2705262d850ff8d73abf339acec4e4283
Removing snapshot sha256:5d30ba46b27fe37484567ccc5242cadc78217b8da605f3f195ef25cbf7487904
Removing snapshot sha256:63ca1fbb43ae5034640e5e6cb3e083e05c290072c5366fcaa9d62435a4cced85
Removing snapshot sha256:67f702c6baae873bceb19487c8b1f27bd2b86077e4f2f0e480e6d60ab508b8f5
Removing snapshot sha256:6864348dd42806d552efdec384f1274be15e2d0c10ce44c1f04347af004c10a9
Removing snapshot sha256:6c7dee8f2c39b84b7dc2711c01d33de93514d9055499173e9290176fbe484b6c
Removing snapshot sha256:6d2198b9bba47eb108a6f8e064d85edb59b204d24ceb4d866ad96079b9ec1498
Removing snapshot sha256:70c2ac7e5c63dab7e94a930dcf8575d71310cda1135a561202a40d254f4125c5
Removing snapshot sha256:711f0795be2fadadbf9fe1151ea3506c44bc3c41083e049b25f8bac1bd91851c
Removing snapshot sha256:74acea72c72664d31caa1810182a8d9f76600a5e41ed9d1eb2814c0bc090bfea
Removing snapshot sha256:75654b8eeebd3beae97271a102f57cdeb794cc91e442648544963a7e951e9558
Removing snapshot sha256:783ad6a93b23221db9f18c15f79aeb134655b6dd29a9a9bc7472ee50852d14a7
Removing snapshot sha256:81ed7e1a344eefb04664b5d772157e32be190d566bd3083af46ec0b8796ae9ae
Removing snapshot sha256:82753493a6d61ded36556292f02f31841a14c20d2f279f19eaad65afb661d5cd
Removing snapshot sha256:84a897f1c589cde259313d1efcd537ab957267a6526caa797d9703c4ee903204
Removing snapshot sha256:8a10d3db42c505ee0fcfa98417bdd7e39b304f6bcc0a06bb1b220797ff2cc63c
Removing snapshot sha256:8d297423f53775a6b77d49e57a5e9f47799fcfddca869a1164226d56c8299763
Removing snapshot sha256:8ec1e08a6c109c9698b32f46974375ee19470c62a5de0618346b3b4442919582
Removing snapshot sha256:94b728d964f60c89faa32d3296c8e524b6a15c163f95728001c8be4091968231
Removing snapshot sha256:9852f74557303324154e94d69646a117800c24f830d6dd3150a61f1cb1877bfb
Removing snapshot sha256:a21e5b12dbac529ad45d976eb9ce45c881f3bedcc500fb30aba1e52aa1813418
Removing snapshot sha256:afb9d24a81528af822cc0a49b79c922afd1b6fb3355f0fe3683749f5ad2e2e5e
Removing snapshot sha256:b403bf5671b66322a4fb4fcf772687a9e487ab58804584befcae862807d8eb88
Removing snapshot sha256:b8c8d85687c0d5b64887dfaf35dedad43ecac3954a798ffa91d79a5aeb500496
Removing snapshot sha256:b921e6c28969094157f9b8e7244677780319637afd14450b7cb6b2fdea558a0c
Removing snapshot sha256:bc27ecb5769a00e309cf99ebc763c4a4b958b618d1decc96ffac5bc05f02f5b7
Removing snapshot sha256:be3ccb6627a5332e309d45ef461d09b4879dd870c7394d89323d0ebc6ca6aa8a
Removing snapshot sha256:c261f7cbbc64211ee175ee47273acdb7b1a36a4450b397a064a8f2c026490095
Removing snapshot sha256:c34d9393647eea0c9e3557ab988efaf59f61d10a2a5613b439ef0958cca5ec10
Removing snapshot sha256:ccf3c4a0fa967a41c1c83497a2ce6fa5787965859df0adb32c4ca2cf7490bc2b
Removing snapshot sha256:cda334c60720b02c295deeee0739beb29d9283df72a19f0e73b54e50c89e8c00
Removing snapshot sha256:cf92d33f869417309692088c341cd0f223c178ea78a125f757317b22aa8f90e9
Removing snapshot sha256:d0037344cf2fb078884f1849f6a1f8cf9a33a3b6139b6a85833e5ee528e1f9a8
Removing snapshot sha256:d3b36d5b79273b1e98e7700470eaeff05a882e777124d84cebcc1505b85ecb36
Removing snapshot sha256:d65a44a37914602d12c611e5e22a50f11451d847e63015cc1c2aef92dee777a4
Removing snapshot sha256:d7698055289ea72fad6a712ae4a30a02f6f294e476718fac7d5eea9098793d8e
Removing snapshot sha256:deb8fe0e16fb632523b566bfa4819d4c8b7689407d4211b88d26b6988d84ef75
Removing snapshot sha256:e2dc0bae2455930f23ae570e019b7f32edc75c0f2d71cab084db837ff9051796
Removing snapshot sha256:e58151b46376c08fb48e2a2fbe134b6de223be0749d20b7b60bf475e526a2884
Removing snapshot sha256:eccbd24a99c60cd9e86ee5305dbfc4a4dc89f5ab4fb1f06c8d64797cecedef34
Removing snapshot sha256:f144bb4c7c7f0d2aa7eeffd36d934ec40db1ee167be727e326aad9fdc616f475

]]></system-out>
  </testcase>
  <system-out><![CDATA[2025-01-29 22:13:55,918 INFO c.h.h.t.HelmChartContainerExtension - Using cached HelmChartContainer instance
2025-01-29 22:13:55,925 INFO c.h.h.t.HelmChartContainerExtension - Creating cached HelmChartContainer instance
2025-01-29 22:13:55,942 INFO o.testcontainers.DockerClientFactory - Testcontainers version: 1.20.4
2025-01-29 22:13:56,374 INFO o.t.d.DockerClientProviderStrategy - Found Docker environment with local Unix socket (unix:///var/run/docker.sock)
2025-01-29 22:13:56,384 INFO o.testcontainers.DockerClientFactory - Docker host IP address is localhost
2025-01-29 22:13:56,400 INFO o.testcontainers.DockerClientFactory - Connected to docker: 
  Server Version: 26.1.3
  API Version: 1.45
  Operating System: Ubuntu 24.04.1 LTS
  Total Memory: 15990 MB
2025-01-29 22:13:56,407 INFO o.testcontainers.images.PullPolicy - Image pull policy will be performed by: DefaultPullPolicy()
2025-01-29 22:13:56,409 INFO o.t.utility.ImageNameSubstitutor - Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')
2025-01-29 22:13:56,434 INFO tc.testcontainers/ryuk:0.11.0 - Pulling docker image: testcontainers/ryuk:0.11.0. Please be patient; this may take some time but only needs to be done once.
2025-01-29 22:13:57,438 INFO tc.testcontainers/ryuk:0.11.0 - Starting to pull image
2025-01-29 22:13:57,451 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  0 downloaded,  0 extracted, (0 bytes/0 bytes)
2025-01-29 22:13:57,996 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  2 pending,  1 downloaded,  0 extracted, (3 MB/? MB)
2025-01-29 22:13:58,006 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  1 pending,  2 downloaded,  0 extracted, (4 MB/? MB)
2025-01-29 22:13:58,041 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  3 downloaded,  0 extracted, (4 MB/10 MB)
2025-01-29 22:13:58,098 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  3 downloaded,  1 extracted, (4 MB/10 MB)
2025-01-29 22:13:58,249 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  3 downloaded,  2 extracted, (4 MB/10 MB)
2025-01-29 22:13:58,292 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  3 downloaded,  3 extracted, (10 MB/10 MB)
2025-01-29 22:13:58,298 INFO tc.testcontainers/ryuk:0.11.0 - Image testcontainers/ryuk:0.11.0 pull took PT1.863657454S
2025-01-29 22:13:58,314 INFO tc.testcontainers/ryuk:0.11.0 - Creating container for image: testcontainers/ryuk:0.11.0
2025-01-29 22:13:58,379 INFO tc.testcontainers/ryuk:0.11.0 - Container testcontainers/ryuk:0.11.0 is starting: 554bab12fd204b9da24abf455037efab6396245e13df1571bbdfcd3ecf2af340
2025-01-29 22:13:58,611 INFO tc.testcontainers/ryuk:0.11.0 - Container testcontainers/ryuk:0.11.0 started in PT0.297211197S
2025-01-29 22:13:58,615 INFO o.t.utility.RyukResourceReaper - Ryuk started - will monitor and terminate Testcontainers containers on JVM exit
2025-01-29 22:13:58,615 INFO o.testcontainers.DockerClientFactory - Checking the system...
2025-01-29 22:13:58,615 INFO o.testcontainers.DockerClientFactory - ✔︎ Docker server version should be at least 1.6.0
2025-01-29 22:13:58,693 INFO o.t.i.builder.ImageFromDockerfile - Pre-emptively checking local images for 'ubuntu:noble-20241118.1@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab', referenced via a Dockerfile. If not available, it will be pulled.
2025-01-29 22:13:58,696 INFO t.u.1@sha256:80dd3c... - Pulling docker image: ubuntu:noble-20241118.1@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab. Please be patient; this may take some time but only needs to be done once.
2025-01-29 22:13:59,393 INFO t.u.1@sha256:80dd3c... - Starting to pull image
2025-01-29 22:13:59,394 INFO t.u.1@sha256:80dd3c... - Pulling image layers:  0 pending,  0 downloaded,  0 extracted, (0 bytes/0 bytes)
2025-01-29 22:14:00,518 INFO t.u.1@sha256:80dd3c... - Pulling image layers:  0 pending,  1 downloaded,  0 extracted, (25 MB/28 MB)
2025-01-29 22:14:01,456 INFO t.u.1@sha256:80dd3c... - Pulling image layers:  0 pending,  1 downloaded,  1 extracted, (28 MB/28 MB)
2025-01-29 22:14:01,463 INFO t.u.1@sha256:80dd3c... - Image ubuntu:noble-20241118.1@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab pull took PT2.766459493S
2025-01-29 22:14:01,463 INFO t.u.1@sha256:80dd3c... - Pull complete. 1 layers, pulled in 2s (downloaded 28 MB at 14 MB/s)
2025-01-29 22:14:01,465 INFO o.t.i.builder.ImageFromDockerfile - Pre-emptively checking local images for 'rancher/k3s:v1.32.1-k3s1', referenced via a Dockerfile. If not available, it will be pulled.
2025-01-29 22:14:01,467 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pulling docker image: rancher/k3s:v1.32.1-k3s1. Please be patient; this may take some time but only needs to be done once.
2025-01-29 22:14:02,465 INFO tc.rancher/k3s:v1.32.1-k3s1 - Starting to pull image
2025-01-29 22:14:02,466 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pulling image layers:  0 pending,  0 downloaded,  0 extracted, (0 bytes/0 bytes)
2025-01-29 22:14:03,785 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pulling image layers:  0 pending,  1 downloaded,  0 extracted, (62 MB/71 MB)
2025-01-29 22:14:04,832 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pulling image layers:  0 pending,  1 downloaded,  1 extracted, (71 MB/71 MB)
2025-01-29 22:14:04,839 INFO tc.rancher/k3s:v1.32.1-k3s1 - Image rancher/k3s:v1.32.1-k3s1 pull took PT3.371710854S
2025-01-29 22:14:04,839 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pull complete. 1 layers, pulled in 2s (downloaded 71 MB at 35 MB/s)
2025-01-29 22:14:04,845 INFO o.t.i.builder.ImageFromDockerfile - Transferred 0 bytes to Docker daemon
2025-01-29 22:14:23,020 INFO c.h.h.t.HelmChartContainer - Starting HelmChartContainer...
2025-01-29 22:14:23,022 INFO t.localhost/testcontainers/cqsek1zageikehvd:latest - Creating container for image: localhost/testcontainers/cqsek1zageikehvd:latest
2025-01-29 22:14:23,095 INFO tc.alpine:3.17 - Pulling docker image: alpine:3.17. Please be patient; this may take some time but only needs to be done once.
2025-01-29 22:14:24,067 INFO tc.alpine:3.17 - Starting to pull image
2025-01-29 22:14:24,068 INFO tc.alpine:3.17 - Pulling image layers:  0 pending,  0 downloaded,  0 extracted, (0 bytes/0 bytes)
2025-01-29 22:14:24,631 INFO tc.alpine:3.17 - Pulling image layers:  0 pending,  1 downloaded,  0 extracted, (3 MB/3 MB)
2025-01-29 22:14:24,732 INFO tc.alpine:3.17 - Pulling image layers:  0 pending,  1 downloaded,  1 extracted, (3 MB/3 MB)
2025-01-29 22:14:24,739 INFO tc.alpine:3.17 - Image alpine:3.17 pull took PT1.643910256S
2025-01-29 22:14:25,280 INFO t.localhost/testcontainers/cqsek1zageikehvd:latest - Container localhost/testcontainers/cqsek1zageikehvd:latest is starting: 0cdda8541101d0ce8ba17f2fe9796e441c66cb8a6cad5d6eaca3f92ce5d8dc21
2025-01-29 22:14:25,657 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting k3s v1.32.1+k3s1 (6a322f12)
2025-01-29 22:14:25,659 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Configuring sqlite3 database connection pooling: maxIdleConns=2, maxOpenConns=0, connMaxLifetime=0s
2025-01-29 22:14:25,660 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Configuring database table schema and indexes, this may take a moment...
2025-01-29 22:14:25,663 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Database tables and indexes are up to date
2025-01-29 22:14:25,666 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Kine available at unix://kine.sock
2025-01-29 22:14:25,774 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Saving cluster bootstrap data to datastore
2025-01-29 22:14:25,775 INFO c.h.h.t.HelmChartContainer - [K3S] [WARNING] dynamiclistener [::]:6443: no cached certificate available for preload - deferring certificate load until storage initialization or first client request
2025-01-29 22:14:25,776 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Active TLS secret / (ver=) (count 10): map[listener.cattle.io/cn-0cdda8541101:0cdda8541101 listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.18.0.2:172.18.0.2 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=02E798FB12988A40C9735A518FF8ACFC39572397]
2025-01-29 22:14:25,935 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Running kube-apiserver --advertise-port=6443 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,k3s --authorization-mode=Node,RBAC --bind-address=127.0.0.1 --cert-dir=/var/lib/rancher/k3s/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/k3s/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/k3s/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --etcd-compaction-interval=0s --etcd-servers=unix://kine.sock --kubelet-certificate-authority=/var/lib/rancher/k3s/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/k3s/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/k3s/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/k3s/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/k3s/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/k3s/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6444 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/k3s/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/k3s/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.key
2025-01-29 22:14:25,937 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Running kube-scheduler --authentication-kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --authorization-kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --bind-address=127.0.0.1 --kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --leader-elect=false --profiling=false --secure-port=10259
2025-01-29 22:14:25,937 INFO c.h.h.t.HelmChartContainer - [K3S] [registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
2025-01-29 22:14:25,938 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Running kube-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/k3s/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/k3s/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/k3s/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/k3s/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --leader-elect=false --profiling=false --root-ca-file=/var/lib/rancher/k3s/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/k3s/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true
2025-01-29 22:14:25,940 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Waiting for API server to become available
2025-01-29 22:14:25,941 INFO c.h.h.t.HelmChartContainer - [K3S] [options.go:299] unable to set WatchListClient feature gate, err: cannot override default for feature "WatchListClient": gates already added to a flag set
2025-01-29 22:14:25,941 INFO c.h.h.t.HelmChartContainer - [K3S] [registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
2025-01-29 22:14:25,942 INFO c.h.h.t.HelmChartContainer - [K3S] [options.go:238] external host was not specified, using 172.18.0.2
2025-01-29 22:14:25,942 INFO c.h.h.t.HelmChartContainer - [K3S] [registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
2025-01-29 22:14:25,943 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Running cloud-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/k3s/server/cred/cloud-controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/k3s/server/cred/cloud-controller.kubeconfig --bind-address=127.0.0.1 --cloud-config=/var/lib/rancher/k3s/server/etc/cloud-config.yaml --cloud-provider=k3s --cluster-cidr=10.42.0.0/16 --configure-cloud-routes=false --controllers=*,-route --kubeconfig=/var/lib/rancher/k3s/server/cred/cloud-controller.kubeconfig --leader-elect=false --leader-elect-resource-name=k3s-cloud-controller-manager --node-status-update-frequency=1m0s --profiling=false
2025-01-29 22:14:25,943 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Server node token is available at /var/lib/rancher/k3s/server/token
2025-01-29 22:14:25,943 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] To join server node to cluster: k3s server -s https://172.18.0.2:6443 -t ${SERVER_NODE_TOKEN}
2025-01-29 22:14:25,943 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Agent node token is available at /var/lib/rancher/k3s/server/agent-token
2025-01-29 22:14:25,944 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] To join agent node to cluster: k3s agent -s https://172.18.0.2:6443 -t ${AGENT_NODE_TOKEN}
2025-01-29 22:14:25,944 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Wrote kubeconfig /etc/rancher/k3s/k3s.yaml
2025-01-29 22:14:25,944 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Run: k3s kubectl
2025-01-29 22:14:25,944 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:151] Version: v1.32.1+k3s1
2025-01-29 22:14:25,944 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:153] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 22:14:26,328 INFO c.h.h.t.HelmChartContainer - [K3S] [plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionPolicy,MutatingAdmissionWebhook.
2025-01-29 22:14:26,329 INFO c.h.h.t.HelmChartContainer - [K3S] [plugins.go:160] Loaded 13 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,ClusterTrustBundleAttest,CertificateSubjectRestriction,ValidatingAdmissionPolicy,ValidatingAdmissionWebhook,ResourceQuota.
2025-01-29 22:14:26,329 INFO c.h.h.t.HelmChartContainer - [K3S] [instance.go:233] Using reconciler: lease
2025-01-29 22:14:26,383 INFO c.h.h.t.HelmChartContainer - [K3S] [apis.go:106] API group "internal.apiserver.k8s.io" is not enabled, skipping.
2025-01-29 22:14:26,428 INFO c.h.h.t.HelmChartContainer - [K3S] [apis.go:106] API group "storagemigration.k8s.io" is not enabled, skipping.
2025-01-29 22:14:26,474 INFO c.h.h.t.HelmChartContainer - [K3S] [apis.go:106] API group "resource.k8s.io" is not enabled, skipping.
2025-01-29 22:14:26,531 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Password verified locally for node 0cdda8541101
2025-01-29 22:14:26,780 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="request-header::/var/lib/rancher/k3s/server/tls/request-header-ca.crt"
2025-01-29 22:14:26,780 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/server/tls/client-ca.crt"
2025-01-29 22:14:26,780 INFO c.h.h.t.HelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:6444
2025-01-29 22:14:26,781 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt::/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.key"
2025-01-29 22:14:26,781 INFO c.h.h.t.HelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 22:14:26,782 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="aggregator-proxy-cert::/var/lib/rancher/k3s/server/tls/client-auth-proxy.crt::/var/lib/rancher/k3s/server/tls/client-auth-proxy.key"
2025-01-29 22:14:26,782 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:80] Starting OpenAPI V3 AggregationController
2025-01-29 22:14:26,782 INFO c.h.h.t.HelmChartContainer - [K3S] [customresource_discovery_controller.go:292] Starting DiscoveryController
2025-01-29 22:14:26,782 INFO c.h.h.t.HelmChartContainer - [K3S] [local_available_controller.go:156] Starting LocalAvailability controller
2025-01-29 22:14:26,783 INFO c.h.h.t.HelmChartContainer - [K3S] [system_namespaces_controller.go:66] Starting system namespaces controller
2025-01-29 22:14:26,783 INFO c.h.h.t.HelmChartContainer - [K3S] [apf_controller.go:377] Starting API Priority and Fairness config controller
2025-01-29 22:14:26,783 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:78] Starting OpenAPI AggregationController
2025-01-29 22:14:26,783 INFO c.h.h.t.HelmChartContainer - [K3S] [cluster_authentication_trust_controller.go:462] Starting cluster_authentication_trust_controller controller
2025-01-29 22:14:26,783 INFO c.h.h.t.HelmChartContainer - [K3S] [apiservice_controller.go:100] Starting APIServiceRegistrationController
2025-01-29 22:14:26,783 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:119] Starting legacy_token_tracking_controller
2025-01-29 22:14:26,783 INFO c.h.h.t.HelmChartContainer - [K3S] [gc_controller.go:78] Starting apiserver lease garbage collector
2025-01-29 22:14:26,786 INFO c.h.h.t.HelmChartContainer - [K3S] [remote_available_controller.go:411] Starting RemoteAvailability controller
2025-01-29 22:14:26,786 INFO c.h.h.t.HelmChartContainer - [K3S] [aggregator.go:169] waiting for initial CRD sync...
2025-01-29 22:14:26,786 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:142] Starting OpenAPI controller
2025-01-29 22:14:26,786 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:90] Starting OpenAPI V3 controller
2025-01-29 22:14:26,786 INFO c.h.h.t.HelmChartContainer - [K3S] [naming_controller.go:294] Starting NamingConditionController
2025-01-29 22:14:26,787 INFO c.h.h.t.HelmChartContainer - [K3S] [establishing_controller.go:81] Starting EstablishingController
2025-01-29 22:14:26,787 INFO c.h.h.t.HelmChartContainer - [K3S] [nonstructuralschema_controller.go:195] Starting NonStructuralSchemaConditionController
2025-01-29 22:14:26,787 INFO c.h.h.t.HelmChartContainer - [K3S] [apiapproval_controller.go:189] Starting KubernetesAPIApprovalPolicyConformantConditionController
2025-01-29 22:14:26,788 INFO c.h.h.t.HelmChartContainer - [K3S] [crd_finalizer.go:269] Starting CRDFinalizer
2025-01-29 22:14:26,789 INFO c.h.h.t.HelmChartContainer - [K3S] [crdregistration_controller.go:114] Starting crd-autoregister controller
2025-01-29 22:14:26,789 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="request-header::/var/lib/rancher/k3s/server/tls/request-header-ca.crt"
2025-01-29 22:14:26,789 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/server/tls/client-ca.crt"
2025-01-29 22:14:26,825 INFO c.h.h.t.HelmChartContainer - [K3S] [policy_source.go:240] refreshing policies
2025-01-29 22:14:26,884 INFO c.h.h.t.HelmChartContainer - [K3S] [apf_controller.go:382] Running API Priority and Fairness config worker
2025-01-29 22:14:26,885 INFO c.h.h.t.HelmChartContainer - [K3S] [apf_controller.go:385] Running API Priority and Fairness periodic rebalancing process
2025-01-29 22:14:26,885 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_discovery.go:451] Starting ResourceDiscoveryManager
2025-01-29 22:14:26,885 INFO c.h.h.t.HelmChartContainer - [K3S] [aggregator.go:171] initial CRD sync complete...
2025-01-29 22:14:26,887 INFO c.h.h.t.HelmChartContainer - [K3S] [autoregister_controller.go:144] Starting autoregister controller
2025-01-29 22:14:26,938 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:95] Unable to perform initial Kubernetes service initialization: namespaces "default" not found
2025-01-29 22:14:27,074 INFO c.h.h.t.HelmChartContainer - [K3S] [WARNING] Host resolv.conf includes loopback or multicast nameservers - kubelet will use autogenerated resolv.conf with nameserver 8.8.8.8
2025-01-29 22:14:27,082 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Module overlay was already loaded
2025-01-29 22:14:27,082 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Module nf_conntrack was already loaded
2025-01-29 22:14:27,082 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Module br_netfilter was already loaded
2025-01-29 22:14:27,088 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Set sysctl 'net/netfilter/nf_conntrack_max' to 131072
2025-01-29 22:14:27,088 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400
2025-01-29 22:14:27,088 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600
2025-01-29 22:14:27,089 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Logging containerd to /var/lib/rancher/k3s/agent/containerd/containerd.log
2025-01-29 22:14:27,090 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Running containerd -c /var/lib/rancher/k3s/agent/etc/containerd/config.toml -a /run/k3s/containerd/containerd.sock --state /run/k3s/containerd --root /var/lib/rancher/k3s/agent/containerd
2025-01-29 22:14:27,784 INFO c.h.h.t.HelmChartContainer - [K3S] [storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
2025-01-29 22:14:27,787 INFO c.h.h.t.HelmChartContainer - [K3S] [storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
2025-01-29 22:14:27,787 INFO c.h.h.t.HelmChartContainer - [K3S] [storage_scheduling.go:111] all system priority classes are created successfully or already exist.
2025-01-29 22:14:28,093 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] containerd is now running
2025-01-29 22:14:28,096 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Connecting to proxy" url="wss://127.0.0.1:6443/v1-k3s/connect
2025-01-29 22:14:28,101 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Creating k3s-cert-monitor event broadcaster
2025-01-29 22:14:28,102 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Running kubelet --cloud-provider=external --config-dir=/var/lib/rancher/k3s/agent/etc/kubelet.conf.d --containerd=/run/k3s/containerd/containerd.sock --hostname-override=0cdda8541101 --kubeconfig=/var/lib/rancher/k3s/agent/kubelet.kubeconfig --node-ip=172.18.0.2 --node-labels=
2025-01-29 22:14:28,102 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Handling backend connection request [0cdda8541101]
2025-01-29 22:14:28,102 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Remotedialer connected to proxy" url="wss://127.0.0.1:6443/v1-k3s/connect
2025-01-29 22:14:28,147 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="default/kubernetes" clusterIPs={"IPv4":"10.43.0.1"}
2025-01-29 22:14:28,151 INFO c.h.h.t.HelmChartContainer - [K3S] [lease.go:265] Resetting endpoints for master service "kubernetes" to [172.18.0.2]
2025-01-29 22:14:28,192 INFO c.h.h.t.HelmChartContainer - [K3S] [ERROR] Sending HTTP/1.1 503 response to 127.0.0.1:34608: runtime core not ready
2025-01-29 22:14:28,270 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Running kube-proxy --cluster-cidr=10.42.0.0/16 --conntrack-max-per-core=0 --conntrack-tcp-timeout-close-wait=0s --conntrack-tcp-timeout-established=0s --healthz-bind-address=127.0.0.1 --hostname-override=0cdda8541101 --kubeconfig=/var/lib/rancher/k3s/agent/kubeproxy.kubeconfig --proxy-mode=iptables
2025-01-29 22:14:28,316 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:687] "Failed to retrieve node info" err="nodes \"0cdda8541101\" not found"
2025-01-29 22:14:28,942 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Waiting for untainted node
2025-01-29 22:14:28,943 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Waiting for cloud-controller-manager privileges to become available
2025-01-29 22:14:28,943 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Kube API server is now running
2025-01-29 22:14:28,943 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] ETCD server is now running
2025-01-29 22:14:28,943 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] k3s is up and running
2025-01-29 22:14:28,943 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Creating k3s-supervisor event broadcaster
2025-01-29 22:14:28,947 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Applying CRD addons.k3s.cattle.io
2025-01-29 22:14:28,957 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Applying CRD etcdsnapshotfiles.k3s.cattle.io
2025-01-29 22:14:28,980 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Applying CRD helmcharts.helm.cattle.io
2025-01-29 22:14:29,009 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Applying CRD helmchartconfigs.helm.cattle.io
2025-01-29 22:14:29,032 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Waiting for CRD helmcharts.helm.cattle.io to become available
2025-01-29 22:14:29,106 INFO c.h.h.t.HelmChartContainer - [K3S] Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
2025-01-29 22:14:29,111 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:515] "Kubelet version" kubeletVersion="v1.32.1+k3s1"
2025-01-29 22:14:29,111 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:517] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 22:14:29,111 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/agent/client-ca.crt"
2025-01-29 22:14:29,114 INFO c.h.h.t.HelmChartContainer - [K3S] [log.go:32] "RuntimeConfig from runtime service failed" err="rpc error: code = Unimplemented desc = method RuntimeConfig not implemented"
2025-01-29 22:14:29,114 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:1416] "CRI implementation should be updated to support RuntimeConfig when KubeletCgroupDriverFromCRI feature gate has been enabled. Falling back to using cgroupDriver from kubelet config."
2025-01-29 22:14:29,118 INFO c.h.h.t.HelmChartContainer - [K3S] [info.go:53] Couldn't collect info from any of the files in "/etc/machine-id,/var/lib/dbus/machine-id"
2025-01-29 22:14:29,118 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:767] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
2025-01-29 22:14:29,119 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:836] "NoSwap is set due to memorySwapBehavior not specified" memorySwapBehavior="" FailSwapOn=false
2025-01-29 22:14:29,119 INFO c.h.h.t.HelmChartContainer - [K3S] [swap_util.go:115] "Swap is on" /proc/swaps contents=<
2025-01-29 22:14:29,119 INFO c.h.h.t.HelmChartContainer - [K3S] 	Filename				Type		Size		Used		Priority
2025-01-29 22:14:29,119 INFO c.h.h.t.HelmChartContainer - [K3S] 	/mnt/swapfile                           file		4194300		0		-2
2025-01-29 22:14:29,119 INFO c.h.h.t.HelmChartContainer - [K3S]  >
2025-01-29 22:14:29,119 INFO c.h.h.t.HelmChartContainer - [K3S] [container_manager_linux.go:268] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
2025-01-29 22:14:29,120 INFO c.h.h.t.HelmChartContainer - [K3S] [container_manager_linux.go:273] "Creating Container Manager object based on Node Config" nodeConfig={"NodeName":"0cdda8541101","RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"/k3s","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"cgroupfs","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"imagefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null,"CgroupVersion":2}
2025-01-29 22:14:29,120 INFO c.h.h.t.HelmChartContainer - [K3S] [topology_manager.go:138] "Creating topology manager with none policy"
2025-01-29 22:14:29,120 INFO c.h.h.t.HelmChartContainer - [K3S] [container_manager_linux.go:304] "Creating device plugin manager"
2025-01-29 22:14:29,120 INFO c.h.h.t.HelmChartContainer - [K3S] [state_mem.go:36] "Initialized new in-memory state store"
2025-01-29 22:14:29,121 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet.go:446] "Attempting to sync node with API server"
2025-01-29 22:14:29,121 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet.go:341] "Adding static pod path" path="/var/lib/rancher/k3s/agent/pod-manifests"
2025-01-29 22:14:29,122 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet.go:352] "Adding apiserver pod source"
2025-01-29 22:14:29,122 INFO c.h.h.t.HelmChartContainer - [K3S] [apiserver.go:42] "Waiting for node sync before watching apiserver pods"
2025-01-29 22:14:29,122 INFO c.h.h.t.HelmChartContainer - [K3S] [apiserver.go:52] "Watching apiserver"
2025-01-29 22:14:29,124 INFO c.h.h.t.HelmChartContainer - [K3S] [kuberuntime_manager.go:269] "Container runtime initialized" containerRuntime="containerd" version="v1.7.23-k3s2" apiVersion="v1"
2025-01-29 22:14:29,126 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet.go:890] "Not starting ClusterTrustBundle informer because we are in static kubelet mode"
2025-01-29 22:14:29,127 INFO c.h.h.t.HelmChartContainer - [K3S] [probe.go:272] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
2025-01-29 22:14:29,127 INFO c.h.h.t.HelmChartContainer - [K3S] [watchdog_linux.go:99] "Systemd watchdog is not enabled"
2025-01-29 22:14:29,128 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:1282] "Started kubelet"
2025-01-29 22:14:29,128 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:208] "Starting to listen read-only" address="0.0.0.0" port=10255
2025-01-29 22:14:29,129 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:169] "Starting to listen" address="0.0.0.0" port=10250
2025-01-29 22:14:29,134 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:490] "Adding debug handlers to kubelet server"
2025-01-29 22:14:29,135 INFO c.h.h.t.HelmChartContainer - [K3S] [ratelimit.go:55] "Setting rate limiting for endpoint" service="podresources" qps=100 burstTokens=10
2025-01-29 22:14:29,137 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:243] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
2025-01-29 22:14:29,137 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="kubelet-server-cert-files::/var/lib/rancher/k3s/agent/serving-kubelet.crt::/var/lib/rancher/k3s/agent/serving-kubelet.key"
2025-01-29 22:14:29,137 INFO c.h.h.t.HelmChartContainer - [K3S] [fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
2025-01-29 22:14:29,138 INFO c.h.h.t.HelmChartContainer - [K3S] [volume_manager.go:297] "Starting Kubelet Volume Manager"
2025-01-29 22:14:29,139 INFO c.h.h.t.HelmChartContainer - [K3S] [desired_state_of_world_populator.go:149] "Desired state populator starts to run"
2025-01-29 22:14:29,139 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler.go:26] "Reconciler: start to sync state"
2025-01-29 22:14:29,139 INFO c.h.h.t.HelmChartContainer - [K3S] [factory.go:221] Registration of the systemd container factory successfully
2025-01-29 22:14:29,139 INFO c.h.h.t.HelmChartContainer - [K3S] [factory.go:219] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
2025-01-29 22:14:29,140 INFO c.h.h.t.HelmChartContainer - [K3S] [factory.go:221] Registration of the containerd container factory successfully
2025-01-29 22:14:29,143 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet.go:1561] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
2025-01-29 22:14:29,147 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_node_status.go:467] "Error getting the current node from lister" err="node \"0cdda8541101\" not found"
2025-01-29 22:14:29,153 INFO c.h.h.t.HelmChartContainer - [K3S] [nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"0cdda8541101\" not found" node="0cdda8541101"
2025-01-29 22:14:29,161 INFO c.h.h.t.HelmChartContainer - [K3S] [cpu_manager.go:221] "Starting CPU manager" policy="none"
2025-01-29 22:14:29,161 INFO c.h.h.t.HelmChartContainer - [K3S] [cpu_manager.go:222] "Reconciling" reconcilePeriod="10s"
2025-01-29 22:14:29,161 INFO c.h.h.t.HelmChartContainer - [K3S] [state_mem.go:36] "Initialized new in-memory state store"
2025-01-29 22:14:29,163 INFO c.h.h.t.HelmChartContainer - [K3S] [policy_none.go:49] "None policy: Start"
2025-01-29 22:14:29,163 INFO c.h.h.t.HelmChartContainer - [K3S] [memory_manager.go:186] "Starting memorymanager" policy="None"
2025-01-29 22:14:29,164 INFO c.h.h.t.HelmChartContainer - [K3S] [state_mem.go:35] "Initializing new in-memory state store"
2025-01-29 22:14:29,169 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
2025-01-29 22:14:29,170 INFO c.h.h.t.HelmChartContainer - [K3S] [manager.go:519] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
2025-01-29 22:14:29,170 INFO c.h.h.t.HelmChartContainer - [K3S] [eviction_manager.go:189] "Eviction manager: starting control loop"
2025-01-29 22:14:29,170 INFO c.h.h.t.HelmChartContainer - [K3S] [container_log_manager.go:189] "Initializing container log rotate workers" workers=1 monitorPeriod="10s"
2025-01-29 22:14:29,171 INFO c.h.h.t.HelmChartContainer - [K3S] [plugin_manager.go:118] "Starting Kubelet Plugin Manager"
2025-01-29 22:14:29,173 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
2025-01-29 22:14:29,173 INFO c.h.h.t.HelmChartContainer - [K3S] [status_manager.go:227] "Starting to sync pod status with apiserver"
2025-01-29 22:14:29,174 INFO c.h.h.t.HelmChartContainer - [K3S] [watchdog_linux.go:127] "Systemd watchdog is not enabled or the interval is invalid, so health checking will not be started."
2025-01-29 22:14:29,174 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet.go:2388] "Starting kubelet main sync loop"
2025-01-29 22:14:29,174 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet.go:2412] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
2025-01-29 22:14:29,178 INFO c.h.h.t.HelmChartContainer - [K3S] [eviction_manager.go:267] "eviction manager: failed to check if we have separate container filesystem. Ignoring." err="no imagefs label for configured runtime"
2025-01-29 22:14:29,178 INFO c.h.h.t.HelmChartContainer - [K3S] [eviction_manager.go:292] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"0cdda8541101\" not found"
2025-01-29 22:14:29,262 INFO c.h.h.t.HelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 22:14:29,271 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_node_status.go:76] "Attempting to register node" node="0cdda8541101"
2025-01-29 22:14:29,277 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_node_status.go:79] "Successfully registered node" node="0cdda8541101"
2025-01-29 22:14:29,278 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_node_status.go:549] "Error updating node status, will retry" err="error getting node \"0cdda8541101\": node \"0cdda8541101\" not found"
2025-01-29 22:14:29,279 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Annotations and labels have been set successfully on node: 0cdda8541101
2025-01-29 22:14:29,279 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting flannel with backend vxlan
2025-01-29 22:14:29,319 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:698] "Successfully retrieved node IP(s)" IPs=["172.18.0.2"]
2025-01-29 22:14:29,319 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:234] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
2025-01-29 22:14:29,322 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:243] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
2025-01-29 22:14:29,322 INFO c.h.h.t.HelmChartContainer - [K3S] [server_linux.go:170] "Using iptables Proxier"
2025-01-29 22:14:29,323 INFO c.h.h.t.HelmChartContainer - [K3S] [proxier.go:255] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
2025-01-29 22:14:29,328 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:497] "Version info" version="v1.32.1+k3s1"
2025-01-29 22:14:29,328 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:499] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 22:14:29,329 INFO c.h.h.t.HelmChartContainer - [K3S] [config.go:199] "Starting service config controller"
2025-01-29 22:14:29,329 INFO c.h.h.t.HelmChartContainer - [K3S] [config.go:105] "Starting endpoint slice config controller"
2025-01-29 22:14:29,331 INFO c.h.h.t.HelmChartContainer - [K3S] [config.go:329] "Starting node config controller"
2025-01-29 22:14:29,336 INFO c.h.h.t.HelmChartContainer - [K3S] [desired_state_of_world_populator.go:157] "Finished populating initial desired state of world"
2025-01-29 22:14:29,508 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:185] "Starting" version="v1.32.1+k3s1"
2025-01-29 22:14:29,509 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:187] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 22:14:29,511 INFO c.h.h.t.HelmChartContainer - [K3S] [requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
2025-01-29 22:14:29,512 INFO c.h.h.t.HelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-01-29 22:14:29,512 INFO c.h.h.t.HelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-01-29 22:14:29,512 INFO c.h.h.t.HelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:10257
2025-01-29 22:14:29,512 INFO c.h.h.t.HelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 22:14:29,516 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="serviceaccount-token-controller"
2025-01-29 22:14:29,524 INFO c.h.h.t.HelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-kubelet-serving"
2025-01-29 22:14:29,525 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/server-ca.key"
2025-01-29 22:14:29,525 INFO c.h.h.t.HelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-kubelet-client"
2025-01-29 22:14:29,526 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/client-ca.key"
2025-01-29 22:14:29,527 INFO c.h.h.t.HelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-kube-apiserver-client"
2025-01-29 22:14:29,527 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/client-ca.key"
2025-01-29 22:14:29,527 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="certificatesigningrequest-signing-controller"
2025-01-29 22:14:29,527 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:723] "Skipping a cloud provider controller" controller="cloud-node-lifecycle-controller"
2025-01-29 22:14:29,527 INFO c.h.h.t.HelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-legacy-unknown"
2025-01-29 22:14:29,528 INFO c.h.h.t.HelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/server-ca.key"
2025-01-29 22:14:29,533 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolumeclaim-protection-controller"
2025-01-29 22:14:29,534 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="kube-apiserver-serving-clustertrustbundle-publisher-controller" requiredFeatureGates=["ClusterTrustBundle"]
2025-01-29 22:14:29,534 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="storageversion-garbage-collector-controller" requiredFeatureGates=["APIServerIdentity","StorageVersionAPI"]
2025-01-29 22:14:29,534 INFO c.h.h.t.HelmChartContainer - [K3S] [pvc_protection_controller.go:168] "Starting PVC protection controller"
2025-01-29 22:14:29,537 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Done waiting for CRD helmcharts.helm.cattle.io to become available
2025-01-29 22:14:29,537 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Waiting for CRD helmchartconfigs.helm.cattle.io to become available
2025-01-29 22:14:29,541 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="job-controller"
2025-01-29 22:14:29,541 INFO c.h.h.t.HelmChartContainer - [K3S] [job_controller.go:243] "Starting job controller"
2025-01-29 22:14:29,546 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="deployment-controller"
2025-01-29 22:14:29,547 INFO c.h.h.t.HelmChartContainer - [K3S] [deployment_controller.go:173] "Starting controller" controller="deployment"
2025-01-29 22:14:29,553 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="disruption-controller"
2025-01-29 22:14:29,553 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:723] "Skipping a cloud provider controller" controller="service-lb-controller"
2025-01-29 22:14:29,553 INFO c.h.h.t.HelmChartContainer - [K3S] [disruption.go:452] "Sending events to api server."
2025-01-29 22:14:29,553 INFO c.h.h.t.HelmChartContainer - [K3S] [disruption.go:463] "Starting disruption controller"
2025-01-29 22:14:29,558 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="ephemeral-volume-controller"
2025-01-29 22:14:29,558 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="service-cidr-controller" requiredFeatureGates=["MultiCIDRServiceAllocator"]
2025-01-29 22:14:29,558 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:743] "Warning: skipping controller" controller="storage-version-migrator-controller"
2025-01-29 22:14:29,558 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:173] "Starting ephemeral volume controller"
2025-01-29 22:14:29,577 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="resourcequota-controller"
2025-01-29 22:14:29,577 INFO c.h.h.t.HelmChartContainer - [K3S] [resource_quota_controller.go:300] "Starting resource quota controller"
2025-01-29 22:14:29,578 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="certificatesigningrequest-approving-controller"
2025-01-29 22:14:29,579 INFO c.h.h.t.HelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrapproving"
2025-01-29 22:14:29,583 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_node_status.go:502] "Fast updating node status as it just became ready"
2025-01-29 22:14:29,586 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-expander-controller"
2025-01-29 22:14:29,586 INFO c.h.h.t.HelmChartContainer - [K3S] [expand_controller.go:329] "Starting expand controller"
2025-01-29 22:14:29,620 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="root-ca-certificate-publisher-controller"
2025-01-29 22:14:29,620 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="resourceclaim-controller" requiredFeatureGates=["DynamicResourceAllocation"]
2025-01-29 22:14:29,620 INFO c.h.h.t.HelmChartContainer - [K3S] [publisher.go:107] "Starting root CA cert publisher controller"
2025-01-29 22:14:29,770 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="taint-eviction-controller"
2025-01-29 22:14:29,770 INFO c.h.h.t.HelmChartContainer - [K3S] [taint_eviction.go:281] "Starting" controller="taint-eviction-controller"
2025-01-29 22:14:29,771 INFO c.h.h.t.HelmChartContainer - [K3S] [taint_eviction.go:287] "Sending events to api server"
2025-01-29 22:14:29,920 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="serviceaccount-controller"
2025-01-29 22:14:29,920 INFO c.h.h.t.HelmChartContainer - [K3S] [serviceaccounts_controller.go:114] "Starting service account controller"
2025-01-29 22:14:29,969 INFO c.h.h.t.HelmChartContainer - [K3S] [node_lifecycle_controller.go:432] "Controller will reconcile labels"
2025-01-29 22:14:29,969 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="node-lifecycle-controller"
2025-01-29 22:14:29,969 INFO c.h.h.t.HelmChartContainer - [K3S] [node_lifecycle_controller.go:466] "Sending events to api server"
2025-01-29 22:14:29,969 INFO c.h.h.t.HelmChartContainer - [K3S] [node_lifecycle_controller.go:477] "Starting node controller"
2025-01-29 22:14:30,038 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Done waiting for CRD helmchartconfigs.helm.cattle.io to become available
2025-01-29 22:14:30,038 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing static file: /var/lib/rancher/k3s/server/static/charts/traefik-27.0.201+up27.0.2.tgz
2025-01-29 22:14:30,039 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing static file: /var/lib/rancher/k3s/server/static/charts/traefik-crd-27.0.201+up27.0.2.tgz
2025-01-29 22:14:30,039 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/runtimes.yaml
2025-01-29 22:14:30,039 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/ccm.yaml
2025-01-29 22:14:30,040 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/local-storage.yaml
2025-01-29 22:14:30,040 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml
2025-01-29 22:14:30,040 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml
2025-01-29 22:14:30,040 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml
2025-01-29 22:14:30,040 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml
2025-01-29 22:14:30,040 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml
2025-01-29 22:14:30,041 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/coredns.yaml
2025-01-29 22:14:30,041 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml
2025-01-29 22:14:30,041 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml
2025-01-29 22:14:30,041 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/rolebindings.yaml
2025-01-29 22:14:30,042 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting dynamiclistener CN filter node controller with SANs: [localhost 127.0.0.1 ::1 localhost 0cdda8541101 172.18.0.2 10.43.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local]
2025-01-29 22:14:30,042 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Tunnel server egress proxy mode: agent
2025-01-29 22:14:30,120 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-attach-detach-controller"
2025-01-29 22:14:30,120 INFO c.h.h.t.HelmChartContainer - [K3S] [attach_detach_controller.go:338] "Starting attach detach controller"
2025-01-29 22:14:30,146 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting k3s.cattle.io/v1, Kind=Addon controller
2025-01-29 22:14:30,146 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Creating deploy event broadcaster
2025-01-29 22:14:30,151 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/ccm" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/ccm.yaml\""
2025-01-29 22:14:30,176 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/ccm" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/ccm.yaml\""
2025-01-29 22:14:30,184 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/coredns.yaml\""
2025-01-29 22:14:30,250 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Node controller
2025-01-29 22:14:30,252 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Creating helm-controller event broadcaster
2025-01-29 22:14:30,260 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Cluster dns configmap has been set successfully
2025-01-29 22:14:30,264 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Labels and annotations have been set successfully on node: 0cdda8541101
2025-01-29 22:14:30,276 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="clusterrole-aggregation-controller"
2025-01-29 22:14:30,276 INFO c.h.h.t.HelmChartContainer - [K3S] [clusterroleaggregation_controller.go:194] "Starting ClusterRoleAggregator controller"
2025-01-29 22:14:30,361 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting helm.cattle.io/v1, Kind=HelmChart controller
2025-01-29 22:14:30,361 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting helm.cattle.io/v1, Kind=HelmChartConfig controller
2025-01-29 22:14:30,364 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding controller
2025-01-29 22:14:30,367 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting batch/v1, Kind=Job controller
2025-01-29 22:14:30,367 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Secret controller
2025-01-29 22:14:30,367 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting /v1, Kind=ServiceAccount controller
2025-01-29 22:14:30,368 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting /v1, Kind=ConfigMap controller
2025-01-29 22:14:30,382 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs={"IPv4":"10.43.0.10"}
2025-01-29 22:14:30,383 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/coredns.yaml\""
2025-01-29 22:14:30,389 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/local-storage" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/local-storage.yaml\""
2025-01-29 22:14:30,423 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="endpoints-controller"
2025-01-29 22:14:30,423 INFO c.h.h.t.HelmChartContainer - [K3S] [endpoints_controller.go:182] "Starting endpoint controller"
2025-01-29 22:14:30,484 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/local-storage" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/local-storage.yaml\""
2025-01-29 22:14:30,489 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/aggregated-metrics-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml\""
2025-01-29 22:14:30,502 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/aggregated-metrics-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml\""
2025-01-29 22:14:30,507 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-delegator" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml\""
2025-01-29 22:14:30,563 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-delegator" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml\""
2025-01-29 22:14:30,568 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml\""
2025-01-29 22:14:30,569 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="replicationcontroller-controller"
2025-01-29 22:14:30,569 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:217] "Starting controller" name="replicationcontroller"
2025-01-29 22:14:30,572 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml\""
2025-01-29 22:14:30,579 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-apiservice" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml\""
2025-01-29 22:14:30,586 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-apiservice" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml\""
2025-01-29 22:14:30,592 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 22:14:30,592 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:146] "Unhandled Error" err=<
2025-01-29 22:14:30,592 INFO c.h.h.t.HelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 22:14:30,592 INFO c.h.h.t.HelmChartContainer - [K3S]  >
2025-01-29 22:14:30,594 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-deployment" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml\""
2025-01-29 22:14:30,594 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:143] error resolving kube-system/metrics-server: service "metrics-server" not found
2025-01-29 22:14:30,603 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-deployment" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml\""
2025-01-29 22:14:30,608 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-service" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml\""
2025-01-29 22:14:30,613 INFO c.h.h.t.HelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="kube-system/metrics-server" clusterIPs={"IPv4":"10.43.117.111"}
2025-01-29 22:14:30,614 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-service" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml\""
2025-01-29 22:14:30,619 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 22:14:30,619 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:146] "Unhandled Error" err=<
2025-01-29 22:14:30,619 INFO c.h.h.t.HelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 22:14:30,619 INFO c.h.h.t.HelmChartContainer - [K3S]  >
2025-01-29 22:14:30,620 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:143] error resolving kube-system/metrics-server: endpoints "metrics-server" not found
2025-01-29 22:14:30,622 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/resource-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml\""
2025-01-29 22:14:30,663 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/resource-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml\""
2025-01-29 22:14:30,669 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/rolebindings" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/rolebindings.yaml\""
2025-01-29 22:14:30,775 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/rolebindings" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/rolebindings.yaml\""
2025-01-29 22:14:30,780 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Updating TLS secret for kube-system/k3s-serving (count: 10): map[listener.cattle.io/cn-0cdda8541101:0cdda8541101 listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.18.0.2:172.18.0.2 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=02E798FB12988A40C9735A518FF8ACFC39572397]
2025-01-29 22:14:30,783 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/runtimes" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/runtimes.yaml\""
2025-01-29 22:14:30,783 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Active TLS secret kube-system/k3s-serving (ver=322) (count 10): map[listener.cattle.io/cn-0cdda8541101:0cdda8541101 listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.18.0.2:172.18.0.2 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=02E798FB12988A40C9735A518FF8ACFC39572397]
2025-01-29 22:14:30,807 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/runtimes" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/runtimes.yaml\""
2025-01-29 22:14:30,819 INFO c.h.h.t.HelmChartContainer - [K3S] [graph_builder.go:351] "Running" component="GraphBuilder"
2025-01-29 22:14:30,819 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="garbage-collector-controller"
2025-01-29 22:14:30,877 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Updating TLS secret for kube-system/k3s-serving (count: 10): map[listener.cattle.io/cn-0cdda8541101:0cdda8541101 listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.18.0.2:172.18.0.2 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=02E798FB12988A40C9735A518FF8ACFC39572397]
2025-01-29 22:14:31,070 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="daemonset-controller"
2025-01-29 22:14:31,070 INFO c.h.h.t.HelmChartContainer - [K3S] [daemon_controller.go:294] "Starting daemon sets controller"
2025-01-29 22:14:31,105 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Tunnel authorizer set Kubelet Port 0.0.0.0:10250
2025-01-29 22:14:31,369 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="horizontal-pod-autoscaler-controller"
2025-01-29 22:14:31,369 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:723] "Skipping a cloud provider controller" controller="node-route-controller"
2025-01-29 22:14:31,369 INFO c.h.h.t.HelmChartContainer - [K3S] [horizontal.go:201] "Starting HPA controller"
2025-01-29 22:14:31,417 INFO c.h.h.t.HelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 22:14:31,520 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="endpointslice-mirroring-controller"
2025-01-29 22:14:31,520 INFO c.h.h.t.HelmChartContainer - [K3S] [endpointslicemirroring_controller.go:227] "Starting EndpointSliceMirroring controller"
2025-01-29 22:14:31,586 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 22:14:31,587 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 22:14:31,587 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:102] "Unhandled Error" err=<
2025-01-29 22:14:31,587 INFO c.h.h.t.HelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 22:14:31,587 INFO c.h.h.t.HelmChartContainer - [K3S]  >
2025-01-29 22:14:31,644 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="0cdda8541101" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodePasswordValidationComplete" message="Deferred node password secret validation complete"
2025-01-29 22:14:31,670 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="cronjob-controller"
2025-01-29 22:14:31,671 INFO c.h.h.t.HelmChartContainer - [K3S] [cronjob_controllerv2.go:145] "Starting cronjob controller v2"
2025-01-29 22:14:31,748 INFO c.h.h.t.HelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 22:14:31,820 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="token-cleaner-controller"
2025-01-29 22:14:31,820 INFO c.h.h.t.HelmChartContainer - [K3S] [tokencleaner.go:117] "Starting token cleaner controller"
2025-01-29 22:14:31,972 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:112] "No Secondary Service CIDR provided. Skipping filtering out secondary service addresses"
2025-01-29 22:14:31,973 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="node-ipam-controller"
2025-01-29 22:14:31,973 INFO c.h.h.t.HelmChartContainer - [K3S] [node_ipam_controller.go:141] "Starting ipam controller"
2025-01-29 22:14:31,997 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:160] Version: v1.32.1+k3s1
2025-01-29 22:14:31,999 INFO c.h.h.t.HelmChartContainer - [K3S] [requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
2025-01-29 22:14:32,000 INFO c.h.h.t.HelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-01-29 22:14:32,001 INFO c.h.h.t.HelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-01-29 22:14:32,001 INFO c.h.h.t.HelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:10258
2025-01-29 22:14:32,001 INFO c.h.h.t.HelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 22:14:32,004 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Creating service-lb-controller event broadcaster
2025-01-29 22:14:32,105 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Started tunnel to 172.18.0.2:6443
2025-01-29 22:14:32,106 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Stopped tunnel to 127.0.0.1:6443
2025-01-29 22:14:32,106 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Connecting to proxy" url="wss://172.18.0.2:6443/v1-k3s/connect
2025-01-29 22:14:32,106 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Proxy done" err="context canceled" url="wss://127.0.0.1:6443/v1-k3s/connect
2025-01-29 22:14:32,106 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] error in remotedialer server [400]: websocket: close 1006 (abnormal closure): unexpected EOF
2025-01-29 22:14:32,108 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Handling backend connection request [0cdda8541101]
2025-01-29 22:14:32,108 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Remotedialer connected to proxy" url="wss://172.18.0.2:6443/v1-k3s/connect
2025-01-29 22:14:32,115 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Node controller
2025-01-29 22:14:32,118 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Pod controller
2025-01-29 22:14:32,119 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="legacy-serviceaccount-token-cleaner-controller"
2025-01-29 22:14:32,119 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="selinux-warning-controller" requiredFeatureGates=["SELinuxChangePolicy"]
2025-01-29 22:14:32,120 INFO c.h.h.t.HelmChartContainer - [K3S] [legacy_serviceaccount_token_cleaner.go:103] "Starting legacy service account token cleaner controller"
2025-01-29 22:14:32,121 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting apps/v1, Kind=DaemonSet controller
2025-01-29 22:14:32,124 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting discovery.k8s.io/v1, Kind=EndpointSlice controller
2025-01-29 22:14:32,125 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:329] Started "cloud-node-controller"
2025-01-29 22:14:32,125 INFO c.h.h.t.HelmChartContainer - [K3S] [node_controller.go:176] Sending events to api server.
2025-01-29 22:14:32,126 INFO c.h.h.t.HelmChartContainer - [K3S] [node_controller.go:185] Waiting for informer caches to sync
2025-01-29 22:14:32,126 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:329] Started "cloud-node-lifecycle-controller"
2025-01-29 22:14:32,126 INFO c.h.h.t.HelmChartContainer - [K3S] [node_lifecycle_controller.go:112] Sending events to api server
2025-01-29 22:14:32,126 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:329] Started "service-lb-controller"
2025-01-29 22:14:32,126 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:306] "node-route-controller" is disabled
2025-01-29 22:14:32,126 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:234] Starting service controller
2025-01-29 22:14:32,225 INFO c.h.h.t.HelmChartContainer - [K3S] [node_controller.go:429] Initializing node 0cdda8541101 with cloud provider
2025-01-29 22:14:32,228 INFO c.h.h.t.HelmChartContainer - [K3S] [node_controller.go:474] Successfully initialized node 0cdda8541101 with cloud provider
2025-01-29 22:14:32,228 INFO c.h.h.t.HelmChartContainer - [K3S] [event.go:389] "Event occurred" object="0cdda8541101" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="Synced" message="Node synced successfully"
2025-01-29 22:14:32,234 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Updated coredns NodeHosts entry for 0cdda8541101
2025-01-29 22:14:32,320 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="validatingadmissionpolicy-status-controller"
2025-01-29 22:14:32,470 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="endpointslice-controller"
2025-01-29 22:14:32,470 INFO c.h.h.t.HelmChartContainer - [K3S] [endpointslice_controller.go:281] "Starting endpoint slice controller"
2025-01-29 22:14:32,545 INFO c.h.h.t.HelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 22:14:32,725 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="namespace-controller"
2025-01-29 22:14:32,725 INFO c.h.h.t.HelmChartContainer - [K3S] [namespace_controller.go:202] "Starting namespace controller"
2025-01-29 22:14:32,777 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:164] "Starting Kubernetes Scheduler" version="v1.32.1+k3s1"
2025-01-29 22:14:32,778 INFO c.h.h.t.HelmChartContainer - [K3S] [server.go:166] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 22:14:32,781 INFO c.h.h.t.HelmChartContainer - [K3S] [requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
2025-01-29 22:14:32,781 INFO c.h.h.t.HelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-01-29 22:14:32,781 INFO c.h.h.t.HelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-01-29 22:14:32,781 INFO c.h.h.t.HelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:10259
2025-01-29 22:14:32,781 INFO c.h.h.t.HelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 22:14:32,870 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="statefulset-controller"
2025-01-29 22:14:32,870 INFO c.h.h.t.HelmChartContainer - [K3S] [stateful_set.go:166] "Starting stateful set controller"
2025-01-29 22:14:33,026 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="ttl-controller"
2025-01-29 22:14:33,026 INFO c.h.h.t.HelmChartContainer - [K3S] [ttl_controller.go:127] "Starting TTL controller"
2025-01-29 22:14:33,170 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-binder-controller"
2025-01-29 22:14:33,170 INFO c.h.h.t.HelmChartContainer - [K3S] [pv_controller_base.go:308] "Starting persistent volume controller"
2025-01-29 22:14:33,321 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-protection-controller"
2025-01-29 22:14:33,321 INFO c.h.h.t.HelmChartContainer - [K3S] [pv_protection_controller.go:81] "Starting PV protection controller"
2025-01-29 22:14:33,470 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="pod-garbage-collector-controller"
2025-01-29 22:14:33,470 INFO c.h.h.t.HelmChartContainer - [K3S] [gc_controller.go:99] "Starting GC controller"
2025-01-29 22:14:33,620 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="replicaset-controller"
2025-01-29 22:14:33,620 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:217] "Starting controller" name="replicaset"
2025-01-29 22:14:33,669 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="certificatesigningrequest-cleaner-controller"
2025-01-29 22:14:33,670 INFO c.h.h.t.HelmChartContainer - [K3S] [cleaner.go:83] "Starting CSR cleaner controller"
2025-01-29 22:14:33,670 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:728] "Warning: controller is disabled" controller="bootstrap-signer-controller"
2025-01-29 22:14:33,670 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="volumeattributesclass-protection-controller" requiredFeatureGates=["VolumeAttributesClass"]
2025-01-29 22:14:33,820 INFO c.h.h.t.HelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="ttl-after-finished-controller"
2025-01-29 22:14:33,820 INFO c.h.h.t.HelmChartContainer - [K3S] [ttlafterfinished_controller.go:112] "Starting TTL after finished controller"
2025-01-29 22:14:33,874 INFO c.h.h.t.HelmChartContainer - [K3S] [actual_state_of_world.go:541] "Failed to update statusUpdateNeeded field in actual state of world" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"0cdda8541101\" does not exist"
2025-01-29 22:14:33,970 INFO c.h.h.t.HelmChartContainer - [K3S] [node_lifecycle_controller.go:1234] "Initializing eviction metric for zone" zone=""
2025-01-29 22:14:33,970 INFO c.h.h.t.HelmChartContainer - [K3S] [node_lifecycle_controller.go:886] "Missing timestamp for Node. Assuming now as a timestamp" node="0cdda8541101"
2025-01-29 22:14:33,970 INFO c.h.h.t.HelmChartContainer - [K3S] [node_lifecycle_controller.go:1080] "Controller detected that zone is now in new state" zone="" newState="Normal"
2025-01-29 22:14:33,974 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:177] "Sending events to api server"
2025-01-29 22:14:33,974 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:183] "Starting range CIDR allocator"
2025-01-29 22:14:33,992 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:428] "Set node PodCIDR" node="0cdda8541101" podCIDRs=["10.42.0.0/24"]
2025-01-29 22:14:33,992 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="0cdda8541101"
2025-01-29 22:14:33,992 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="0cdda8541101"
2025-01-29 22:14:33,992 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="0cdda8541101"
2025-01-29 22:14:33,992 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Flannel found PodCIDR assigned for node 0cdda8541101
2025-01-29 22:14:33,992 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] The interface eth0 with ipv4 address 172.18.0.2 will be used by flannel
2025-01-29 22:14:34,000 INFO c.h.h.t.HelmChartContainer - [K3S] [kube.go:139] Waiting 10m0s for node controller to sync
2025-01-29 22:14:34,001 INFO c.h.h.t.HelmChartContainer - [K3S] [kube.go:469] Starting kube subnet manager
2025-01-29 22:14:34,114 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Starting network policy controller version v2.2.1, built on 2025-01-28T18:27:08Z, go1.23.4
2025-01-29 22:14:34,114 INFO c.h.h.t.HelmChartContainer - [K3S] [network_policy_controller.go:164] Starting network policy controller
2025-01-29 22:14:34,142 INFO c.h.h.t.HelmChartContainer - [K3S] [network_policy_controller.go:176] Starting network policy controller full sync goroutine
2025-01-29 22:14:34,427 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 22:14:34,427 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:146] "Unhandled Error" err=<
2025-01-29 22:14:34,427 INFO c.h.h.t.HelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 22:14:34,427 INFO c.h.h.t.HelmChartContainer - [K3S]  >
2025-01-29 22:14:34,428 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:143] error resolving kube-system/metrics-server: no endpoints available for service "metrics-server"
2025-01-29 22:14:34,475 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="0cdda8541101"
2025-01-29 22:14:34,734 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="100.67088ms"
2025-01-29 22:14:34,738 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="104.701417ms"
2025-01-29 22:14:34,739 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="109.76539ms"
2025-01-29 22:14:34,758 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="19.072673ms"
2025-01-29 22:14:34,758 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="33.643µs"
2025-01-29 22:14:34,763 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="26.058803ms"
2025-01-29 22:14:34,766 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="26.770314ms"
2025-01-29 22:14:34,766 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="45.546µs"
2025-01-29 22:14:34,774 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="14.395365ms"
2025-01-29 22:14:34,774 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="41.1µs"
2025-01-29 22:14:34,780 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="51.717µs"
2025-01-29 22:14:34,789 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="29.806µs"
2025-01-29 22:14:34,796 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="61.174µs"
2025-01-29 22:14:34,877 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"custom-config-volume\" (UniqueName: \"kubernetes.io/configmap/c12af24d-fa2b-4494-91ec-0ade252376b2-custom-config-volume\") pod \"coredns-ff8999cc5-mwqvg\" (UID: \"c12af24d-fa2b-4494-91ec-0ade252376b2\") " pod="kube-system/coredns-ff8999cc5-mwqvg"
2025-01-29 22:14:34,877 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-k82kw\" (UniqueName: \"kubernetes.io/projected/c12af24d-fa2b-4494-91ec-0ade252376b2-kube-api-access-k82kw\") pod \"coredns-ff8999cc5-mwqvg\" (UID: \"c12af24d-fa2b-4494-91ec-0ade252376b2\") " pod="kube-system/coredns-ff8999cc5-mwqvg"
2025-01-29 22:14:34,877 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/cb4d26ec-3af5-46e5-a77d-6fb98e336743-config-volume\") pod \"local-path-provisioner-698b58967b-hngww\" (UID: \"cb4d26ec-3af5-46e5-a77d-6fb98e336743\") " pod="kube-system/local-path-provisioner-698b58967b-hngww"
2025-01-29 22:14:34,878 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-hnnjk\" (UniqueName: \"kubernetes.io/projected/cb4d26ec-3af5-46e5-a77d-6fb98e336743-kube-api-access-hnnjk\") pod \"local-path-provisioner-698b58967b-hngww\" (UID: \"cb4d26ec-3af5-46e5-a77d-6fb98e336743\") " pod="kube-system/local-path-provisioner-698b58967b-hngww"
2025-01-29 22:14:34,878 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp-dir\" (UniqueName: \"kubernetes.io/empty-dir/124be842-8139-455b-b757-31bd81010992-tmp-dir\") pod \"metrics-server-8584b5786c-hxmzt\" (UID: \"124be842-8139-455b-b757-31bd81010992\") " pod="kube-system/metrics-server-8584b5786c-hxmzt"
2025-01-29 22:14:34,878 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-7x775\" (UniqueName: \"kubernetes.io/projected/124be842-8139-455b-b757-31bd81010992-kube-api-access-7x775\") pod \"metrics-server-8584b5786c-hxmzt\" (UID: \"124be842-8139-455b-b757-31bd81010992\") " pod="kube-system/metrics-server-8584b5786c-hxmzt"
2025-01-29 22:14:34,878 INFO c.h.h.t.HelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/c12af24d-fa2b-4494-91ec-0ade252376b2-config-volume\") pod \"coredns-ff8999cc5-mwqvg\" (UID: \"c12af24d-fa2b-4494-91ec-0ade252376b2\") " pod="kube-system/coredns-ff8999cc5-mwqvg"
2025-01-29 22:14:35,001 INFO c.h.h.t.HelmChartContainer - [K3S] [kube.go:146] Node controller sync successful
2025-01-29 22:14:35,001 INFO c.h.h.t.HelmChartContainer - [K3S] [vxlan.go:141] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false
2025-01-29 22:14:35,003 INFO c.h.h.t.HelmChartContainer - [K3S] [kube.go:636] List of node(0cdda8541101) annotations: map[string]string{"alpha.kubernetes.io/provided-node-ip":"172.18.0.2", "k3s.io/hostname":"0cdda8541101", "k3s.io/internal-ip":"172.18.0.2", "k3s.io/node-args":"[\"server\",\"--etcd-arg\",\"unsafe-no-fsync\",\"--etcd-arg\",\"snapshot-count=10000\",\"--etcd-arg\",\"auto-compaction-mode=revision\",\"--etcd-arg\",\"auto-compaction-retention=1000000\",\"--kube-apiserver-arg\",\"etcd-compaction-interval=0s\",\"--disable\",\"traefik\",\"--tls-san\",\"localhost\"]", "k3s.io/node-config-hash":"2QNNT5M5XUBFOLO5XPGEVGOM5UDLHHTIVMSRUPAUHE5DU3HUYQUQ====", "k3s.io/node-env":"{}", "node.alpha.kubernetes.io/ttl":"0", "volumes.kubernetes.io/controller-managed-attach-detach":"true"}
2025-01-29 22:14:35,008 INFO c.h.h.t.HelmChartContainer - [K3S] [iptables.go:51] Starting flannel in iptables mode...
2025-01-29 22:14:35,008 INFO c.h.h.t.HelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_NETWORK in file: /run/flannel/subnet.env
2025-01-29 22:14:35,008 INFO c.h.h.t.HelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_SUBNET in file: /run/flannel/subnet.env
2025-01-29 22:14:35,008 INFO c.h.h.t.HelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_IPV6_NETWORK in file: /run/flannel/subnet.env
2025-01-29 22:14:35,008 INFO c.h.h.t.HelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_IPV6_SUBNET in file: /run/flannel/subnet.env
2025-01-29 22:14:35,008 INFO c.h.h.t.HelmChartContainer - [K3S] [iptables.go:115] Current network or subnet (10.42.0.0/16, 10.42.0.0/24) is not equal to previous one (0.0.0.0/0, 0.0.0.0/0), trying to recycle old iptables rules
2025-01-29 22:14:35,008 INFO c.h.h.t.HelmChartContainer - [K3S] [kube.go:490] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.0.0/24]
2025-01-29 22:14:35,009 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="0cdda8541101"
2025-01-29 22:14:35,016 INFO c.h.h.t.HelmChartContainer - [K3S] [iptables.go:125] Setting up masking rules
2025-01-29 22:14:35,018 INFO c.h.h.t.HelmChartContainer - [K3S] [iptables.go:226] Changing default FORWARD chain policy to ACCEPT
2025-01-29 22:14:35,020 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Wrote flannel subnet file to /run/flannel/subnet.env
2025-01-29 22:14:35,020 INFO c.h.h.t.HelmChartContainer - [K3S] [INFO] Running flannel backend.
2025-01-29 22:14:35,020 INFO c.h.h.t.HelmChartContainer - [K3S] [vxlan_network.go:65] watching for new subnet leases
2025-01-29 22:14:35,033 INFO c.h.h.t.HelmChartContainer - [K3S] [iptables.go:372] bootstrap done
2025-01-29 22:14:35,040 INFO c.h.h.t.HelmChartContainer - [K3S] [iptables.go:372] bootstrap done
2025-01-29 22:14:35,429 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 22:14:35,429 INFO c.h.h.t.HelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 22:14:35,429 INFO c.h.h.t.HelmChartContainer - [K3S] [controller.go:102] "Unhandled Error" err=<
2025-01-29 22:14:35,429 INFO c.h.h.t.HelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 22:14:35,429 INFO c.h.h.t.HelmChartContainer - [K3S]  >
2025-01-29 22:14:38,343 DEBUG c.h.h.t.HelmChartContainer - Image file loaded 'hivemq-platform-operator.tar'
2025-01-29 22:14:38,948 DEBUG c.h.h.t.HelmChartContainer - Image file loaded 'hivemq-platform-operator-init.tar'
2025-01-29 22:14:39,367 INFO c.h.h.t.HelmChartContainer - [K3S] [kuberuntime_manager.go:1702] "Updating runtime config through cri with podcidr" CIDR="10.42.0.0/24"
2025-01-29 22:14:39,368 INFO c.h.h.t.HelmChartContainer - [K3S] [kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.42.0.0/24"
2025-01-29 22:14:39,379 INFO c.h.h.t.HelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="0cdda8541101"
2025-01-29 22:14:40,222 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="31.329µs"
2025-01-29 22:14:40,263 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="13.057313ms"
2025-01-29 22:14:40,263 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="32.451µs"
2025-01-29 22:14:40,273 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="14.822258ms"
2025-01-29 22:14:40,273 INFO c.h.h.t.HelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="28.173µs"
2025-01-29 22:14:45,031 DEBUG c.h.h.t.HelmChartContainer - Image file loaded 'hivemq-platform.tar'
2025-01-29 22:14:45,031 DEBUG c.h.h.t.HelmChartContainer - Successful Helm chart Container startup
2025-01-29 22:14:45,045 INFO t.localhost/testcontainers/cqsek1zageikehvd:latest - Container localhost/testcontainers/cqsek1zageikehvd:latest started in PT22.022656745S
2025-01-29 22:14:45,055 DEBUG c.h.h.t.HelmChartContainer - Executing helm command: /bin/helm --kubeconfig /etc/rancher/k3s/k3s.yaml repo add hivemq https://hivemq.github.io/helm-charts
2025-01-29 22:14:46,307 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Starting] Starting kubelet. [null:0cdda8541101]
2025-01-29 22:14:46,308 INFO c.h.h.t.HelmChartContainer - [EVENT] Warning [InvalidDiskCapacity] invalid capacity 0 on image filesystem [null:0cdda8541101]
2025-01-29 22:14:46,309 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [NodeHasSufficientMemory] Node 0cdda8541101 status is now: NodeHasSufficientMemory [null:0cdda8541101]
2025-01-29 22:14:46,310 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [NodeHasNoDiskPressure] Node 0cdda8541101 status is now: NodeHasNoDiskPressure [null:0cdda8541101]
2025-01-29 22:14:46,311 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [NodeHasSufficientPID] Node 0cdda8541101 status is now: NodeHasSufficientPID [null:0cdda8541101]
2025-01-29 22:14:46,311 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [NodeAllocatableEnforced] Updated Node Allocatable limit across pods [null:0cdda8541101]
2025-01-29 22:14:46,313 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [NodeReady] Node 0cdda8541101 status is now: NodeReady [null:0cdda8541101]
2025-01-29 22:14:46,314 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [NodePasswordValidationComplete] Deferred node password secret validation complete [null:0cdda8541101]
2025-01-29 22:14:46,314 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [Synced] Node synced successfully [null:0cdda8541101]
2025-01-29 22:14:46,315 INFO c.h.h.t.HelmChartContainer - [EVENT] Normal [RegisteredNode] Node 0cdda8541101 event: Registered Node 0cdda8541101 in Controller [null:0cdda8541101]
2025-01-29 22:14:46,320 INFO c.h.h.t.HelmChartContainer - Saved kubeconfig file on /tmp/kubeconfig-1290485494665960515.yaml
2025-01-29 22:14:46,320 INFO c.h.h.t.HelmChartContainer - HelmChartContainer is started
]]></system-out>
  <system-err><![CDATA[]]></system-err>
</testsuite>
