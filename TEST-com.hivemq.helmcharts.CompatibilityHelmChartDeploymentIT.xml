<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="com.hivemq.helmcharts.CompatibilityHelmChartDeploymentIT" tests="1" skipped="0" failures="0" errors="0" timestamp="2025-01-29T00:57:18" hostname="fv-az1369-754" time="144.227">
  <properties/>
  <testcase name="withHelmLocalVersionDeployment_mqttMessagePublishedReceived()" classname="com.hivemq.helmcharts.CompatibilityHelmChartDeploymentIT" time="144.227">
    <system-out><![CDATA[2025-01-29 00:57:18,334 INFO o.testcontainers.DockerClientFactory - Testcontainers version: 1.20.4
2025-01-29 00:57:18,807 INFO o.t.d.DockerClientProviderStrategy - Found Docker environment with local Unix socket (unix:///var/run/docker.sock)
2025-01-29 00:57:18,815 INFO o.testcontainers.DockerClientFactory - Docker host IP address is localhost
2025-01-29 00:57:18,831 INFO o.testcontainers.DockerClientFactory - Connected to docker: 
  Server Version: 26.1.3
  API Version: 1.45
  Operating System: Ubuntu 24.04.1 LTS
  Total Memory: 15990 MB
2025-01-29 00:57:18,837 INFO o.testcontainers.images.PullPolicy - Image pull policy will be performed by: DefaultPullPolicy()
2025-01-29 00:57:18,839 INFO o.t.utility.ImageNameSubstitutor - Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')
2025-01-29 00:57:18,865 INFO tc.testcontainers/ryuk:0.11.0 - Pulling docker image: testcontainers/ryuk:0.11.0. Please be patient; this may take some time but only needs to be done once.
2025-01-29 00:57:19,846 INFO tc.testcontainers/ryuk:0.11.0 - Starting to pull image
2025-01-29 00:57:19,860 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  0 downloaded,  0 extracted, (0 bytes/0 bytes)
2025-01-29 00:57:20,184 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  2 pending,  1 downloaded,  0 extracted, (879 KB/? MB)
2025-01-29 00:57:20,242 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  1 pending,  2 downloaded,  0 extracted, (4 MB/? MB)
2025-01-29 00:57:20,272 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  3 downloaded,  0 extracted, (4 MB/10 MB)
2025-01-29 00:57:20,345 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  3 downloaded,  1 extracted, (6 MB/10 MB)
2025-01-29 00:57:20,449 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  3 downloaded,  2 extracted, (6 MB/10 MB)
2025-01-29 00:57:20,485 INFO tc.testcontainers/ryuk:0.11.0 - Pulling image layers:  0 pending,  3 downloaded,  3 extracted, (10 MB/10 MB)
2025-01-29 00:57:20,491 INFO tc.testcontainers/ryuk:0.11.0 - Image testcontainers/ryuk:0.11.0 pull took PT1.625282924S
2025-01-29 00:57:20,511 INFO tc.testcontainers/ryuk:0.11.0 - Creating container for image: testcontainers/ryuk:0.11.0
2025-01-29 00:57:20,575 INFO tc.testcontainers/ryuk:0.11.0 - Container testcontainers/ryuk:0.11.0 is starting: 2529951e645e725f06125bdb94f797402aabd5d659314e2099dc62291fd683ed
2025-01-29 00:57:21,028 INFO tc.testcontainers/ryuk:0.11.0 - Container testcontainers/ryuk:0.11.0 started in PT0.516318606S
2025-01-29 00:57:21,031 INFO o.t.utility.RyukResourceReaper - Ryuk started - will monitor and terminate Testcontainers containers on JVM exit
2025-01-29 00:57:21,032 INFO o.testcontainers.DockerClientFactory - Checking the system...
2025-01-29 00:57:21,032 INFO o.testcontainers.DockerClientFactory - ✔︎ Docker server version should be at least 1.6.0
2025-01-29 00:57:21,052 INFO o.t.i.builder.ImageFromDockerfile - Pre-emptively checking local images for 'ubuntu:noble-20241118.1@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab', referenced via a Dockerfile. If not available, it will be pulled.
2025-01-29 00:57:21,054 INFO t.u.1@sha256:80dd3c... - Pulling docker image: ubuntu:noble-20241118.1@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab. Please be patient; this may take some time but only needs to be done once.
2025-01-29 00:57:21,305 INFO t.u.1@sha256:80dd3c... - Starting to pull image
2025-01-29 00:57:21,306 INFO t.u.1@sha256:80dd3c... - Pulling image layers:  0 pending,  0 downloaded,  0 extracted, (0 bytes/0 bytes)
2025-01-29 00:57:21,956 INFO t.u.1@sha256:80dd3c... - Pulling image layers:  0 pending,  1 downloaded,  0 extracted, (26 MB/28 MB)
2025-01-29 00:57:22,970 INFO t.u.1@sha256:80dd3c... - Pulling image layers:  0 pending,  1 downloaded,  1 extracted, (28 MB/28 MB)
2025-01-29 00:57:22,977 INFO t.u.1@sha256:80dd3c... - Image ubuntu:noble-20241118.1@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab pull took PT1.922655866S
2025-01-29 00:57:22,977 INFO t.u.1@sha256:80dd3c... - Pull complete. 1 layers, pulled in 1s (downloaded 28 MB at 28 MB/s)
2025-01-29 00:57:22,979 INFO o.t.i.builder.ImageFromDockerfile - Pre-emptively checking local images for 'rancher/k3s:v1.32.1-k3s1', referenced via a Dockerfile. If not available, it will be pulled.
2025-01-29 00:57:22,980 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pulling docker image: rancher/k3s:v1.32.1-k3s1. Please be patient; this may take some time but only needs to be done once.
2025-01-29 00:57:23,360 INFO tc.rancher/k3s:v1.32.1-k3s1 - Starting to pull image
2025-01-29 00:57:23,361 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pulling image layers:  0 pending,  0 downloaded,  0 extracted, (0 bytes/0 bytes)
2025-01-29 00:57:24,600 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pulling image layers:  0 pending,  1 downloaded,  0 extracted, (65 MB/71 MB)
2025-01-29 00:57:25,641 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pulling image layers:  0 pending,  1 downloaded,  1 extracted, (71 MB/71 MB)
2025-01-29 00:57:25,647 INFO tc.rancher/k3s:v1.32.1-k3s1 - Image rancher/k3s:v1.32.1-k3s1 pull took PT2.666109918S
2025-01-29 00:57:25,647 INFO tc.rancher/k3s:v1.32.1-k3s1 - Pull complete. 1 layers, pulled in 2s (downloaded 71 MB at 35 MB/s)
2025-01-29 00:57:25,652 INFO o.t.i.builder.ImageFromDockerfile - Transferred 0 bytes to Docker daemon
2025-01-29 00:57:43,019 INFO t.localhost/testcontainers/6bnecnaskpov4nfq:latest - Creating container for image: localhost/testcontainers/6bnecnaskpov4nfq:latest
2025-01-29 00:57:43,021 INFO tc.alpine:3.17 - Pulling docker image: alpine:3.17. Please be patient; this may take some time but only needs to be done once.
2025-01-29 00:57:43,364 INFO tc.alpine:3.17 - Starting to pull image
2025-01-29 00:57:43,365 INFO tc.alpine:3.17 - Pulling image layers:  0 pending,  0 downloaded,  0 extracted, (0 bytes/0 bytes)
2025-01-29 00:57:43,762 INFO tc.alpine:3.17 - Pulling image layers:  0 pending,  1 downloaded,  0 extracted, (3 MB/3 MB)
2025-01-29 00:57:43,856 INFO tc.alpine:3.17 - Pulling image layers:  0 pending,  1 downloaded,  1 extracted, (3 MB/3 MB)
2025-01-29 00:57:43,862 INFO tc.alpine:3.17 - Image alpine:3.17 pull took PT0.840371702S
2025-01-29 00:57:44,215 INFO t.localhost/testcontainers/6bnecnaskpov4nfq:latest - Container localhost/testcontainers/6bnecnaskpov4nfq:latest is starting: a5beccf5b7f1809ba1b700f131a065e709ab732db1d67f8b6394f022b4bf2e74
2025-01-29 00:57:44,571 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting k3s v1.32.1+k3s1 (6a322f12)
2025-01-29 00:57:44,573 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Configuring sqlite3 database connection pooling: maxIdleConns=2, maxOpenConns=0, connMaxLifetime=0s
2025-01-29 00:57:44,574 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Configuring database table schema and indexes, this may take a moment...
2025-01-29 00:57:44,577 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Database tables and indexes are up to date
2025-01-29 00:57:44,580 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Kine available at unix://kine.sock
2025-01-29 00:57:44,624 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Saving cluster bootstrap data to datastore
2025-01-29 00:57:44,625 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] dynamiclistener [::]:6443: no cached certificate available for preload - deferring certificate load until storage initialization or first client request
2025-01-29 00:57:44,626 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Active TLS secret / (ver=) (count 10): map[listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.17.0.3:172.17.0.3 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-a5beccf5b7f1:a5beccf5b7f1 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=A6981EECC166907766259FF7C13F1AEDB31169D0]
2025-01-29 00:57:44,786 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kube-apiserver --advertise-port=6443 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,k3s --authorization-mode=Node,RBAC --bind-address=127.0.0.1 --cert-dir=/var/lib/rancher/k3s/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/k3s/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/k3s/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --etcd-servers=unix://kine.sock --kubelet-certificate-authority=/var/lib/rancher/k3s/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/k3s/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/k3s/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/k3s/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/k3s/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/k3s/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6444 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/k3s/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/k3s/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.key
2025-01-29 00:57:44,788 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kube-scheduler --authentication-kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --authorization-kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --bind-address=127.0.0.1 --kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --leader-elect=false --profiling=false --secure-port=10259
2025-01-29 00:57:44,788 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
2025-01-29 00:57:44,789 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kube-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/k3s/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/k3s/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/k3s/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/k3s/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --leader-elect=false --profiling=false --root-ca-file=/var/lib/rancher/k3s/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/k3s/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true
2025-01-29 00:57:44,790 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [options.go:299] unable to set WatchListClient feature gate, err: cannot override default for feature "WatchListClient": gates already added to a flag set
2025-01-29 00:57:44,790 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
2025-01-29 00:57:44,790 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running cloud-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/k3s/server/cred/cloud-controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/k3s/server/cred/cloud-controller.kubeconfig --bind-address=127.0.0.1 --cloud-config=/var/lib/rancher/k3s/server/etc/cloud-config.yaml --cloud-provider=k3s --cluster-cidr=10.42.0.0/16 --configure-cloud-routes=false --controllers=*,-route --kubeconfig=/var/lib/rancher/k3s/server/cred/cloud-controller.kubeconfig --leader-elect=false --leader-elect-resource-name=k3s-cloud-controller-manager --node-status-update-frequency=1m0s --profiling=false
2025-01-29 00:57:44,790 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for API server to become available
2025-01-29 00:57:44,791 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
2025-01-29 00:57:44,791 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Server node token is available at /var/lib/rancher/k3s/server/token
2025-01-29 00:57:44,791 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] To join server node to cluster: k3s server -s https://172.17.0.3:6443 -t ${SERVER_NODE_TOKEN}
2025-01-29 00:57:44,791 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [options.go:238] external host was not specified, using 172.17.0.3
2025-01-29 00:57:44,792 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Agent node token is available at /var/lib/rancher/k3s/server/agent-token
2025-01-29 00:57:44,792 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] To join agent node to cluster: k3s agent -s https://172.17.0.3:6443 -t ${AGENT_NODE_TOKEN}
2025-01-29 00:57:44,792 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Wrote kubeconfig /etc/rancher/k3s/k3s.yaml
2025-01-29 00:57:44,792 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Run: k3s kubectl
2025-01-29 00:57:44,792 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:151] Version: v1.32.1+k3s1
2025-01-29 00:57:44,792 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:153] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 00:57:45,177 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionPolicy,MutatingAdmissionWebhook.
2025-01-29 00:57:45,179 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [plugins.go:160] Loaded 13 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,ClusterTrustBundleAttest,CertificateSubjectRestriction,ValidatingAdmissionPolicy,ValidatingAdmissionWebhook,ResourceQuota.
2025-01-29 00:57:45,179 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [instance.go:233] Using reconciler: lease
2025-01-29 00:57:45,257 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apis.go:106] API group "internal.apiserver.k8s.io" is not enabled, skipping.
2025-01-29 00:57:45,302 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apis.go:106] API group "storagemigration.k8s.io" is not enabled, skipping.
2025-01-29 00:57:45,344 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apis.go:106] API group "resource.k8s.io" is not enabled, skipping.
2025-01-29 00:57:45,349 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Password verified locally for node a5beccf5b7f1
2025-01-29 00:57:45,664 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/server/tls/client-ca.crt"
2025-01-29 00:57:45,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="request-header::/var/lib/rancher/k3s/server/tls/request-header-ca.crt"
2025-01-29 00:57:45,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt::/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.key"
2025-01-29 00:57:45,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:6444
2025-01-29 00:57:45,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 00:57:45,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [system_namespaces_controller.go:66] Starting system namespaces controller
2025-01-29 00:57:45,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cluster_authentication_trust_controller.go:462] Starting cluster_authentication_trust_controller controller
2025-01-29 00:57:45,666 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [gc_controller.go:78] Starting apiserver lease garbage collector
2025-01-29 00:57:45,666 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [customresource_discovery_controller.go:292] Starting DiscoveryController
2025-01-29 00:57:45,666 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [local_available_controller.go:156] Starting LocalAvailability controller
2025-01-29 00:57:45,670 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apiservice_controller.go:100] Starting APIServiceRegistrationController
2025-01-29 00:57:45,670 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:119] Starting legacy_token_tracking_controller
2025-01-29 00:57:45,670 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:78] Starting OpenAPI AggregationController
2025-01-29 00:57:45,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:80] Starting OpenAPI V3 AggregationController
2025-01-29 00:57:45,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="aggregator-proxy-cert::/var/lib/rancher/k3s/server/tls/client-auth-proxy.crt::/var/lib/rancher/k3s/server/tls/client-auth-proxy.key"
2025-01-29 00:57:45,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [remote_available_controller.go:411] Starting RemoteAvailability controller
2025-01-29 00:57:45,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:142] Starting OpenAPI controller
2025-01-29 00:57:45,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:90] Starting OpenAPI V3 controller
2025-01-29 00:57:45,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [naming_controller.go:294] Starting NamingConditionController
2025-01-29 00:57:45,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [establishing_controller.go:81] Starting EstablishingController
2025-01-29 00:57:45,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [nonstructuralschema_controller.go:195] Starting NonStructuralSchemaConditionController
2025-01-29 00:57:45,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apiapproval_controller.go:189] Starting KubernetesAPIApprovalPolicyConformantConditionController
2025-01-29 00:57:45,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [crd_finalizer.go:269] Starting CRDFinalizer
2025-01-29 00:57:45,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [crdregistration_controller.go:114] Starting crd-autoregister controller
2025-01-29 00:57:45,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/server/tls/client-ca.crt"
2025-01-29 00:57:45,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="request-header::/var/lib/rancher/k3s/server/tls/request-header-ca.crt"
2025-01-29 00:57:45,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apf_controller.go:377] Starting API Priority and Fairness config controller
2025-01-29 00:57:45,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [aggregator.go:169] waiting for initial CRD sync...
2025-01-29 00:57:45,765 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_discovery.go:451] Starting ResourceDiscoveryManager
2025-01-29 00:57:45,766 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apf_controller.go:382] Running API Priority and Fairness config worker
2025-01-29 00:57:45,767 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apf_controller.go:385] Running API Priority and Fairness periodic rebalancing process
2025-01-29 00:57:45,769 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [aggregator.go:171] initial CRD sync complete...
2025-01-29 00:57:45,769 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [autoregister_controller.go:144] Starting autoregister controller
2025-01-29 00:57:45,773 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [policy_source.go:240] refreshing policies
2025-01-29 00:57:45,781 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:145] "Failed to ensure lease exists, will retry" err="namespaces \"kube-system\" not found" interval="200ms"
2025-01-29 00:57:45,819 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:95] Unable to perform initial Kubernetes service initialization: namespaces "default" not found
2025-01-29 00:57:45,820 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:148] "Unhandled Error" err="while syncing ConfigMap \"kube-system/kube-apiserver-legacy-service-account-token-tracking\", err: namespaces \"kube-system\" not found" logger="UnhandledError"
2025-01-29 00:57:45,929 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Module overlay was already loaded
2025-01-29 00:57:45,930 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Module nf_conntrack was already loaded
2025-01-29 00:57:45,930 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Module br_netfilter was already loaded
2025-01-29 00:57:45,935 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Set sysctl 'net/netfilter/nf_conntrack_max' to 131072
2025-01-29 00:57:45,935 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400
2025-01-29 00:57:45,935 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600
2025-01-29 00:57:45,937 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Logging containerd to /var/lib/rancher/k3s/agent/containerd/containerd.log
2025-01-29 00:57:45,937 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running containerd -c /var/lib/rancher/k3s/agent/etc/containerd/config.toml -a /run/k3s/containerd/containerd.sock --state /run/k3s/containerd --root /var/lib/rancher/k3s/agent/containerd
2025-01-29 00:57:46,668 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
2025-01-29 00:57:46,671 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
2025-01-29 00:57:46,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [storage_scheduling.go:111] all system priority classes are created successfully or already exist.
2025-01-29 00:57:46,940 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] containerd is now running
2025-01-29 00:57:46,945 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Connecting to proxy" url="wss://127.0.0.1:6443/v1-k3s/connect
2025-01-29 00:57:46,945 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating k3s-cert-monitor event broadcaster
2025-01-29 00:57:46,946 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kubelet --cloud-provider=external --config-dir=/var/lib/rancher/k3s/agent/etc/kubelet.conf.d --containerd=/run/k3s/containerd/containerd.sock --hostname-override=a5beccf5b7f1 --kubeconfig=/var/lib/rancher/k3s/agent/kubelet.kubeconfig --node-ip=172.17.0.3 --node-labels=
2025-01-29 00:57:46,947 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Handling backend connection request [a5beccf5b7f1]
2025-01-29 00:57:46,948 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Remotedialer connected to proxy" url="wss://127.0.0.1:6443/v1-k3s/connect
2025-01-29 00:57:47,056 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [ERROR] Sending HTTP/1.1 503 response to 127.0.0.1:54884: runtime core not ready
2025-01-29 00:57:47,125 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="default/kubernetes" clusterIPs={"IPv4":"10.43.0.1"}
2025-01-29 00:57:47,130 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [lease.go:265] Resetting endpoints for master service "kubernetes" to [172.17.0.3]
2025-01-29 00:57:47,136 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kube-proxy --cluster-cidr=10.42.0.0/16 --conntrack-max-per-core=0 --conntrack-tcp-timeout-close-wait=0s --conntrack-tcp-timeout-established=0s --healthz-bind-address=127.0.0.1 --hostname-override=a5beccf5b7f1 --kubeconfig=/var/lib/rancher/k3s/agent/kubeproxy.kubeconfig --proxy-mode=iptables
2025-01-29 00:57:47,175 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:687] "Failed to retrieve node info" err="nodes \"a5beccf5b7f1\" not found"
2025-01-29 00:57:47,791 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for untainted node
2025-01-29 00:57:47,791 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Kube API server is now running
2025-01-29 00:57:47,791 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] ETCD server is now running
2025-01-29 00:57:47,791 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] k3s is up and running
2025-01-29 00:57:47,792 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for cloud-controller-manager privileges to become available
2025-01-29 00:57:47,793 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating k3s-supervisor event broadcaster
2025-01-29 00:57:47,799 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Applying CRD addons.k3s.cattle.io
2025-01-29 00:57:47,809 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Applying CRD etcdsnapshotfiles.k3s.cattle.io
2025-01-29 00:57:47,817 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Applying CRD helmcharts.helm.cattle.io
2025-01-29 00:57:47,828 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Applying CRD helmchartconfigs.helm.cattle.io
2025-01-29 00:57:47,839 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for CRD helmcharts.helm.cattle.io to become available
2025-01-29 00:57:47,954 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
2025-01-29 00:57:47,956 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:515] "Kubelet version" kubeletVersion="v1.32.1+k3s1"
2025-01-29 00:57:47,957 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:517] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 00:57:47,958 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/agent/client-ca.crt"
2025-01-29 00:57:47,960 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [log.go:32] "RuntimeConfig from runtime service failed" err="rpc error: code = Unimplemented desc = method RuntimeConfig not implemented"
2025-01-29 00:57:47,960 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:1416] "CRI implementation should be updated to support RuntimeConfig when KubeletCgroupDriverFromCRI feature gate has been enabled. Falling back to using cgroupDriver from kubelet config."
2025-01-29 00:57:47,964 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [info.go:53] Couldn't collect info from any of the files in "/etc/machine-id,/var/lib/dbus/machine-id"
2025-01-29 00:57:47,964 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:767] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
2025-01-29 00:57:47,964 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:836] "NoSwap is set due to memorySwapBehavior not specified" memorySwapBehavior="" FailSwapOn=false
2025-01-29 00:57:47,964 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [swap_util.go:115] "Swap is on" /proc/swaps contents=<
2025-01-29 00:57:47,965 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	Filename				Type		Size		Used		Priority
2025-01-29 00:57:47,966 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	/mnt/swapfile                           file		4194300		0		-2
2025-01-29 00:57:47,966 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 00:57:47,966 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [container_manager_linux.go:268] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
2025-01-29 00:57:47,967 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [container_manager_linux.go:273] "Creating Container Manager object based on Node Config" nodeConfig={"NodeName":"a5beccf5b7f1","RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"/k3s","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"cgroupfs","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"imagefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null,"CgroupVersion":2}
2025-01-29 00:57:47,967 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [topology_manager.go:138] "Creating topology manager with none policy"
2025-01-29 00:57:47,967 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [container_manager_linux.go:304] "Creating device plugin manager"
2025-01-29 00:57:47,971 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [state_mem.go:36] "Initialized new in-memory state store"
2025-01-29 00:57:47,971 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:446] "Attempting to sync node with API server"
2025-01-29 00:57:47,971 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:341] "Adding static pod path" path="/var/lib/rancher/k3s/agent/pod-manifests"
2025-01-29 00:57:47,971 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:352] "Adding apiserver pod source"
2025-01-29 00:57:47,971 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apiserver.go:42] "Waiting for node sync before watching apiserver pods"
2025-01-29 00:57:47,972 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kuberuntime_manager.go:269] "Container runtime initialized" containerRuntime="containerd" version="v1.7.23-k3s2" apiVersion="v1"
2025-01-29 00:57:47,972 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:890] "Not starting ClusterTrustBundle informer because we are in static kubelet mode"
2025-01-29 00:57:47,972 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [probe.go:272] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
2025-01-29 00:57:47,972 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [watchdog_linux.go:99] "Systemd watchdog is not enabled"
2025-01-29 00:57:47,972 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:1282] "Started kubelet"
2025-01-29 00:57:47,973 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:169] "Starting to listen" address="0.0.0.0" port=10250
2025-01-29 00:57:47,974 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:490] "Adding debug handlers to kubelet server"
2025-01-29 00:57:47,976 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:208] "Starting to listen read-only" address="0.0.0.0" port=10255
2025-01-29 00:57:47,977 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [ratelimit.go:55] "Setting rate limiting for endpoint" service="podresources" qps=100 burstTokens=10
2025-01-29 00:57:47,978 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
2025-01-29 00:57:47,979 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:243] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
2025-01-29 00:57:47,981 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:1561] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
2025-01-29 00:57:47,982 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [volume_manager.go:297] "Starting Kubelet Volume Manager"
2025-01-29 00:57:47,984 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:467] "Error getting the current node from lister" err="node \"a5beccf5b7f1\" not found"
2025-01-29 00:57:47,984 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [desired_state_of_world_populator.go:149] "Desired state populator starts to run"
2025-01-29 00:57:47,984 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler.go:26] "Reconciler: start to sync state"
2025-01-29 00:57:47,987 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [factory.go:221] Registration of the systemd container factory successfully
2025-01-29 00:57:47,987 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [factory.go:219] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
2025-01-29 00:57:47,988 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="kubelet-server-cert-files::/var/lib/rancher/k3s/agent/serving-kubelet.crt::/var/lib/rancher/k3s/agent/serving-kubelet.key"
2025-01-29 00:57:47,993 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [factory.go:221] Registration of the containerd container factory successfully
2025-01-29 00:57:47,994 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"a5beccf5b7f1\" not found" node="a5beccf5b7f1"
2025-01-29 00:57:48,007 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
2025-01-29 00:57:48,008 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
2025-01-29 00:57:48,009 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [status_manager.go:227] "Starting to sync pod status with apiserver"
2025-01-29 00:57:48,009 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [watchdog_linux.go:127] "Systemd watchdog is not enabled or the interval is invalid, so health checking will not be started."
2025-01-29 00:57:48,010 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:2388] "Starting kubelet main sync loop"
2025-01-29 00:57:48,010 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:2412] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
2025-01-29 00:57:48,020 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cpu_manager.go:221] "Starting CPU manager" policy="none"
2025-01-29 00:57:48,022 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cpu_manager.go:222] "Reconciling" reconcilePeriod="10s"
2025-01-29 00:57:48,022 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [state_mem.go:36] "Initialized new in-memory state store"
2025-01-29 00:57:48,023 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [policy_none.go:49] "None policy: Start"
2025-01-29 00:57:48,023 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [memory_manager.go:186] "Starting memorymanager" policy="None"
2025-01-29 00:57:48,023 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [state_mem.go:35] "Initializing new in-memory state store"
2025-01-29 00:57:48,026 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [manager.go:519] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
2025-01-29 00:57:48,027 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [eviction_manager.go:189] "Eviction manager: starting control loop"
2025-01-29 00:57:48,027 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [container_log_manager.go:189] "Initializing container log rotate workers" workers=1 monitorPeriod="10s"
2025-01-29 00:57:48,030 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [plugin_manager.go:118] "Starting Kubelet Plugin Manager"
2025-01-29 00:57:48,030 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [eviction_manager.go:267] "eviction manager: failed to check if we have separate container filesystem. Ignoring." err="no imagefs label for configured runtime"
2025-01-29 00:57:48,030 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [eviction_manager.go:292] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"a5beccf5b7f1\" not found"
2025-01-29 00:57:48,042 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 00:57:48,130 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:76] "Attempting to register node" node="a5beccf5b7f1"
2025-01-29 00:57:48,136 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:79] "Successfully registered node" node="a5beccf5b7f1"
2025-01-29 00:57:48,136 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:549] "Error updating node status, will retry" err="error getting node \"a5beccf5b7f1\": node \"a5beccf5b7f1\" not found"
2025-01-29 00:57:48,149 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Annotations and labels have been set successfully on node: a5beccf5b7f1
2025-01-29 00:57:48,150 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting flannel with backend vxlan
2025-01-29 00:57:48,268 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:698] "Successfully retrieved node IP(s)" IPs=["172.17.0.3"]
2025-01-29 00:57:48,269 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:234] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
2025-01-29 00:57:48,271 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:185] "Starting" version="v1.32.1+k3s1"
2025-01-29 00:57:48,271 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:187] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 00:57:48,271 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:243] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
2025-01-29 00:57:48,272 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server_linux.go:170] "Using iptables Proxier"
2025-01-29 00:57:48,273 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [proxier.go:255] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
2025-01-29 00:57:48,275 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-01-29 00:57:48,275 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-01-29 00:57:48,275 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
2025-01-29 00:57:48,277 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:10257
2025-01-29 00:57:48,277 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 00:57:48,278 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:497] "Version info" version="v1.32.1+k3s1"
2025-01-29 00:57:48,278 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:499] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 00:57:48,280 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [config.go:199] "Starting service config controller"
2025-01-29 00:57:48,280 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [config.go:105] "Starting endpoint slice config controller"
2025-01-29 00:57:48,280 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [config.go:329] "Starting node config controller"
2025-01-29 00:57:48,281 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="serviceaccount-token-controller"
2025-01-29 00:57:48,290 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="endpoints-controller"
2025-01-29 00:57:48,290 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [endpoints_controller.go:182] "Starting endpoint controller"
2025-01-29 00:57:48,295 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="endpointslice-controller"
2025-01-29 00:57:48,295 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [endpointslice_controller.go:281] "Starting endpoint slice controller"
2025-01-29 00:57:48,299 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="token-cleaner-controller"
2025-01-29 00:57:48,300 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="selinux-warning-controller" requiredFeatureGates=["SELinuxChangePolicy"]
2025-01-29 00:57:48,300 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tokencleaner.go:117] "Starting token cleaner controller"
2025-01-29 00:57:48,315 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="resourcequota-controller"
2025-01-29 00:57:48,315 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [resource_quota_controller.go:300] "Starting resource quota controller"
2025-01-29 00:57:48,321 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="job-controller"
2025-01-29 00:57:48,321 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [job_controller.go:243] "Starting job controller"
2025-01-29 00:57:48,326 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="certificatesigningrequest-approving-controller"
2025-01-29 00:57:48,326 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrapproving"
2025-01-29 00:57:48,337 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:112] "No Secondary Service CIDR provided. Skipping filtering out secondary service addresses"
2025-01-29 00:57:48,337 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="node-ipam-controller"
2025-01-29 00:57:48,337 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:723] "Skipping a cloud provider controller" controller="node-route-controller"
2025-01-29 00:57:48,337 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_ipam_controller.go:141] "Starting ipam controller"
2025-01-29 00:57:48,342 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Done waiting for CRD helmcharts.helm.cattle.io to become available
2025-01-29 00:57:48,343 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for CRD helmchartconfigs.helm.cattle.io to become available
2025-01-29 00:57:48,345 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-protection-controller"
2025-01-29 00:57:48,345 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [pv_protection_controller.go:81] "Starting PV protection controller"
2025-01-29 00:57:48,354 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:502] "Fast updating node status as it just became ready"
2025-01-29 00:57:48,384 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="root-ca-certificate-publisher-controller"
2025-01-29 00:57:48,384 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [publisher.go:107] "Starting root CA cert publisher controller"
2025-01-29 00:57:48,537 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="replicationcontroller-controller"
2025-01-29 00:57:48,540 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:217] "Starting controller" name="replicationcontroller"
2025-01-29 00:57:48,787 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="namespace-controller"
2025-01-29 00:57:48,787 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [namespace_controller.go:202] "Starting namespace controller"
2025-01-29 00:57:48,845 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Done waiting for CRD helmchartconfigs.helm.cattle.io to become available
2025-01-29 00:57:48,845 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing static file: /var/lib/rancher/k3s/server/static/charts/traefik-27.0.201+up27.0.2.tgz
2025-01-29 00:57:48,846 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing static file: /var/lib/rancher/k3s/server/static/charts/traefik-crd-27.0.201+up27.0.2.tgz
2025-01-29 00:57:48,846 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml
2025-01-29 00:57:48,847 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml
2025-01-29 00:57:48,847 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml
2025-01-29 00:57:48,847 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/runtimes.yaml
2025-01-29 00:57:48,847 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/ccm.yaml
2025-01-29 00:57:48,847 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/coredns.yaml
2025-01-29 00:57:48,847 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/local-storage.yaml
2025-01-29 00:57:48,847 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml
2025-01-29 00:57:48,848 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml
2025-01-29 00:57:48,848 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml
2025-01-29 00:57:48,848 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml
2025-01-29 00:57:48,849 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/rolebindings.yaml
2025-01-29 00:57:48,849 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting dynamiclistener CN filter node controller with SANs: [localhost 127.0.0.1 ::1 localhost a5beccf5b7f1 172.17.0.3 10.43.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local]
2025-01-29 00:57:48,850 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Tunnel server egress proxy mode: agent
2025-01-29 00:57:48,954 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting k3s.cattle.io/v1, Kind=Addon controller
2025-01-29 00:57:48,954 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating deploy event broadcaster
2025-01-29 00:57:48,965 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apiserver.go:52] "Watching apiserver"
2025-01-29 00:57:48,983 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [desired_state_of_world_populator.go:157] "Finished populating initial desired state of world"
2025-01-29 00:57:49,034 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [graph_builder.go:351] "Running" component="GraphBuilder"
2025-01-29 00:57:49,034 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="garbage-collector-controller"
2025-01-29 00:57:49,057 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Node controller
2025-01-29 00:57:49,058 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating helm-controller event broadcaster
2025-01-29 00:57:49,069 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Cluster dns configmap has been set successfully
2025-01-29 00:57:49,075 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Labels and annotations have been set successfully on node: a5beccf5b7f1
2025-01-29 00:57:49,166 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting helm.cattle.io/v1, Kind=HelmChart controller
2025-01-29 00:57:49,166 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting helm.cattle.io/v1, Kind=HelmChartConfig controller
2025-01-29 00:57:49,168 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding controller
2025-01-29 00:57:49,171 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting batch/v1, Kind=Job controller
2025-01-29 00:57:49,171 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Secret controller
2025-01-29 00:57:49,171 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=ConfigMap controller
2025-01-29 00:57:49,171 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=ServiceAccount controller
2025-01-29 00:57:49,293 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="daemonset-controller"
2025-01-29 00:57:49,294 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [daemon_controller.go:294] "Starting daemon sets controller"
2025-01-29 00:57:49,584 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="horizontal-pod-autoscaler-controller"
2025-01-29 00:57:49,584 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [horizontal.go:201] "Starting HPA controller"
2025-01-29 00:57:49,629 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Updating TLS secret for kube-system/k3s-serving (count: 10): map[listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.17.0.3:172.17.0.3 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-a5beccf5b7f1:a5beccf5b7f1 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=A6981EECC166907766259FF7C13F1AEDB31169D0]
2025-01-29 00:57:49,632 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Active TLS secret kube-system/k3s-serving (ver=244) (count 10): map[listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.17.0.3:172.17.0.3 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-a5beccf5b7f1:a5beccf5b7f1 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=A6981EECC166907766259FF7C13F1AEDB31169D0]
2025-01-29 00:57:49,728 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Updating TLS secret for kube-system/k3s-serving (count: 10): map[listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.17.0.3:172.17.0.3 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-a5beccf5b7f1:a5beccf5b7f1 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=A6981EECC166907766259FF7C13F1AEDB31169D0]
2025-01-29 00:57:49,734 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="legacy-serviceaccount-token-cleaner-controller"
2025-01-29 00:57:49,734 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:723] "Skipping a cloud provider controller" controller="service-lb-controller"
2025-01-29 00:57:49,734 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [legacy_serviceaccount_token_cleaner.go:103] "Starting legacy service account token cleaner controller"
2025-01-29 00:57:49,884 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="clusterrole-aggregation-controller"
2025-01-29 00:57:49,884 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [clusterroleaggregation_controller.go:194] "Starting ClusterRoleAggregator controller"
2025-01-29 00:57:50,034 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="ephemeral-volume-controller"
2025-01-29 00:57:50,035 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:173] "Starting ephemeral volume controller"
2025-01-29 00:57:50,035 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="storageversion-garbage-collector-controller" requiredFeatureGates=["APIServerIdentity","StorageVersionAPI"]
2025-01-29 00:57:50,035 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="service-cidr-controller" requiredFeatureGates=["MultiCIDRServiceAllocator"]
2025-01-29 00:57:50,184 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="endpointslice-mirroring-controller"
2025-01-29 00:57:50,185 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [endpointslicemirroring_controller.go:227] "Starting EndpointSliceMirroring controller"
2025-01-29 00:57:50,334 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="pod-garbage-collector-controller"
2025-01-29 00:57:50,334 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [gc_controller.go:99] "Starting GC controller"
2025-01-29 00:57:50,461 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="a5beccf5b7f1" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodePasswordValidationComplete" message="Deferred node password secret validation complete"
2025-01-29 00:57:50,485 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="cronjob-controller"
2025-01-29 00:57:50,485 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:743] "Warning: skipping controller" controller="storage-version-migrator-controller"
2025-01-29 00:57:50,485 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cronjob_controllerv2.go:145] "Starting cronjob controller v2"
2025-01-29 00:57:50,634 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="deployment-controller"
2025-01-29 00:57:50,634 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:728] "Warning: controller is disabled" controller="bootstrap-signer-controller"
2025-01-29 00:57:50,634 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [deployment_controller.go:173] "Starting controller" controller="deployment"
2025-01-29 00:57:50,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:432] "Controller will reconcile labels"
2025-01-29 00:57:50,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="node-lifecycle-controller"
2025-01-29 00:57:50,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:466] "Sending events to api server"
2025-01-29 00:57:50,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:477] "Starting node controller"
2025-01-29 00:57:50,835 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-binder-controller"
2025-01-29 00:57:50,835 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="resourceclaim-controller" requiredFeatureGates=["DynamicResourceAllocation"]
2025-01-29 00:57:50,835 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [pv_controller_base.go:308] "Starting persistent volume controller"
2025-01-29 00:57:50,958 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/ccm" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/ccm.yaml\""
2025-01-29 00:57:50,975 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/ccm" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/ccm.yaml\""
2025-01-29 00:57:50,982 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/coredns.yaml\""
2025-01-29 00:57:51,034 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="validatingadmissionpolicy-status-controller"
2025-01-29 00:57:51,083 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="taint-eviction-controller"
2025-01-29 00:57:51,083 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [taint_eviction.go:281] "Starting" controller="taint-eviction-controller"
2025-01-29 00:57:51,084 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [taint_eviction.go:287] "Sending events to api server"
2025-01-29 00:57:51,087 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs={"IPv4":"10.43.0.10"}
2025-01-29 00:57:51,087 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/coredns.yaml\""
2025-01-29 00:57:51,094 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/local-storage" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/local-storage.yaml\""
2025-01-29 00:57:51,188 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/local-storage" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/local-storage.yaml\""
2025-01-29 00:57:51,194 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/aggregated-metrics-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml\""
2025-01-29 00:57:51,234 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolumeclaim-protection-controller"
2025-01-29 00:57:51,234 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [pvc_protection_controller.go:168] "Starting PVC protection controller"
2025-01-29 00:57:51,265 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/aggregated-metrics-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml\""
2025-01-29 00:57:51,271 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-delegator" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml\""
2025-01-29 00:57:51,276 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-delegator" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml\""
2025-01-29 00:57:51,281 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml\""
2025-01-29 00:57:51,286 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml\""
2025-01-29 00:57:51,293 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-apiservice" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml\""
2025-01-29 00:57:51,300 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-apiservice" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml\""
2025-01-29 00:57:51,304 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 00:57:51,305 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:146] "Unhandled Error" err=<
2025-01-29 00:57:51,305 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 00:57:51,305 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 00:57:51,305 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:143] error resolving kube-system/metrics-server: service "metrics-server" not found
2025-01-29 00:57:51,306 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-deployment" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml\""
2025-01-29 00:57:51,317 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-deployment" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml\""
2025-01-29 00:57:51,323 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-service" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml\""
2025-01-29 00:57:51,329 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="kube-system/metrics-server" clusterIPs={"IPv4":"10.43.67.139"}
2025-01-29 00:57:51,329 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-service" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml\""
2025-01-29 00:57:51,335 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 00:57:51,335 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:146] "Unhandled Error" err=<
2025-01-29 00:57:51,336 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 00:57:51,336 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 00:57:51,336 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:143] error resolving kube-system/metrics-server: endpoints "metrics-server" not found
2025-01-29 00:57:51,339 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/resource-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml\""
2025-01-29 00:57:51,376 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/resource-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml\""
2025-01-29 00:57:51,381 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/rolebindings" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/rolebindings.yaml\""
2025-01-29 00:57:51,385 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="replicaset-controller"
2025-01-29 00:57:51,385 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:217] "Starting controller" name="replicaset"
2025-01-29 00:57:51,488 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/rolebindings" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/rolebindings.yaml\""
2025-01-29 00:57:51,494 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/runtimes" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/runtimes.yaml\""
2025-01-29 00:57:51,518 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/runtimes" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/runtimes.yaml\""
2025-01-29 00:57:51,584 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="disruption-controller"
2025-01-29 00:57:51,584 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [disruption.go:452] "Sending events to api server."
2025-01-29 00:57:51,584 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [disruption.go:463] "Starting disruption controller"
2025-01-29 00:57:51,634 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-kubelet-serving"
2025-01-29 00:57:51,634 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/server-ca.key"
2025-01-29 00:57:51,635 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-kubelet-client"
2025-01-29 00:57:51,635 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/client-ca.key"
2025-01-29 00:57:51,635 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-kube-apiserver-client"
2025-01-29 00:57:51,636 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/client-ca.key"
2025-01-29 00:57:51,636 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="certificatesigningrequest-signing-controller"
2025-01-29 00:57:51,636 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-legacy-unknown"
2025-01-29 00:57:51,636 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/server-ca.key"
2025-01-29 00:57:51,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="certificatesigningrequest-cleaner-controller"
2025-01-29 00:57:51,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cleaner.go:83] "Starting CSR cleaner controller"
2025-01-29 00:57:51,834 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="ttl-controller"
2025-01-29 00:57:51,834 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:723] "Skipping a cloud provider controller" controller="cloud-node-lifecycle-controller"
2025-01-29 00:57:51,834 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [ttl_controller.go:127] "Starting TTL controller"
2025-01-29 00:57:51,952 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Tunnel authorizer set Kubelet Port 0.0.0.0:10250
2025-01-29 00:57:51,989 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-expander-controller"
2025-01-29 00:57:51,990 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="volumeattributesclass-protection-controller" requiredFeatureGates=["VolumeAttributesClass"]
2025-01-29 00:57:51,991 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [expand_controller.go:329] "Starting expand controller"
2025-01-29 00:57:52,127 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 00:57:52,135 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="ttl-after-finished-controller"
2025-01-29 00:57:52,135 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="kube-apiserver-serving-clustertrustbundle-publisher-controller" requiredFeatureGates=["ClusterTrustBundle"]
2025-01-29 00:57:52,135 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [ttlafterfinished_controller.go:112] "Starting TTL after finished controller"
2025-01-29 00:57:52,290 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="serviceaccount-controller"
2025-01-29 00:57:52,290 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serviceaccounts_controller.go:114] "Starting service account controller"
2025-01-29 00:57:52,302 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 00:57:52,302 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 00:57:52,302 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:102] "Unhandled Error" err=<
2025-01-29 00:57:52,302 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 00:57:52,302 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 00:57:52,435 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="statefulset-controller"
2025-01-29 00:57:52,435 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [stateful_set.go:166] "Starting stateful set controller"
2025-01-29 00:57:52,460 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 00:57:52,584 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-attach-detach-controller"
2025-01-29 00:57:52,585 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [attach_detach_controller.go:338] "Starting attach detach controller"
2025-01-29 00:57:52,613 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [actual_state_of_world.go:541] "Failed to update statusUpdateNeeded field in actual state of world" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"a5beccf5b7f1\" does not exist"
2025-01-29 00:57:52,638 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:177] "Sending events to api server"
2025-01-29 00:57:52,638 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:183] "Starting range CIDR allocator"
2025-01-29 00:57:52,646 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Flannel found PodCIDR assigned for node a5beccf5b7f1
2025-01-29 00:57:52,646 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:428] "Set node PodCIDR" node="a5beccf5b7f1" podCIDRs=["10.42.0.0/24"]
2025-01-29 00:57:52,647 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="a5beccf5b7f1"
2025-01-29 00:57:52,647 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="a5beccf5b7f1"
2025-01-29 00:57:52,648 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] The interface eth0 with ipv4 address 172.17.0.3 will be used by flannel
2025-01-29 00:57:52,654 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:139] Waiting 10m0s for node controller to sync
2025-01-29 00:57:52,654 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:469] Starting kube subnet manager
2025-01-29 00:57:52,657 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Updated coredns NodeHosts entry for a5beccf5b7f1
2025-01-29 00:57:52,659 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Network policy controller waiting for removal of node.cloudprovider.kubernetes.io/uninitialized taint
2025-01-29 00:57:52,681 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:160] Version: v1.32.1+k3s1
2025-01-29 00:57:52,685 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
2025-01-29 00:57:52,685 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-01-29 00:57:52,685 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-01-29 00:57:52,685 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:10258
2025-01-29 00:57:52,685 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 00:57:52,691 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating service-lb-controller event broadcaster
2025-01-29 00:57:52,804 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Node controller
2025-01-29 00:57:52,807 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Pod controller
2025-01-29 00:57:52,811 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting apps/v1, Kind=DaemonSet controller
2025-01-29 00:57:52,814 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting discovery.k8s.io/v1, Kind=EndpointSlice controller
2025-01-29 00:57:52,814 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:329] Started "cloud-node-controller"
2025-01-29 00:57:52,814 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_controller.go:176] Sending events to api server.
2025-01-29 00:57:52,814 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_controller.go:185] Waiting for informer caches to sync
2025-01-29 00:57:52,814 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:329] Started "cloud-node-lifecycle-controller"
2025-01-29 00:57:52,815 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:329] Started "service-lb-controller"
2025-01-29 00:57:52,815 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:306] "node-route-controller" is disabled
2025-01-29 00:57:52,817 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:112] Sending events to api server
2025-01-29 00:57:52,817 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:234] Starting service controller
2025-01-29 00:57:52,884 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:1234] "Initializing eviction metric for zone" zone=""
2025-01-29 00:57:52,886 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:886] "Missing timestamp for Node. Assuming now as a timestamp" node="a5beccf5b7f1"
2025-01-29 00:57:52,886 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:1080] "Controller detected that zone is now in new state" zone="" newState="Normal"
2025-01-29 00:57:52,891 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="a5beccf5b7f1"
2025-01-29 00:57:52,914 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_controller.go:429] Initializing node a5beccf5b7f1 with cloud provider
2025-01-29 00:57:52,918 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_controller.go:474] Successfully initialized node a5beccf5b7f1 with cloud provider
2025-01-29 00:57:52,918 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="a5beccf5b7f1" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="Synced" message="Node synced successfully"
2025-01-29 00:57:52,919 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="a5beccf5b7f1"
2025-01-29 00:57:52,953 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Started tunnel to 172.17.0.3:6443
2025-01-29 00:57:52,953 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Stopped tunnel to 127.0.0.1:6443
2025-01-29 00:57:52,954 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Connecting to proxy" url="wss://172.17.0.3:6443/v1-k3s/connect
2025-01-29 00:57:52,954 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Proxy done" err="context canceled" url="wss://127.0.0.1:6443/v1-k3s/connect
2025-01-29 00:57:52,954 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] error in remotedialer server [400]: websocket: close 1006 (abnormal closure): unexpected EOF
2025-01-29 00:57:52,955 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Handling backend connection request [a5beccf5b7f1]
2025-01-29 00:57:52,955 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Remotedialer connected to proxy" url="wss://172.17.0.3:6443/v1-k3s/connect
2025-01-29 00:57:53,142 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="a5beccf5b7f1"
2025-01-29 00:57:53,212 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 00:57:53,392 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 00:57:53,392 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:146] "Unhandled Error" err=<
2025-01-29 00:57:53,392 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 00:57:53,392 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 00:57:53,393 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:143] error resolving kube-system/metrics-server: no endpoints available for service "metrics-server"
2025-01-29 00:57:53,501 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="661.598855ms"
2025-01-29 00:57:53,502 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="659.349399ms"
2025-01-29 00:57:53,504 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="665.460692ms"
2025-01-29 00:57:53,519 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="16.531035ms"
2025-01-29 00:57:53,522 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="33.964µs"
2025-01-29 00:57:53,528 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="23.693524ms"
2025-01-29 00:57:53,530 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="33.172µs"
2025-01-29 00:57:53,531 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="26.49µs"
2025-01-29 00:57:53,534 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="32.452571ms"
2025-01-29 00:57:53,534 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="32.29µs"
2025-01-29 00:57:53,535 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="41.789µs"
2025-01-29 00:57:53,654 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:146] Node controller sync successful
2025-01-29 00:57:53,654 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [vxlan.go:141] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false
2025-01-29 00:57:53,656 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:636] List of node(a5beccf5b7f1) annotations: map[string]string{"alpha.kubernetes.io/provided-node-ip":"172.17.0.3", "k3s.io/hostname":"a5beccf5b7f1", "k3s.io/internal-ip":"172.17.0.3", "k3s.io/node-args":"[\"server\",\"--disable\",\"traefik\",\"--tls-san\",\"localhost\"]", "k3s.io/node-config-hash":"JO7YSLDHXFTIIPZLLVI7GVGPULZK5EY6PYXUBKR6RNNG4QMX5FBQ====", "k3s.io/node-env":"{}", "node.alpha.kubernetes.io/ttl":"0", "volumes.kubernetes.io/controller-managed-attach-detach":"true"}
2025-01-29 00:57:53,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:490] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.0.0/24]
2025-01-29 00:57:53,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="a5beccf5b7f1"
2025-01-29 00:57:53,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:51] Starting flannel in iptables mode...
2025-01-29 00:57:53,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_NETWORK in file: /run/flannel/subnet.env
2025-01-29 00:57:53,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_SUBNET in file: /run/flannel/subnet.env
2025-01-29 00:57:53,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_IPV6_NETWORK in file: /run/flannel/subnet.env
2025-01-29 00:57:53,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_IPV6_SUBNET in file: /run/flannel/subnet.env
2025-01-29 00:57:53,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:115] Current network or subnet (10.42.0.0/16, 10.42.0.0/24) is not equal to previous one (0.0.0.0/0, 0.0.0.0/0), trying to recycle old iptables rules
2025-01-29 00:57:53,679 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:125] Setting up masking rules
2025-01-29 00:57:53,682 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:226] Changing default FORWARD chain policy to ACCEPT
2025-01-29 00:57:53,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Wrote flannel subnet file to /run/flannel/subnet.env
2025-01-29 00:57:53,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running flannel backend.
2025-01-29 00:57:53,685 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [vxlan_network.go:65] watching for new subnet leases
2025-01-29 00:57:53,698 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:372] bootstrap done
2025-01-29 00:57:53,711 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:372] bootstrap done
2025-01-29 00:57:53,724 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:164] "Starting Kubernetes Scheduler" version="v1.32.1+k3s1"
2025-01-29 00:57:53,724 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:166] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 00:57:53,736 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
2025-01-29 00:57:53,745 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-01-29 00:57:53,745 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-01-29 00:57:53,745 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:10259
2025-01-29 00:57:53,745 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 00:57:53,844 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="34.174µs"
2025-01-29 00:57:53,845 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="26.83µs"
2025-01-29 00:57:53,845 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="24.205µs"
2025-01-29 00:57:53,877 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="38.962µs"
2025-01-29 00:57:53,884 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="27.111µs"
2025-01-29 00:57:53,890 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="32.932µs"
2025-01-29 00:57:54,030 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"custom-config-volume\" (UniqueName: \"kubernetes.io/configmap/10b40697-aca0-459a-89e6-62a084c55320-custom-config-volume\") pod \"coredns-ff8999cc5-l6gwv\" (UID: \"10b40697-aca0-459a-89e6-62a084c55320\") " pod="kube-system/coredns-ff8999cc5-l6gwv"
2025-01-29 00:57:54,030 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-5rr9m\" (UniqueName: \"kubernetes.io/projected/10b40697-aca0-459a-89e6-62a084c55320-kube-api-access-5rr9m\") pod \"coredns-ff8999cc5-l6gwv\" (UID: \"10b40697-aca0-459a-89e6-62a084c55320\") " pod="kube-system/coredns-ff8999cc5-l6gwv"
2025-01-29 00:57:54,030 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/fadf9c8d-4978-48c2-a696-e7869b2b4ac8-config-volume\") pod \"local-path-provisioner-698b58967b-7dc4d\" (UID: \"fadf9c8d-4978-48c2-a696-e7869b2b4ac8\") " pod="kube-system/local-path-provisioner-698b58967b-7dc4d"
2025-01-29 00:57:54,030 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-lrxqm\" (UniqueName: \"kubernetes.io/projected/fadf9c8d-4978-48c2-a696-e7869b2b4ac8-kube-api-access-lrxqm\") pod \"local-path-provisioner-698b58967b-7dc4d\" (UID: \"fadf9c8d-4978-48c2-a696-e7869b2b4ac8\") " pod="kube-system/local-path-provisioner-698b58967b-7dc4d"
2025-01-29 00:57:54,030 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp-dir\" (UniqueName: \"kubernetes.io/empty-dir/676932e0-e898-4eec-b0ae-84cef7a0ac1e-tmp-dir\") pod \"metrics-server-8584b5786c-wp6m4\" (UID: \"676932e0-e898-4eec-b0ae-84cef7a0ac1e\") " pod="kube-system/metrics-server-8584b5786c-wp6m4"
2025-01-29 00:57:54,030 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-gdhbr\" (UniqueName: \"kubernetes.io/projected/676932e0-e898-4eec-b0ae-84cef7a0ac1e-kube-api-access-gdhbr\") pod \"metrics-server-8584b5786c-wp6m4\" (UID: \"676932e0-e898-4eec-b0ae-84cef7a0ac1e\") " pod="kube-system/metrics-server-8584b5786c-wp6m4"
2025-01-29 00:57:54,031 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/10b40697-aca0-459a-89e6-62a084c55320-config-volume\") pod \"coredns-ff8999cc5-l6gwv\" (UID: \"10b40697-aca0-459a-89e6-62a084c55320\") " pod="kube-system/coredns-ff8999cc5-l6gwv"
2025-01-29 00:57:54,394 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 00:57:54,394 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 00:57:54,394 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:102] "Unhandled Error" err=<
2025-01-29 00:57:54,394 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 00:57:54,394 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 00:57:54,765 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting network policy controller version v2.2.1, built on 2025-01-28T18:27:08Z, go1.23.4
2025-01-29 00:57:54,766 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [network_policy_controller.go:164] Starting network policy controller
2025-01-29 00:57:54,803 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [network_policy_controller.go:176] Starting network policy controller full sync goroutine
2025-01-29 00:57:58,060 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="5.201157ms"
2025-01-29 00:57:58,063 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="29.115µs"
2025-01-29 00:57:58,070 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="31.629µs"
2025-01-29 00:57:58,092 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="29.485µs"
2025-01-29 00:57:58,174 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kuberuntime_manager.go:1702] "Updating runtime config through cri with podcidr" CIDR="10.42.0.0/24"
2025-01-29 00:57:58,174 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.42.0.0/24"
2025-01-29 00:57:58,181 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="a5beccf5b7f1"
2025-01-29 00:57:59,067 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="5.726964ms"
2025-01-29 00:57:59,067 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="55.805µs"
2025-01-29 00:58:10,987 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="default/test-hivemq-hivemq-operator-operator" clusterIPs={"IPv4":"10.43.172.198"}
2025-01-29 00:58:11,009 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-hivemq-operator-operator-bc4cbf748" duration="13.509637ms"
2025-01-29 00:58:11,025 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-hivemq-operator-operator-bc4cbf748" duration="14.196663ms"
2025-01-29 00:58:11,026 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-hivemq-operator-operator-bc4cbf748" duration="29.666µs"
2025-01-29 00:58:11,026 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-hivemq-operator-operator-bc4cbf748" duration="23.414µs"
2025-01-29 00:58:11,110 DEBUG c.h.h.t.OperatorHelmChartContainer - Chart 'test-hivemq' installed or upgraded
2025-01-29 00:58:11,144 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-k7stq\" (UniqueName: \"kubernetes.io/projected/277fc94c-330b-46d4-8058-0ed9fd1ea4f3-kube-api-access-k7stq\") pod \"test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2\" (UID: \"277fc94c-330b-46d4-8058-0ed9fd1ea4f3\") " pod="default/test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2"
2025-01-29 00:58:11,144 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"templates\" (UniqueName: \"kubernetes.io/configmap/277fc94c-330b-46d4-8058-0ed9fd1ea4f3-templates\") pod \"test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2\" (UID: \"277fc94c-330b-46d4-8058-0ed9fd1ea4f3\") " pod="default/test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2"
2025-01-29 00:58:12,096 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-hivemq-operator-operator-bc4cbf748" duration="12.385529ms"
2025-01-29 00:58:12,097 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-hivemq-operator-operator-bc4cbf748" duration="35.036µs"
2025-01-29 00:58:14,083 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="17.972501ms"
2025-01-29 00:58:14,084 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="32.992µs"
2025-01-29 00:58:18,753 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="a5beccf5b7f1"
2025-01-29 00:58:18,764 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="default/hivemq-test-hivemq-cc" clusterIPs={"IPv4":"10.43.54.209"}
2025-01-29 00:58:18,770 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="default/hivemq-test-hivemq-mqtt" clusterIPs={"IPv4":"10.43.66.165"}
2025-01-29 00:58:18,772 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-test-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="EnsuringLoadBalancer" message="Ensuring load balancer"
2025-01-29 00:58:18,858 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-test-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="AppliedDaemonSet" message="Applied LoadBalancer DaemonSet kube-system/svclb-hivemq-test-hivemq-mqtt-4fdc25bb"
2025-01-29 00:58:21,109 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-test-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="UpdatedLoadBalancer" message="Updated LoadBalancer with new IPs: [] -> [172.17.0.3]"
2025-01-29 00:58:21,252 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Pending and waiting for Running
2025-01-29 00:58:21,431 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Pending and waiting for Running
2025-01-29 00:58:22,429 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Pending and waiting for Running
2025-01-29 00:58:22,738 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Pending and waiting for Running
2025-01-29 00:58:23,128 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 00:58:23,542 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="16.546544ms"
2025-01-29 00:58:23,559 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="17.212378ms"
2025-01-29 00:58:23,560 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="27.602µs"
2025-01-29 00:58:23,720 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 00:58:23,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"heap-dumps\" (UniqueName: \"kubernetes.io/empty-dir/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-heap-dumps\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"log\" (UniqueName: \"kubernetes.io/empty-dir/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-log\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"dns-wait-config\" (UniqueName: \"kubernetes.io/configmap/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-dns-wait-config\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"shared-data\" (UniqueName: \"kubernetes.io/empty-dir/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-shared-data\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"audit\" (UniqueName: \"kubernetes.io/empty-dir/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-audit\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vj6xb\" (UniqueName: \"kubernetes.io/projected/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-kube-api-access-vj6xb\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"data\" (UniqueName: \"kubernetes.io/empty-dir/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-data\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"live-info\" (UniqueName: \"kubernetes.io/configmap/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-live-info\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"conf-override\" (UniqueName: \"kubernetes.io/empty-dir/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-conf-override\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,724 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"backup\" (UniqueName: \"kubernetes.io/empty-dir/4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec-backup\") pod \"test-hivemq-6ff45d747b-wwx2k\" (UID: \"4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec\") " pod="default/test-hivemq-6ff45d747b-wwx2k"
2025-01-29 00:58:23,952 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 00:58:24,160 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="36.308µs"
2025-01-29 00:58:25,117 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="50.935µs"
2025-01-29 00:58:25,134 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-test-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="UpdatedLoadBalancer" message="Updated LoadBalancer with new IPs: [172.17.0.3] -> [172.17.0.3]"
2025-01-29 00:58:26,119 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="55.584µs"
2025-01-29 00:58:27,119 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="49.082µs"
2025-01-29 00:58:37,138 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="46.307µs"
2025-01-29 00:58:38,136 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="59.732µs"
2025-01-29 00:58:49,241 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="a5beccf5b7f1"
2025-01-29 00:59:09,175 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="10.302125ms"
2025-01-29 00:59:09,176 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-test-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="UpdatedLoadBalancer" message="Updated LoadBalancer with new IPs: [172.17.0.3] -> [172.17.0.3]"
2025-01-29 00:59:09,177 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="42.099µs"
2025-01-29 00:59:39,182 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="6.3337ms"
2025-01-29 00:59:39,182 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/test-hivemq-6ff45d747b" duration="42.801µs"
2025-01-29 00:59:39,216 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 00:59:39,453 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 00:59:39,618 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 00:59:39,719 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 00:59:39,932 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 00:59:40,023 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Running and waiting for Running
2025-01-29 00:59:40,325 INFO t.localhost/testcontainers/6bnecnaskpov4nfq:latest - Container localhost/testcontainers/6bnecnaskpov4nfq:latest started in PT1M57.305817429S
2025-01-29 00:59:40,397 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Starting] Starting kubelet. [null:a5beccf5b7f1]
2025-01-29 00:59:40,398 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Warning [InvalidDiskCapacity] invalid capacity 0 on image filesystem [null:a5beccf5b7f1]
2025-01-29 00:59:40,398 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeHasSufficientMemory] Node a5beccf5b7f1 status is now: NodeHasSufficientMemory [null:a5beccf5b7f1]
2025-01-29 00:59:40,398 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeHasNoDiskPressure] Node a5beccf5b7f1 status is now: NodeHasNoDiskPressure [null:a5beccf5b7f1]
2025-01-29 00:59:40,399 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeHasSufficientPID] Node a5beccf5b7f1 status is now: NodeHasSufficientPID [null:a5beccf5b7f1]
2025-01-29 00:59:40,399 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeAllocatableEnforced] Updated Node Allocatable limit across pods [null:a5beccf5b7f1]
2025-01-29 00:59:40,400 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeReady] Node a5beccf5b7f1 status is now: NodeReady [null:a5beccf5b7f1]
2025-01-29 00:59:40,401 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodePasswordValidationComplete] Deferred node password secret validation complete [null:a5beccf5b7f1]
2025-01-29 00:59:40,401 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [RegisteredNode] Node a5beccf5b7f1 event: Registered Node a5beccf5b7f1 in Controller [null:a5beccf5b7f1]
2025-01-29 00:59:40,402 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Synced] Node synced successfully [null:a5beccf5b7f1]
2025-01-29 00:59:40,402 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [EnsuringLoadBalancer] Ensuring load balancer [default:hivemq-test-hivemq-mqtt]
2025-01-29 00:59:40,403 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [AppliedDaemonSet] Applied LoadBalancer DaemonSet kube-system/svclb-hivemq-test-hivemq-mqtt-4fdc25bb [default:hivemq-test-hivemq-mqtt]
2025-01-29 00:59:40,403 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [UpdatedLoadBalancer] Updated LoadBalancer with new IPs: [] -> [172.17.0.3] [default:hivemq-test-hivemq-mqtt]
2025-01-29 00:59:40,403 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [UpdatedLoadBalancer] Updated LoadBalancer with new IPs: [172.17.0.3] -> [172.17.0.3] [default:hivemq-test-hivemq-mqtt]
2025-01-29 00:59:40,404 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned default/test-hivemq-6ff45d747b-wwx2k to a5beccf5b7f1 [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,404 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulling] Pulling image "busybox:latest" [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,405 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "busybox:latest" in 962ms (962ms including waiting). Image size: 2167089 bytes. [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,405 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Created] Created container: init-shared [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,406 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Started] Started container init-shared [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,406 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulled] Container image "hivemq/init-dns-wait:snapshot" already present on machine [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,406 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Created] Created container: dns-wait [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,408 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Started] Started container dns-wait [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,409 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulled] Container image "hivemq/hivemq4:k8s-4.36.0" already present on machine [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,409 INFO c.h.h.t.OperatorHelmChartContainer - Received Pulled event for container hivemq in pod test-hivemq-6ff45d747b-wwx2k [4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec]
2025-01-29 00:59:40,409 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Created] Created container: hivemq [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,409 INFO c.h.h.t.OperatorHelmChartContainer - Received Created event for container hivemq in pod test-hivemq-6ff45d747b-wwx2k [4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec]
2025-01-29 00:59:40,436 INFO c.h.h.t.OperatorHelmChartContainer - Started log watcher for hivemq in pod test-hivemq-6ff45d747b-wwx2k [4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec]
2025-01-29 00:59:40,437 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Started] Started container hivemq [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,437 INFO c.h.h.t.OperatorHelmChartContainer - Received Started event for container hivemq in pod test-hivemq-6ff45d747b-wwx2k [4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec]
2025-01-29 00:59:40,438 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: Log statement not present (yet)
 [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,439 INFO c.h.h.t.OperatorHelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-6ff45d747b-wwx2k [4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec]
2025-01-29 00:59:40,439 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Warning [Unhealthy] Liveness probe failed: dial tcp 10.42.0.7:1883: connect: connection refused [default:test-hivemq-6ff45d747b-wwx2k]
2025-01-29 00:59:40,439 INFO c.h.h.t.OperatorHelmChartContainer - Received Unhealthy event for container hivemq in pod test-hivemq-6ff45d747b-wwx2k [4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec]
2025-01-29 00:59:40,440 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: test-hivemq-6ff45d747b-wwx2k [default:test-hivemq-6ff45d747b]
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Copying external files
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Rewriting config.xml...
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Creating initial lastUpdate files...
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Disabling Prometheus
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Pod info:
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] extension-names=hivemq-kafka-extension hivemq-google-cloud-pubsub-extension hivemq-bridge-extension hivemq-enterprise-security-extension hivemq-distributed-tracing-extension hivemq-amazon-kinesis-extension
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] extension-uris=preinstalled preinstalled preinstalled preinstalled preinstalled preinstalled
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] extension-states=false false false false false false
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] extensions-static=false false false false false false
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Installing extension #0 with name: hivemq-kafka-extension, URI: preinstalled, enabled state: false
2025-01-29 00:59:40,442 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ 3 != 3 ]]
2025-01-29 00:59:40,442 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_URI=preinstalled
2025-01-29 00:59:40,442 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-kafka-extension
2025-01-29 00:59:40,442 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_STATE=false
2025-01-29 00:59:40,442 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-kafka-extension
2025-01-29 00:59:40,442 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] ++ mktemp -d
2025-01-29 00:59:40,442 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + install_dir=/tmp/tmp.ITpCbLgE3k
2025-01-29 00:59:40,442 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set +e
2025-01-29 00:59:40,441 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned default/test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2 to a5beccf5b7f1 [default:test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /opt/hivemq/extensions/hivemq-kafka-extension/DISABLED ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set -e
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ false == \f\a\l\s\e ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + touch /opt/hivemq/extensions/hivemq-kafka-extension/DISABLED
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + /opt/hivemq/bin/run_initialization.sh hivemq-kafka-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-kafka-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-kafka-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + cd /opt/hivemq/extensions/hivemq-kafka-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f init_tmp ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /etc/podinfo/init-extension-hivemq-kafka-extension ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Installing extension #1 with name: hivemq-google-cloud-pubsub-extension, URI: preinstalled, enabled state: false
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ 3 != 3 ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_URI=preinstalled
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-google-cloud-pubsub-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_STATE=false
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] ++ mktemp -d
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + install_dir=/tmp/tmp.mrCcV60nzs
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set +e
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension/DISABLED ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set -e
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ false == \f\a\l\s\e ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + touch /opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension/DISABLED
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + /opt/hivemq/bin/run_initialization.sh hivemq-google-cloud-pubsub-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-google-cloud-pubsub-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + cd /opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f init_tmp ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /etc/podinfo/init-extension-hivemq-google-cloud-pubsub-extension ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Installing extension #2 with name: hivemq-bridge-extension, URI: preinstalled, enabled state: false
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ 3 != 3 ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_URI=preinstalled
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-bridge-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_STATE=false
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-bridge-extension
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] ++ mktemp -d
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + install_dir=/tmp/tmp.KzLXGdhQA9
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set +e
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /opt/hivemq/extensions/hivemq-bridge-extension/DISABLED ]]
2025-01-29 00:59:40,443 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set -e
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ false == \f\a\l\s\e ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + touch /opt/hivemq/extensions/hivemq-bridge-extension/DISABLED
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + /opt/hivemq/bin/run_initialization.sh hivemq-bridge-extension
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-bridge-extension
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-bridge-extension
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + cd /opt/hivemq/extensions/hivemq-bridge-extension
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f init_tmp ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /etc/podinfo/init-extension-hivemq-bridge-extension ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Installing extension #3 with name: hivemq-enterprise-security-extension, URI: preinstalled, enabled state: false
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ 3 != 3 ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_URI=preinstalled
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-enterprise-security-extension
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_STATE=false
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-enterprise-security-extension
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] ++ mktemp -d
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + install_dir=/tmp/tmp.z7bk3X1Gzy
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set +e
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /opt/hivemq/extensions/hivemq-enterprise-security-extension/DISABLED ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set -e
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ false == \f\a\l\s\e ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + touch /opt/hivemq/extensions/hivemq-enterprise-security-extension/DISABLED
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + /opt/hivemq/bin/run_initialization.sh hivemq-enterprise-security-extension
2025-01-29 00:59:40,445 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulled] Container image "hivemq/hivemq-operator:snapshot" already present on machine [default:test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2]
2025-01-29 00:59:40,445 INFO c.h.h.t.OperatorHelmChartContainer - Received Pulled event for container operator in pod test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2 [277fc94c-330b-46d4-8058-0ed9fd1ea4f3]
2025-01-29 00:59:40,445 INFO c.h.h.t.OperatorHelmChartContainer - [POD] test-hivemq-6ff45d747b-wwx2k [4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec] in default was ADDED
2025-01-29 00:59:40,445 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Created] Created container: operator [default:test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2]
2025-01-29 00:59:40,445 INFO c.h.h.t.OperatorHelmChartContainer - Received Created event for container operator in pod test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2 [277fc94c-330b-46d4-8058-0ed9fd1ea4f3]
2025-01-29 00:59:40,447 INFO c.h.h.t.OperatorHelmChartContainer - [POD] test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2 [277fc94c-330b-46d4-8058-0ed9fd1ea4f3] in default was ADDED
2025-01-29 00:59:40,444 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-enterprise-security-extension
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-enterprise-security-extension
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + cd /opt/hivemq/extensions/hivemq-enterprise-security-extension
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f init_tmp ]]
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /etc/podinfo/init-extension-hivemq-enterprise-security-extension ]]
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + echo 'Using init script from config map'
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + cat /etc/podinfo/init-extension-hivemq-enterprise-security-extension
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Using init script from config map
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + echo 'Executing initialization script'
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Executing initialization script
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + chmod +x init
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + ./init
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]                                  Dload  Upload   Total   Spent    Left  Speed
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]  19  910k   19  175k    0     0   546k      0  0:00:01 --:--:--  0:00:01  546k
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 100  910k  100  910k    0     0  2432k      0 --:--:-- --:--:-- --:--:-- 2429k
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Installing extension #4 with name: hivemq-distributed-tracing-extension, URI: preinstalled, enabled state: false
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ 3 != 3 ]]
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_URI=preinstalled
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-distributed-tracing-extension
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_STATE=false
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-distributed-tracing-extension
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] ++ mktemp -d
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + install_dir=/tmp/tmp.4JO9gLT5mK
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set +e
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [POD] coredns-ff8999cc5-l6gwv [10b40697-aca0-459a-89e6-62a084c55320] in kube-system was ADDED
2025-01-29 00:59:40,452 INFO c.h.h.t.OperatorHelmChartContainer - [POD] local-path-provisioner-698b58967b-7dc4d [fadf9c8d-4978-48c2-a696-e7869b2b4ac8] in kube-system was ADDED
2025-01-29 00:59:40,451 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /opt/hivemq/extensions/hivemq-distributed-tracing-extension/DISABLED ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set -e
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ false == \f\a\l\s\e ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + touch /opt/hivemq/extensions/hivemq-distributed-tracing-extension/DISABLED
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + /opt/hivemq/bin/run_initialization.sh hivemq-distributed-tracing-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-distributed-tracing-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-distributed-tracing-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + cd /opt/hivemq/extensions/hivemq-distributed-tracing-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f init_tmp ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /etc/podinfo/init-extension-hivemq-distributed-tracing-extension ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] Installing extension #5 with name: hivemq-amazon-kinesis-extension, URI: preinstalled, enabled state: false
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ 3 != 3 ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_URI=preinstalled
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-amazon-kinesis-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_STATE=false
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-amazon-kinesis-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] ++ mktemp -d
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + install_dir=/tmp/tmp.l1glo7cXTX
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set +e
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /opt/hivemq/extensions/hivemq-amazon-kinesis-extension/DISABLED ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + set -e
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ false == \f\a\l\s\e ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + touch /opt/hivemq/extensions/hivemq-amazon-kinesis-extension/DISABLED
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + was_enabled=0
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + /opt/hivemq/bin/run_initialization.sh hivemq-amazon-kinesis-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + EXTENSION_NAME=hivemq-amazon-kinesis-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + TARGET_DIR=/opt/hivemq/extensions/hivemq-amazon-kinesis-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + cd /opt/hivemq/extensions/hivemq-amazon-kinesis-extension
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f init_tmp ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] + [[ -f /etc/podinfo/init-extension-hivemq-amazon-kinesis-extension ]]
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] -------------------------------------------------------------------------
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]                   _    _  _              __  __   ____
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]                  | |  | |(_)            |  \/  | / __ \
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]                  | |__| | _ __   __ ___ | \  / || |  | |
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]                  |  __  || |\ \ / // _ \| |\/| || |  | |
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]                  | |  | || | \ V /|  __/| |  | || |__| |
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]                  |_|  |_||_|  \_/  \___||_|  |_| \___\_\
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] -------------------------------------------------------------------------
2025-01-29 00:59:40,453 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,454 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]   HiveMQ Start Script for Linux/Unix v1.14
2025-01-29 00:59:40,454 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,454 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] -------------------------------------------------------------------------
2025-01-29 00:59:40,454 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,454 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]   HIVEMQ_HOME: /opt/hivemq
2025-01-29 00:59:40,454 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,454 INFO c.h.h.t.OperatorHelmChartContainer - [POD] metrics-server-8584b5786c-wp6m4 [676932e0-e898-4eec-b0ae-84cef7a0ac1e] in kube-system was ADDED
2025-01-29 00:59:40,456 INFO c.h.h.t.OperatorHelmChartContainer - [POD] svclb-hivemq-test-hivemq-mqtt-4fdc25bb-v5gpc [15e8ed43-9063-45ab-9063-c91f59212029] in kube-system was ADDED
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]   JAVA_OPTS: -XX:+UnlockExperimentalVMOptions -XX:InitialRAMPercentage=40 -XX:MaxRAMPercentage=50 -XX:MinRAMPercentage=30 -Djava.net.preferIPv4Stack=true --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/sun.nio.ch=ALL-UNNAMED --add-opens jdk.management/com.sun.management.internal=ALL-UNNAMED --add-exports java.base/jdk.internal.misc=ALL-UNNAMED -Djava.security.egd=file:/dev/./urandom -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9010 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Duser.language=en -Duser.region=US -XX:+CrashOnOutOfMemoryError -XX:+HeapDumpOnOutOfMemoryError
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b]   JAVA_VERSION: 21
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] -------------------------------------------------------------------------
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] 
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Starting HiveMQ Enterprise Server
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - HiveMQ version: 4.36.0
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - HiveMQ home directory: /opt/hivemq
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Log Configuration was overridden by /opt/hivemq/conf/logback.xml
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Adding TCP Listener on bind address 0.0.0.0 and port 1883. Name: tcp-listener-1883. Proxy Protocol supported: false
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting retained messages enabled to true
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting wildcard subscriptions enabled to true
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting subscription identifier enabled to true
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting shared subscriptions enabled to true
2025-01-29 00:59:40,458 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting maximum qos to EXACTLY_ONCE 
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting topic alias enabled to true
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting topic alias maximum per client to 5
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting the number of max queued messages  per client to 1000 entries
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting queued messages strategy for each client to DISCARD
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting the expiry interval for client sessions to 4294967295 seconds
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting the expiry interval for publish messages to 4294967296 seconds
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting the server receive maximum to 10
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting keep alive maximum to 65535 seconds
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting keep alive allow zero to true
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting the maximum packet size for mqtt messages 268435460 bytes
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting global maximum allowed connections to -1
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting the maximum client id length to 65535
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting the timeout for disconnecting idle tcp connections before a connect message was received to 10000 milliseconds
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Throttling the global incoming traffic limit 0 bytes/second
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting the maximum topic length to 65535
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting allow server assigned client identifier to true
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting validate UTF-8 to true
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting payload format validation to false
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting allow-problem-information to true
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting control-center audit log enabled to true
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting rest-api audit log enabled to true
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting HiveMQ Control Center enabled to true 
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting HiveMQ Control Center default login enabled to true 
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting HiveMQ Control Center session idle time to 14400 seconds
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Adding Http-Listener to HiveMQ Control Center Config
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Set TLS to disabled for cluster TCP transport
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting replica count to 2 
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting cluster TCP health-check enabled
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting cluster TCP health-check bind-address to 10.42.0.7
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting cluster TCP health-check bind-address to 9000
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting cluster TCP health-check bind-port to 9000
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting cluster TCP health-check external-address to default
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting cluster TCP health-check external-port to 0
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting cluster heartbeat enabled
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting cluster heartbeat interval to 4000 ms
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting the cluster heartbeat timeout to 30000 ms
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting HiveMQ REST API enabled to false 
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting HiveMQ REST API authentication enabled to false 
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting HiveMQ Health API enabled to false 
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting client event history enabled to false
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting client event history lifetime to 604800000 ms
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting overload protection enabled to true 
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting anonymous usage statistics enabled to false 
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting expired messages topic enabled to false
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting dropped messages topic enabled to false
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Setting dead messages topic enabled to false
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Successfully loaded configuration from '/opt/hivemq/conf/config.xml'.
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Performing sanity checks.
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Soft limit for open files (1048576) satisfies the recommended limit (1000000).
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Hard limit for open files (1048576) satisfies the recommended limit (1000000).
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - HiveMQ license directory (/opt/hivemq/license) satisfies all required file-system permissions.
2025-01-29 00:59:40,459 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - HiveMQ data directory (/opt/hivemq/data) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - HiveMQ log directory (/opt/hivemq/log) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - HiveMQ backup directory (/opt/hivemq/backup) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - HiveMQ audit directory (/opt/hivemq/audit) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - HiveMQ extensions directory (/opt/hivemq/extensions) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-allow-all-extension (/opt/hivemq/extensions/hivemq-allow-all-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-google-cloud-pubsub-extension (/opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-enterprise-security-extension (/opt/hivemq/extensions/hivemq-enterprise-security-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-bridge-extension (/opt/hivemq/extensions/hivemq-bridge-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-kafka-extension (/opt/hivemq/extensions/hivemq-kafka-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-distributed-tracing-extension (/opt/hivemq/extensions/hivemq-distributed-tracing-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-prometheus-extension (/opt/hivemq/extensions/hivemq-prometheus-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-amazon-kinesis-extension (/opt/hivemq/extensions/hivemq-amazon-kinesis-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-k8s-sync-extension (/opt/hivemq/extensions/hivemq-k8s-sync-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,460 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-dns-cluster-discovery (/opt/hivemq/extensions/hivemq-dns-cluster-discovery) satisfies all required file-system permissions.
2025-01-29 00:59:40,461 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-snowflake-extension (/opt/hivemq/extensions/hivemq-snowflake-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,461 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-postgresql-extension (/opt/hivemq/extensions/hivemq-postgresql-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,464 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-mysql-extension (/opt/hivemq/extensions/hivemq-mysql-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,464 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-mongodb-extension (/opt/hivemq/extensions/hivemq-mongodb-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-data-lake-extension (/opt/hivemq/extensions/hivemq-data-lake-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Extension directory hivemq-microsoft-sql-server-extension (/opt/hivemq/extensions/hivemq-microsoft-sql-server-extension) satisfies all required file-system permissions.
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Temporary directory (/tmp) satisfies all required file-system permissions.
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Heap dump directory (/opt/hivemq/dumps) satisfies all required file-system permissions.
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Performed all sanity checks in 95ms. All sanity checks passed successfully.
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - This node's ID is N9DX7
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Clustering is enabled
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Configured WriteBufferManager with size for memtables 311023370 and for the block cache 466535055
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Starting RocksDBMemoryUsageWatchdog.
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - RocksDBMemoryUsageWatchdog is running.
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Created folder /opt/hivemq/data
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/publish_payload_store/040500_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/client_queue/042800_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/client_session_store/040100_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/client_session_subscriptions/043200_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/retained_messages/040800_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/attribute/043100_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/incoming_message_flow/043000_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/data_hub_modules/043000_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/data_hub_schemas/042000_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/data_hub_scripts/042300_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Folder /opt/hivemq/data/persistence/data_hub_policies/042000_R does not exist, trying to create it
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Diagnostic mode is disabled
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - No valid license file found. Using trial license, restricted to 25 connections.
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Native Epoll is available on this platform
2025-01-29 00:59:40,466 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Set extension executor thread pool size to 1
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Set extension executor thread pool keep-alive to 30 seconds
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - initializing RSA key
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - finished initializing RSA key in 1295ms
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Unable to provide size and free metrics for disk /dev/sda: Could not find the corresponding FileStore (OSHI/Java).
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Unable to provide size and free metrics for disk /dev/sdb: Could not find the corresponding FileStore (OSHI/Java).
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Throttling incoming traffic to 0 B/s
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Throttling outgoing traffic to 0 B/s
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - No valid license file for Data Hub found. Using free license, restricted to 1 policy.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Building initial topic tree
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Started JMX Metrics Reporting.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Registered JVM metrics with prefix com.hivemq.jvm.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Registered HiveMQ Health API metrics.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Audit Logger started.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - This node uses '1' CPU cores.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Starting HiveMQ extension system.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Starting extension with id "hivemq-dns-cluster-discovery" at /opt/hivemq/extensions/hivemq-dns-cluster-discovery
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - HiveMQ DNS Cluster Discovery Extension: No DNS server address was set in the configuration file or environment variable.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - HiveMQ DNS Cluster Discovery Extension: No reload interval was set in the configuration file or environment variable. Defaulting to 30.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Extension "DNS Cluster Discovery Extension" version 4.3.3 started successfully.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Starting extension with id "hivemq-k8s-sync-extension" at /opt/hivemq/extensions/hivemq-k8s-sync-extension
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Using TCP cluster transport on address 10.42.0.7 and port 7000
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Using extension cluster discovery
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Could not get configMap modification timestamp for source /hivemq-data/conf/..data, likely no ConfigMap mounted
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Could not get configMap modification timestamp for source /hivemq-data/extensions/..data, likely no ConfigMap mounted
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Could not get configMap modification timestamp for source /hivemq-data/bin/..data, likely no ConfigMap mounted
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Started HiveMQ Kubernetes State Synchronization Extension:1.0.3
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Extension "HiveMQ Kubernetes State Synchronization Extension" version 1.0.3 started successfully.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Starting extension with id "hivemq-allow-all-extension" at /opt/hivemq/extensions/hivemq-allow-all-extension
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] WARN  - 
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] ################################################################################################################
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] # This HiveMQ deployment is not secure! You are lacking Authentication and Authorization.                      #
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] # Right now any MQTT client can connect to the broker with a full set of permissions.                          #
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] # For production usage, add an appropriate security extension and remove the hivemq-allow-all extension.       #
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] # You can download security extensions from the HiveMQ Marketplace (https://www.hivemq.com/extensions/).       #
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] ################################################################################################################
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - Simple authenticator added by extension 'hivemq-allow-all-extension'.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Extension "Allow All Extension" version 1.1.1 started successfully.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - HiveMQ DNS Cluster Discovery Extension: Discovered new address '10.42.0.7'.
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - N9DX7: no members discovered after 2189 ms: creating cluster as first member
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Cluster nodes found by discovery: [N9DX7|0] (1) [N9DX7].
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - State of node N9DX7 changed to UNKNOWN was null. Current cluster node states: {N9DX7=UNKNOWN}
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] DEBUG - State of node N9DX7 set to RUNNING. Current cluster node states: {N9DX7=RUNNING}
2025-01-29 00:59:40,467 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] WARN  - No user for HiveMQ Control Center configured. Starting with default user
2025-01-29 00:59:40,468 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Starting HiveMQ Control Center on address 0.0.0.0 and port 8080
2025-01-29 00:59:40,468 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Mounting HiveMQ Control Center V2 Preview
2025-01-29 00:59:40,468 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Started HiveMQ Control Center in 1404ms
2025-01-29 00:59:40,468 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Starting TCP listener on address 0.0.0.0 and port 1883
2025-01-29 00:59:40,468 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Started TCP Listener on address 0.0.0.0 and on port 1883.
2025-01-29 00:59:40,468 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-6ff45d747b] [hivemq] [4ce1c74b] INFO  - Started HiveMQ in 24993ms
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - Started log watcher for operator in pod test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2 [277fc94c-330b-46d4-8058-0ed9fd1ea4f3]
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] Picked up JAVA_TOOL_OPTIONS: -XX:+UnlockExperimentalVMOptions -XX:InitialRAMPercentage=75 -XX:MaxRAMPercentage=75
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c]  __  __ _                                  _   
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] |  \/  (_) ___ _ __ ___  _ __   __ _ _   _| |_ 
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] | |\/| | |/ __| '__/ _ \| '_ \ / _` | | | | __|
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] | |  | | | (__| | | (_) | | | | (_| | |_| | |_ 
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] |_|  |_|_|\___|_|  \___/|_| |_|\__,_|\__,_|\__|
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c]   Micronaut (v3.5.2)
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] 
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:58:15.235?[0;39m ?[1;30m[main]?[0;39m ?[34mINFO ?[0;39m ?[35mio.micronaut.runtime.Micronaut?[0;39m - Startup completed in 2353ms. Server Running: http://test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2:8443
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:58:16.340?[0;39m ?[1;30m[main]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Initializing HiveMQ operator
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:58:17.402?[0;39m ?[1;30m[main]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Operating from namespace 'default'
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:58:17.535?[0;39m ?[1;30m[pool-3-thread-1]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.AbstractWatcher?[0;39m - CustomResource watcher running for kinds HiveMQCluster
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:58:18.149?[0;39m ?[1;30m[main]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Operator started in 1809ms
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:58:18.449?[0;39m ?[1;30m[pool-3-thread-2]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Syncing state for cluster 'test-hivemq' in namespace 'default'
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:58:22.612?[0;39m ?[1;30m[pool-3-thread-7]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Syncing state for cluster 'test-hivemq' in namespace 'default'
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:58:23.526?[0;39m ?[1;30m[pool-3-thread-2]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.util.DeploymentUtil?[0;39m - Waiting for deployment test-hivemq to roll out...
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:58:24.207?[0;39m ?[1;30m[pool-3-thread-7]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.util.DeploymentUtil?[0;39m - Waiting for deployment test-hivemq to roll out...
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:59:40.038?[0;39m ?[1;30m[pool-3-thread-7]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - State synchronization complete for cluster 'test-hivemq' in namespace 'default' in 77426ms
2025-01-29 00:59:40,476 INFO c.h.h.t.OperatorHelmChartContainer - [test-hivemq-hivemq-operator] [operator] [277fc94c] ?[36m00:59:40.120?[0;39m ?[1;30m[pool-3-thread-2]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - State synchronization complete for cluster 'test-hivemq' in namespace 'default' in 81671ms
2025-01-29 00:59:40,477 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Started] Started container operator [default:test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2]
2025-01-29 00:59:40,477 INFO c.h.h.t.OperatorHelmChartContainer - Received Started event for container operator in pod test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2 [277fc94c-330b-46d4-8058-0ed9fd1ea4f3]
2025-01-29 00:59:40,477 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2 [default:test-hivemq-hivemq-operator-operator-bc4cbf748]
2025-01-29 00:59:40,477 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [ScalingReplicaSet] Scaled up replica set test-hivemq-hivemq-operator-operator-bc4cbf748 from 0 to 1 [default:test-hivemq-hivemq-operator-operator]
2025-01-29 00:59:40,477 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [ScalingReplicaSet] Scaled up replica set test-hivemq-6ff45d747b from 0 to 1 [default:test-hivemq]
2025-01-29 00:59:40,987 INFO c.h.h.t.OperatorHelmChartContainer - Stopped log watcher for operator in pod test-hivemq-hivemq-operator-operator-bc4cbf748-4rwq2 [277fc94c-330b-46d4-8058-0ed9fd1ea4f3]
2025-01-29 00:59:40,987 INFO c.h.h.t.OperatorHelmChartContainer - Stopped log watcher for hivemq in pod test-hivemq-6ff45d747b-wwx2k [4ce1c74b-8c1e-45ef-bb7b-3f7e82c78fec]
2025-01-29 00:59:41,000 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] signal received: \"terminated\", canceling context...
2025-01-29 00:59:41,000 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] TTL events watch channel closed
2025-01-29 00:59:41,000 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down discovery.k8s.io/v1, Kind=EndpointSlice workers
2025-01-29 00:59:41,000 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down apps/v1, Kind=DaemonSet workers
2025-01-29 00:59:41,000 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down /v1, Kind=Pod workers
2025-01-29 00:59:41,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down /v1, Kind=Node workers
2025-01-29 00:59:41,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tlsconfig.go:258] "Shutting down DynamicServingCertificateController"
2025-01-29 00:59:41,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down /v1, Kind=ServiceAccount workers
2025-01-29 00:59:41,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down /v1, Kind=ConfigMap workers
2025-01-29 00:59:41,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down /v1, Kind=Secret workers
2025-01-29 00:59:41,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down batch/v1, Kind=Job workers
2025-01-29 00:59:41,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding workers
2025-01-29 00:59:41,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down helm.cattle.io/v1, Kind=HelmChartConfig workers
2025-01-29 00:59:41,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Shutting down helm.cattle.io/v1, Kind=HelmChart workers
2025-01-29 00:59:41,134 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 
2025-01-29 00:59:41,134 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 
]]></system-out>
  </testcase>
  <system-out><![CDATA[]]></system-out>
  <system-err><![CDATA[]]></system-err>
</testsuite>
