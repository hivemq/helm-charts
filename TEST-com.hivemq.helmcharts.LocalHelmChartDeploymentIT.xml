<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="com.hivemq.helmcharts.LocalHelmChartDeploymentIT" tests="1" skipped="0" failures="0" errors="0" timestamp="2025-01-29T17:04:50" hostname="fv-az1693-991" time="119.459">
  <properties/>
  <testcase name="withLocalImages_mqttMessagePublishedReceived()" classname="com.hivemq.helmcharts.LocalHelmChartDeploymentIT" time="119.459">
    <system-out><![CDATA[2025-01-29 17:04:50,182 INFO t.localhost/testcontainers/z6wwrsag35yrdxlc:latest - Creating container for image: localhost/testcontainers/z6wwrsag35yrdxlc:latest
2025-01-29 17:04:50,301 INFO t.localhost/testcontainers/z6wwrsag35yrdxlc:latest - Container localhost/testcontainers/z6wwrsag35yrdxlc:latest is starting: e992ce4f78638de54d749925204c575057bc4ea470fdd2996c4b320e612307b4
2025-01-29 17:04:50,653 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting k3s v1.32.1+k3s1 (6a322f12)
2025-01-29 17:04:50,656 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Configuring sqlite3 database connection pooling: maxIdleConns=2, maxOpenConns=0, connMaxLifetime=0s
2025-01-29 17:04:50,656 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Configuring database table schema and indexes, this may take a moment...
2025-01-29 17:04:50,659 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Database tables and indexes are up to date
2025-01-29 17:04:50,662 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Kine available at unix://kine.sock
2025-01-29 17:04:50,836 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Saving cluster bootstrap data to datastore
2025-01-29 17:04:50,837 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] dynamiclistener [::]:6443: no cached certificate available for preload - deferring certificate load until storage initialization or first client request
2025-01-29 17:04:50,837 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Active TLS secret / (ver=) (count 10): map[listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.17.0.3:172.17.0.3 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-e992ce4f7863:e992ce4f7863 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=66F5AD3322EF9A733EECD9E896E217296F5EE33D]
2025-01-29 17:04:50,997 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kube-apiserver --advertise-port=6443 --allow-privileged=true --anonymous-auth=false --api-audiences=https://kubernetes.default.svc.cluster.local,k3s --authorization-mode=Node,RBAC --bind-address=127.0.0.1 --cert-dir=/var/lib/rancher/k3s/server/tls/temporary-certs --client-ca-file=/var/lib/rancher/k3s/server/tls/client-ca.crt --egress-selector-config-file=/var/lib/rancher/k3s/server/etc/egress-selector-config.yaml --enable-admission-plugins=NodeRestriction --enable-aggregator-routing=true --enable-bootstrap-token-auth=true --etcd-servers=unix://kine.sock --kubelet-certificate-authority=/var/lib/rancher/k3s/server/tls/server-ca.crt --kubelet-client-certificate=/var/lib/rancher/k3s/server/tls/client-kube-apiserver.crt --kubelet-client-key=/var/lib/rancher/k3s/server/tls/client-kube-apiserver.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --profiling=false --proxy-client-cert-file=/var/lib/rancher/k3s/server/tls/client-auth-proxy.crt --proxy-client-key-file=/var/lib/rancher/k3s/server/tls/client-auth-proxy.key --requestheader-allowed-names=system:auth-proxy --requestheader-client-ca-file=/var/lib/rancher/k3s/server/tls/request-header-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6444 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/rancher/k3s/server/tls/service.key --service-account-signing-key-file=/var/lib/rancher/k3s/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --service-node-port-range=30000-32767 --storage-backend=etcd3 --tls-cert-file=/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305 --tls-private-key-file=/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.key
2025-01-29 17:04:50,997 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kube-scheduler --authentication-kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --authorization-kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --bind-address=127.0.0.1 --kubeconfig=/var/lib/rancher/k3s/server/cred/scheduler.kubeconfig --leader-elect=false --profiling=false --secure-port=10259
2025-01-29 17:04:50,998 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for API server to become available
2025-01-29 17:04:50,998 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
2025-01-29 17:04:50,998 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kube-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --bind-address=127.0.0.1 --cluster-cidr=10.42.0.0/16 --cluster-signing-kube-apiserver-client-cert-file=/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt --cluster-signing-kube-apiserver-client-key-file=/var/lib/rancher/k3s/server/tls/client-ca.key --cluster-signing-kubelet-client-cert-file=/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt --cluster-signing-kubelet-client-key-file=/var/lib/rancher/k3s/server/tls/client-ca.key --cluster-signing-kubelet-serving-cert-file=/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt --cluster-signing-kubelet-serving-key-file=/var/lib/rancher/k3s/server/tls/server-ca.key --cluster-signing-legacy-unknown-cert-file=/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt --cluster-signing-legacy-unknown-key-file=/var/lib/rancher/k3s/server/tls/server-ca.key --configure-cloud-routes=false --controllers=*,tokencleaner,-service,-route,-cloud-node-lifecycle --kubeconfig=/var/lib/rancher/k3s/server/cred/controller.kubeconfig --leader-elect=false --profiling=false --root-ca-file=/var/lib/rancher/k3s/server/tls/server-ca.crt --secure-port=10257 --service-account-private-key-file=/var/lib/rancher/k3s/server/tls/service.current.key --service-cluster-ip-range=10.43.0.0/16 --use-service-account-credentials=true
2025-01-29 17:04:50,998 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [options.go:299] unable to set WatchListClient feature gate, err: cannot override default for feature "WatchListClient": gates already added to a flag set
2025-01-29 17:04:50,998 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
2025-01-29 17:04:50,999 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
2025-01-29 17:04:50,999 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running cloud-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/var/lib/rancher/k3s/server/cred/cloud-controller.kubeconfig --authorization-kubeconfig=/var/lib/rancher/k3s/server/cred/cloud-controller.kubeconfig --bind-address=127.0.0.1 --cloud-config=/var/lib/rancher/k3s/server/etc/cloud-config.yaml --cloud-provider=k3s --cluster-cidr=10.42.0.0/16 --configure-cloud-routes=false --controllers=*,-route --kubeconfig=/var/lib/rancher/k3s/server/cred/cloud-controller.kubeconfig --leader-elect=false --leader-elect-resource-name=k3s-cloud-controller-manager --node-status-update-frequency=1m0s --profiling=false
2025-01-29 17:04:51,000 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [options.go:238] external host was not specified, using 172.17.0.3
2025-01-29 17:04:51,000 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Server node token is available at /var/lib/rancher/k3s/server/token
2025-01-29 17:04:51,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] To join server node to cluster: k3s server -s https://172.17.0.3:6443 -t ${SERVER_NODE_TOKEN}
2025-01-29 17:04:51,001 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Agent node token is available at /var/lib/rancher/k3s/server/agent-token
2025-01-29 17:04:51,002 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] To join agent node to cluster: k3s agent -s https://172.17.0.3:6443 -t ${AGENT_NODE_TOKEN}
2025-01-29 17:04:51,002 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:151] Version: v1.32.1+k3s1
2025-01-29 17:04:51,002 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:153] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 17:04:51,002 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Wrote kubeconfig /etc/rancher/k3s/k3s.yaml
2025-01-29 17:04:51,002 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Run: k3s kubectl
2025-01-29 17:04:51,263 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionPolicy,MutatingAdmissionWebhook.
2025-01-29 17:04:51,263 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [plugins.go:160] Loaded 13 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,ClusterTrustBundleAttest,CertificateSubjectRestriction,ValidatingAdmissionPolicy,ValidatingAdmissionWebhook,ResourceQuota.
2025-01-29 17:04:51,263 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [instance.go:233] Using reconciler: lease
2025-01-29 17:04:51,337 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apis.go:106] API group "internal.apiserver.k8s.io" is not enabled, skipping.
2025-01-29 17:04:51,380 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apis.go:106] API group "storagemigration.k8s.io" is not enabled, skipping.
2025-01-29 17:04:51,405 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apis.go:106] API group "resource.k8s.io" is not enabled, skipping.
2025-01-29 17:04:51,608 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Password verified locally for node e992ce4f7863
2025-01-29 17:04:51,715 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="request-header::/var/lib/rancher/k3s/server/tls/request-header-ca.crt"
2025-01-29 17:04:51,715 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt::/var/lib/rancher/k3s/server/tls/serving-kube-apiserver.key"
2025-01-29 17:04:51,715 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/server/tls/client-ca.crt"
2025-01-29 17:04:51,715 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:6444
2025-01-29 17:04:51,715 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 17:04:51,715 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apf_controller.go:377] Starting API Priority and Fairness config controller
2025-01-29 17:04:51,715 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:119] Starting legacy_token_tracking_controller
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:78] Starting OpenAPI AggregationController
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [remote_available_controller.go:411] Starting RemoteAvailability controller
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [gc_controller.go:78] Starting apiserver lease garbage collector
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="aggregator-proxy-cert::/var/lib/rancher/k3s/server/tls/client-auth-proxy.crt::/var/lib/rancher/k3s/server/tls/client-auth-proxy.key"
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [aggregator.go:169] waiting for initial CRD sync...
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [system_namespaces_controller.go:66] Starting system namespaces controller
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [customresource_discovery_controller.go:292] Starting DiscoveryController
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cluster_authentication_trust_controller.go:462] Starting cluster_authentication_trust_controller controller
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [local_available_controller.go:156] Starting LocalAvailability controller
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:80] Starting OpenAPI V3 AggregationController
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apiservice_controller.go:100] Starting APIServiceRegistrationController
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:142] Starting OpenAPI controller
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:90] Starting OpenAPI V3 controller
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [naming_controller.go:294] Starting NamingConditionController
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [establishing_controller.go:81] Starting EstablishingController
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [nonstructuralschema_controller.go:195] Starting NonStructuralSchemaConditionController
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apiapproval_controller.go:189] Starting KubernetesAPIApprovalPolicyConformantConditionController
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [crd_finalizer.go:269] Starting CRDFinalizer
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/server/tls/client-ca.crt"
2025-01-29 17:04:51,720 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="request-header::/var/lib/rancher/k3s/server/tls/request-header-ca.crt"
2025-01-29 17:04:51,728 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [crdregistration_controller.go:114] Starting crd-autoregister controller
2025-01-29 17:04:51,759 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [policy_source.go:240] refreshing policies
2025-01-29 17:04:51,815 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apf_controller.go:382] Running API Priority and Fairness config worker
2025-01-29 17:04:51,815 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apf_controller.go:385] Running API Priority and Fairness periodic rebalancing process
2025-01-29 17:04:51,817 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_discovery.go:451] Starting ResourceDiscoveryManager
2025-01-29 17:04:51,830 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [aggregator.go:171] initial CRD sync complete...
2025-01-29 17:04:51,831 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [autoregister_controller.go:144] Starting autoregister controller
2025-01-29 17:04:51,869 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:95] Unable to perform initial Kubernetes service initialization: namespaces "default" not found
2025-01-29 17:04:52,128 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Module overlay was already loaded
2025-01-29 17:04:52,128 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Module nf_conntrack was already loaded
2025-01-29 17:04:52,128 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Module br_netfilter was already loaded
2025-01-29 17:04:52,132 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Set sysctl 'net/netfilter/nf_conntrack_max' to 131072
2025-01-29 17:04:52,133 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400
2025-01-29 17:04:52,133 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600
2025-01-29 17:04:52,134 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Logging containerd to /var/lib/rancher/k3s/agent/containerd/containerd.log
2025-01-29 17:04:52,134 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running containerd -c /var/lib/rancher/k3s/agent/etc/containerd/config.toml -a /run/k3s/containerd/containerd.sock --state /run/k3s/containerd --root /var/lib/rancher/k3s/agent/containerd
2025-01-29 17:04:52,721 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
2025-01-29 17:04:52,723 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
2025-01-29 17:04:52,724 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [storage_scheduling.go:111] all system priority classes are created successfully or already exist.
2025-01-29 17:04:53,138 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] containerd is now running
2025-01-29 17:04:53,143 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Connecting to proxy" url="wss://127.0.0.1:6443/v1-k3s/connect
2025-01-29 17:04:53,145 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating k3s-cert-monitor event broadcaster
2025-01-29 17:04:53,145 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kubelet --cloud-provider=external --config-dir=/var/lib/rancher/k3s/agent/etc/kubelet.conf.d --containerd=/run/k3s/containerd/containerd.sock --hostname-override=e992ce4f7863 --kubeconfig=/var/lib/rancher/k3s/agent/kubelet.kubeconfig --node-ip=172.17.0.3 --node-labels=
2025-01-29 17:04:53,147 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Handling backend connection request [e992ce4f7863]
2025-01-29 17:04:53,149 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Remotedialer connected to proxy" url="wss://127.0.0.1:6443/v1-k3s/connect
2025-01-29 17:04:53,153 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
2025-01-29 17:04:53,157 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:515] "Kubelet version" kubeletVersion="v1.32.1+k3s1"
2025-01-29 17:04:53,157 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:517] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 17:04:53,159 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/agent/client-ca.crt"
2025-01-29 17:04:53,161 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [log.go:32] "RuntimeConfig from runtime service failed" err="rpc error: code = Unimplemented desc = method RuntimeConfig not implemented"
2025-01-29 17:04:53,161 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:1416] "CRI implementation should be updated to support RuntimeConfig when KubeletCgroupDriverFromCRI feature gate has been enabled. Falling back to using cgroupDriver from kubelet config."
2025-01-29 17:04:53,164 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [info.go:53] Couldn't collect info from any of the files in "/etc/machine-id,/var/lib/dbus/machine-id"
2025-01-29 17:04:53,164 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:767] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
2025-01-29 17:04:53,165 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:836] "NoSwap is set due to memorySwapBehavior not specified" memorySwapBehavior="" FailSwapOn=false
2025-01-29 17:04:53,165 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [swap_util.go:115] "Swap is on" /proc/swaps contents=<
2025-01-29 17:04:53,165 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	Filename				Type		Size		Used		Priority
2025-01-29 17:04:53,165 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	/mnt/swapfile                           file		4194300		524		-2
2025-01-29 17:04:53,165 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 17:04:53,166 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [container_manager_linux.go:268] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
2025-01-29 17:04:53,167 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [container_manager_linux.go:273] "Creating Container Manager object based on Node Config" nodeConfig={"NodeName":"e992ce4f7863","RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"/k3s","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"cgroupfs","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"imagefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null,"CgroupVersion":2}
2025-01-29 17:04:53,167 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [topology_manager.go:138] "Creating topology manager with none policy"
2025-01-29 17:04:53,167 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [container_manager_linux.go:304] "Creating device plugin manager"
2025-01-29 17:04:53,167 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [state_mem.go:36] "Initialized new in-memory state store"
2025-01-29 17:04:53,167 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:446] "Attempting to sync node with API server"
2025-01-29 17:04:53,167 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:341] "Adding static pod path" path="/var/lib/rancher/k3s/agent/pod-manifests"
2025-01-29 17:04:53,167 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:352] "Adding apiserver pod source"
2025-01-29 17:04:53,167 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apiserver.go:42] "Waiting for node sync before watching apiserver pods"
2025-01-29 17:04:53,171 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kuberuntime_manager.go:269] "Container runtime initialized" containerRuntime="containerd" version="v1.7.23-k3s2" apiVersion="v1"
2025-01-29 17:04:53,171 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:890] "Not starting ClusterTrustBundle informer because we are in static kubelet mode"
2025-01-29 17:04:53,171 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [probe.go:272] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
2025-01-29 17:04:53,171 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [watchdog_linux.go:99] "Systemd watchdog is not enabled"
2025-01-29 17:04:53,171 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:1282] "Started kubelet"
2025-01-29 17:04:53,172 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
2025-01-29 17:04:53,172 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="kubelet-server-cert-files::/var/lib/rancher/k3s/agent/serving-kubelet.crt::/var/lib/rancher/k3s/agent/serving-kubelet.key"
2025-01-29 17:04:53,172 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:169] "Starting to listen" address="0.0.0.0" port=10250
2025-01-29 17:04:53,175 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:490] "Adding debug handlers to kubelet server"
2025-01-29 17:04:53,182 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:208] "Starting to listen read-only" address="0.0.0.0" port=10255
2025-01-29 17:04:53,182 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [volume_manager.go:297] "Starting Kubelet Volume Manager"
2025-01-29 17:04:53,182 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:467] "Error getting the current node from lister" err="node \"e992ce4f7863\" not found"
2025-01-29 17:04:53,187 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [desired_state_of_world_populator.go:149] "Desired state populator starts to run"
2025-01-29 17:04:53,187 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:1561] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
2025-01-29 17:04:53,187 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler.go:26] "Reconciler: start to sync state"
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [ratelimit.go:55] "Setting rate limiting for endpoint" service="podresources" qps=100 burstTokens=10
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:243] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [factory.go:221] Registration of the containerd container factory successfully
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [factory.go:221] Registration of the systemd container factory successfully
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [factory.go:219] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="default/kubernetes" clusterIPs={"IPv4":"10.43.0.1"}
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [status_manager.go:227] "Starting to sync pod status with apiserver"
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [watchdog_linux.go:127] "Systemd watchdog is not enabled or the interval is invalid, so health checking will not be started."
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:2388] "Starting kubelet main sync loop"
2025-01-29 17:04:53,192 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet.go:2412] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
2025-01-29 17:04:53,207 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"e992ce4f7863\" not found" node="e992ce4f7863"
2025-01-29 17:04:53,216 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [lease.go:265] Resetting endpoints for master service "kubernetes" to [172.17.0.3]
2025-01-29 17:04:53,241 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cpu_manager.go:221] "Starting CPU manager" policy="none"
2025-01-29 17:04:53,241 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cpu_manager.go:222] "Reconciling" reconcilePeriod="10s"
2025-01-29 17:04:53,241 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [state_mem.go:36] "Initialized new in-memory state store"
2025-01-29 17:04:53,244 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [policy_none.go:49] "None policy: Start"
2025-01-29 17:04:53,244 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [memory_manager.go:186] "Starting memorymanager" policy="None"
2025-01-29 17:04:53,244 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [state_mem.go:35] "Initializing new in-memory state store"
2025-01-29 17:04:53,246 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [manager.go:519] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
2025-01-29 17:04:53,247 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [eviction_manager.go:189] "Eviction manager: starting control loop"
2025-01-29 17:04:53,249 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [container_log_manager.go:189] "Initializing container log rotate workers" workers=1 monitorPeriod="10s"
2025-01-29 17:04:53,249 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [plugin_manager.go:118] "Starting Kubelet Plugin Manager"
2025-01-29 17:04:53,250 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [eviction_manager.go:267] "eviction manager: failed to check if we have separate container filesystem. Ignoring." err="no imagefs label for configured runtime"
2025-01-29 17:04:53,250 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [eviction_manager.go:292] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"e992ce4f7863\" not found"
2025-01-29 17:04:53,274 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [ERROR] Sending HTTP/1.1 503 response to 127.0.0.1:35188: runtime core not ready
2025-01-29 17:04:53,349 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:76] "Attempting to register node" node="e992ce4f7863"
2025-01-29 17:04:53,352 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:79] "Successfully registered node" node="e992ce4f7863"
2025-01-29 17:04:53,354 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:549] "Error updating node status, will retry" err="error getting node \"e992ce4f7863\": node \"e992ce4f7863\" not found"
2025-01-29 17:04:53,358 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Annotations and labels have been set successfully on node: e992ce4f7863
2025-01-29 17:04:53,358 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting flannel with backend vxlan
2025-01-29 17:04:53,385 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running kube-proxy --cluster-cidr=10.42.0.0/16 --conntrack-max-per-core=0 --conntrack-tcp-timeout-close-wait=0s --conntrack-tcp-timeout-established=0s --healthz-bind-address=127.0.0.1 --hostname-override=e992ce4f7863 --kubeconfig=/var/lib/rancher/k3s/agent/kubeproxy.kubeconfig --proxy-mode=iptables
2025-01-29 17:04:53,428 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:698] "Successfully retrieved node IP(s)" IPs=["172.17.0.3"]
2025-01-29 17:04:53,428 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:234] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
2025-01-29 17:04:53,431 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:243] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
2025-01-29 17:04:53,431 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server_linux.go:170] "Using iptables Proxier"
2025-01-29 17:04:53,432 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [proxier.go:255] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
2025-01-29 17:04:53,432 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:497] "Version info" version="v1.32.1+k3s1"
2025-01-29 17:04:53,432 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:499] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 17:04:53,436 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [config.go:199] "Starting service config controller"
2025-01-29 17:04:53,436 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [config.go:105] "Starting endpoint slice config controller"
2025-01-29 17:04:53,436 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [config.go:329] "Starting node config controller"
2025-01-29 17:04:53,663 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_node_status.go:502] "Fast updating node status as it just became ready"
2025-01-29 17:04:54,003 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for untainted node
2025-01-29 17:04:54,003 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for cloud-controller-manager privileges to become available
2025-01-29 17:04:54,004 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating k3s-supervisor event broadcaster
2025-01-29 17:04:54,004 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Kube API server is now running
2025-01-29 17:04:54,004 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] ETCD server is now running
2025-01-29 17:04:54,004 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] k3s is up and running
2025-01-29 17:04:54,011 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Applying CRD addons.k3s.cattle.io
2025-01-29 17:04:54,023 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Applying CRD etcdsnapshotfiles.k3s.cattle.io
2025-01-29 17:04:54,034 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Applying CRD helmcharts.helm.cattle.io
2025-01-29 17:04:54,049 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Applying CRD helmchartconfigs.helm.cattle.io
2025-01-29 17:04:54,065 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for CRD helmcharts.helm.cattle.io to become available
2025-01-29 17:04:54,168 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [apiserver.go:52] "Watching apiserver"
2025-01-29 17:04:54,186 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [desired_state_of_world_populator.go:157] "Finished populating initial desired state of world"
2025-01-29 17:04:54,295 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 17:04:54,568 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Done waiting for CRD helmcharts.helm.cattle.io to become available
2025-01-29 17:04:54,568 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Waiting for CRD helmchartconfigs.helm.cattle.io to become available
2025-01-29 17:04:54,619 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:185] "Starting" version="v1.32.1+k3s1"
2025-01-29 17:04:54,619 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:187] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 17:04:54,621 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
2025-01-29 17:04:54,621 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-01-29 17:04:54,621 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-01-29 17:04:54,622 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:10257
2025-01-29 17:04:54,622 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 17:04:54,626 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="serviceaccount-token-controller"
2025-01-29 17:04:54,640 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="namespace-controller"
2025-01-29 17:04:54,641 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [namespace_controller.go:202] "Starting namespace controller"
2025-01-29 17:04:54,649 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="garbage-collector-controller"
2025-01-29 17:04:54,649 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:723] "Skipping a cloud provider controller" controller="node-route-controller"
2025-01-29 17:04:54,649 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:743] "Warning: skipping controller" controller="storage-version-migrator-controller"
2025-01-29 17:04:54,649 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [graph_builder.go:351] "Running" component="GraphBuilder"
2025-01-29 17:04:54,660 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="horizontal-pod-autoscaler-controller"
2025-01-29 17:04:54,660 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [horizontal.go:201] "Starting HPA controller"
2025-01-29 17:04:54,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="statefulset-controller"
2025-01-29 17:04:54,665 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:723] "Skipping a cloud provider controller" controller="cloud-node-lifecycle-controller"
2025-01-29 17:04:54,666 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [stateful_set.go:166] "Starting stateful set controller"
2025-01-29 17:04:54,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="root-ca-certificate-publisher-controller"
2025-01-29 17:04:54,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="resourceclaim-controller" requiredFeatureGates=["DynamicResourceAllocation"]
2025-01-29 17:04:54,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [publisher.go:107] "Starting root CA cert publisher controller"
2025-01-29 17:04:54,678 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="legacy-serviceaccount-token-cleaner-controller"
2025-01-29 17:04:54,678 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [legacy_serviceaccount_token_cleaner.go:103] "Starting legacy service account token cleaner controller"
2025-01-29 17:04:54,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="deployment-controller"
2025-01-29 17:04:54,684 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [deployment_controller.go:173] "Starting controller" controller="deployment"
2025-01-29 17:04:54,829 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="disruption-controller"
2025-01-29 17:04:54,829 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [disruption.go:452] "Sending events to api server."
2025-01-29 17:04:54,829 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [disruption.go:463] "Starting disruption controller"
2025-01-29 17:04:55,071 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Done waiting for CRD helmchartconfigs.helm.cattle.io to become available
2025-01-29 17:04:55,071 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing static file: /var/lib/rancher/k3s/server/static/charts/traefik-27.0.201+up27.0.2.tgz
2025-01-29 17:04:55,072 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing static file: /var/lib/rancher/k3s/server/static/charts/traefik-crd-27.0.201+up27.0.2.tgz
2025-01-29 17:04:55,072 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml
2025-01-29 17:04:55,073 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml
2025-01-29 17:04:55,073 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/rolebindings.yaml
2025-01-29 17:04:55,073 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/ccm.yaml
2025-01-29 17:04:55,073 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/local-storage.yaml
2025-01-29 17:04:55,073 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml
2025-01-29 17:04:55,073 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml
2025-01-29 17:04:55,073 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml
2025-01-29 17:04:55,073 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/runtimes.yaml
2025-01-29 17:04:55,074 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/coredns.yaml
2025-01-29 17:04:55,074 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml
2025-01-29 17:04:55,074 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Writing manifest: /var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml
2025-01-29 17:04:55,075 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting dynamiclistener CN filter node controller with SANs: [localhost 127.0.0.1 ::1 localhost e992ce4f7863 172.17.0.3 10.43.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local]
2025-01-29 17:04:55,075 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Tunnel server egress proxy mode: agent
2025-01-29 17:04:55,083 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:112] "No Secondary Service CIDR provided. Skipping filtering out secondary service addresses"
2025-01-29 17:04:55,083 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="node-ipam-controller"
2025-01-29 17:04:55,083 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_ipam_controller.go:141] "Starting ipam controller"
2025-01-29 17:04:55,180 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting k3s.cattle.io/v1, Kind=Addon controller
2025-01-29 17:04:55,180 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating deploy event broadcaster
2025-01-29 17:04:55,229 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="ttl-after-finished-controller"
2025-01-29 17:04:55,229 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="kube-apiserver-serving-clustertrustbundle-publisher-controller" requiredFeatureGates=["ClusterTrustBundle"]
2025-01-29 17:04:55,229 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [ttlafterfinished_controller.go:112] "Starting TTL after finished controller"
2025-01-29 17:04:55,284 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Node controller
2025-01-29 17:04:55,287 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating helm-controller event broadcaster
2025-01-29 17:04:55,301 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Cluster dns configmap has been set successfully
2025-01-29 17:04:55,395 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting helm.cattle.io/v1, Kind=HelmChart controller
2025-01-29 17:04:55,395 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting helm.cattle.io/v1, Kind=HelmChartConfig controller
2025-01-29 17:04:55,397 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding controller
2025-01-29 17:04:55,400 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting batch/v1, Kind=Job controller
2025-01-29 17:04:55,400 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=ConfigMap controller
2025-01-29 17:04:55,400 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=ServiceAccount controller
2025-01-29 17:04:55,400 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Secret controller
2025-01-29 17:04:55,533 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="resourcequota-controller"
2025-01-29 17:04:55,534 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [resource_quota_controller.go:300] "Starting resource quota controller"
2025-01-29 17:04:55,687 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="serviceaccount-controller"
2025-01-29 17:04:55,687 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:723] "Skipping a cloud provider controller" controller="service-lb-controller"
2025-01-29 17:04:55,687 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serviceaccounts_controller.go:114] "Starting service account controller"
2025-01-29 17:04:55,830 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-binder-controller"
2025-01-29 17:04:55,830 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [pv_controller_base.go:308] "Starting persistent volume controller"
2025-01-29 17:04:55,841 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Updating TLS secret for kube-system/k3s-serving (count: 10): map[listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.17.0.3:172.17.0.3 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-e992ce4f7863:e992ce4f7863 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=66F5AD3322EF9A733EECD9E896E217296F5EE33D]
2025-01-29 17:04:55,844 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Active TLS secret kube-system/k3s-serving (ver=242) (count 10): map[listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.17.0.3:172.17.0.3 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-e992ce4f7863:e992ce4f7863 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=66F5AD3322EF9A733EECD9E896E217296F5EE33D]
2025-01-29 17:04:55,940 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Updating TLS secret for kube-system/k3s-serving (count: 10): map[listener.cattle.io/cn-10.43.0.1:10.43.0.1 listener.cattle.io/cn-127.0.0.1:127.0.0.1 listener.cattle.io/cn-172.17.0.3:172.17.0.3 listener.cattle.io/cn-__1-f16284:::1 listener.cattle.io/cn-e992ce4f7863:e992ce4f7863 listener.cattle.io/cn-kubernetes:kubernetes listener.cattle.io/cn-kubernetes.default:kubernetes.default listener.cattle.io/cn-kubernetes.default.svc:kubernetes.default.svc listener.cattle.io/cn-kubernetes.default.svc.cluster.local:kubernetes.default.svc.cluster.local listener.cattle.io/cn-localhost:localhost listener.cattle.io/fingerprint:SHA1=66F5AD3322EF9A733EECD9E896E217296F5EE33D]
2025-01-29 17:04:55,979 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-attach-detach-controller"
2025-01-29 17:04:55,979 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [attach_detach_controller.go:338] "Starting attach detach controller"
2025-01-29 17:04:56,130 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="ephemeral-volume-controller"
2025-01-29 17:04:56,130 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:173] "Starting ephemeral volume controller"
2025-01-29 17:04:56,279 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="token-cleaner-controller"
2025-01-29 17:04:56,279 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tokencleaner.go:117] "Starting token cleaner controller"
2025-01-29 17:04:56,307 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Labels and annotations have been set successfully on node: e992ce4f7863
2025-01-29 17:04:56,429 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="clusterrole-aggregation-controller"
2025-01-29 17:04:56,429 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [clusterroleaggregation_controller.go:194] "Starting ClusterRoleAggregator controller"
2025-01-29 17:04:56,579 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="endpointslice-mirroring-controller"
2025-01-29 17:04:56,579 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [endpointslicemirroring_controller.go:227] "Starting EndpointSliceMirroring controller"
2025-01-29 17:04:56,711 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="e992ce4f7863" fieldPath="" kind="Node" apiVersion="" type="Normal" reason="NodePasswordValidationComplete" message="Deferred node password secret validation complete"
2025-01-29 17:04:56,729 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="pod-garbage-collector-controller"
2025-01-29 17:04:56,729 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [gc_controller.go:99] "Starting GC controller"
2025-01-29 17:04:56,881 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="job-controller"
2025-01-29 17:04:56,881 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [job_controller.go:243] "Starting job controller"
2025-01-29 17:04:57,029 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="certificatesigningrequest-cleaner-controller"
2025-01-29 17:04:57,029 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cleaner.go:83] "Starting CSR cleaner controller"
2025-01-29 17:04:57,179 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="ttl-controller"
2025-01-29 17:04:57,179 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:728] "Warning: controller is disabled" controller="bootstrap-signer-controller"
2025-01-29 17:04:57,179 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [ttl_controller.go:127] "Starting TTL controller"
2025-01-29 17:04:57,184 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/ccm" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/ccm.yaml\""
2025-01-29 17:04:57,202 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/ccm" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/ccm.yaml\""
2025-01-29 17:04:57,210 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/coredns.yaml\""
2025-01-29 17:04:57,315 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs={"IPv4":"10.43.0.10"}
2025-01-29 17:04:57,316 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/coredns.yaml\""
2025-01-29 17:04:57,322 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/local-storage" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/local-storage.yaml\""
2025-01-29 17:04:57,328 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolumeclaim-protection-controller"
2025-01-29 17:04:57,328 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="service-cidr-controller" requiredFeatureGates=["MultiCIDRServiceAllocator"]
2025-01-29 17:04:57,328 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [pvc_protection_controller.go:168] "Starting PVC protection controller"
2025-01-29 17:04:57,416 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/local-storage" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/local-storage.yaml\""
2025-01-29 17:04:57,422 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/aggregated-metrics-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml\""
2025-01-29 17:04:57,479 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="endpointslice-controller"
2025-01-29 17:04:57,479 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [endpointslice_controller.go:281] "Starting endpoint slice controller"
2025-01-29 17:04:57,494 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/aggregated-metrics-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/aggregated-metrics-reader.yaml\""
2025-01-29 17:04:57,500 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-delegator" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml\""
2025-01-29 17:04:57,504 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-delegator" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-delegator.yaml\""
2025-01-29 17:04:57,509 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml\""
2025-01-29 17:04:57,514 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/auth-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/auth-reader.yaml\""
2025-01-29 17:04:57,519 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-apiservice" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml\""
2025-01-29 17:04:57,525 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-apiservice" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-apiservice.yaml\""
2025-01-29 17:04:57,529 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 17:04:57,530 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:146] "Unhandled Error" err=<
2025-01-29 17:04:57,530 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 17:04:57,530 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 17:04:57,530 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:143] error resolving kube-system/metrics-server: service "metrics-server" not found
2025-01-29 17:04:57,531 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-deployment" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml\""
2025-01-29 17:04:57,540 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-deployment" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-deployment.yaml\""
2025-01-29 17:04:57,545 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-service" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml\""
2025-01-29 17:04:57,550 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="kube-system/metrics-server" clusterIPs={"IPv4":"10.43.118.43"}
2025-01-29 17:04:57,551 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/metrics-server-service" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/metrics-server-service.yaml\""
2025-01-29 17:04:57,555 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 17:04:57,555 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:146] "Unhandled Error" err=<
2025-01-29 17:04:57,556 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 17:04:57,556 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 17:04:57,557 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:143] error resolving kube-system/metrics-server: endpoints "metrics-server" not found
2025-01-29 17:04:57,558 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/resource-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml\""
2025-01-29 17:04:57,605 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/resource-reader" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/metrics-server/resource-reader.yaml\""
2025-01-29 17:04:57,611 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/rolebindings" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/rolebindings.yaml\""
2025-01-29 17:04:57,629 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="replicaset-controller"
2025-01-29 17:04:57,629 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:217] "Starting controller" name="replicaset"
2025-01-29 17:04:57,680 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-kubelet-serving"
2025-01-29 17:04:57,680 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/server-ca.key"
2025-01-29 17:04:57,680 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-kubelet-client"
2025-01-29 17:04:57,680 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/client-ca.key"
2025-01-29 17:04:57,680 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-kube-apiserver-client"
2025-01-29 17:04:57,680 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/client-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/client-ca.key"
2025-01-29 17:04:57,680 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrsigning-legacy-unknown"
2025-01-29 17:04:57,680 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="certificatesigningrequest-signing-controller"
2025-01-29 17:04:57,680 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/var/lib/rancher/k3s/server/tls/server-ca.nochain.crt::/var/lib/rancher/k3s/server/tls/server-ca.key"
2025-01-29 17:04:57,717 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/rolebindings" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/rolebindings.yaml\""
2025-01-29 17:04:57,724 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/runtimes" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="ApplyingManifest" message="Applying manifest at \"/var/lib/rancher/k3s/server/manifests/runtimes.yaml\""
2025-01-29 17:04:57,729 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="certificatesigningrequest-approving-controller"
2025-01-29 17:04:57,729 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [certificate_controller.go:120] "Starting certificate controller" name="csrapproving"
2025-01-29 17:04:57,750 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="kube-system/runtimes" fieldPath="" kind="Addon" apiVersion="k3s.cattle.io/v1" type="Normal" reason="AppliedManifest" message="Applied manifest at \"/var/lib/rancher/k3s/server/manifests/runtimes.yaml\""
2025-01-29 17:04:57,879 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-protection-controller"
2025-01-29 17:04:57,879 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [pv_protection_controller.go:81] "Starting PV protection controller"
2025-01-29 17:04:58,029 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="endpoints-controller"
2025-01-29 17:04:58,029 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [endpoints_controller.go:182] "Starting endpoint controller"
2025-01-29 17:04:58,151 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Tunnel authorizer set Kubelet Port 0.0.0.0:10250
2025-01-29 17:04:58,182 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="persistentvolume-expander-controller"
2025-01-29 17:04:58,182 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="storageversion-garbage-collector-controller" requiredFeatureGates=["APIServerIdentity","StorageVersionAPI"]
2025-01-29 17:04:58,182 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [expand_controller.go:329] "Starting expand controller"
2025-01-29 17:04:58,229 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="taint-eviction-controller"
2025-01-29 17:04:58,229 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [taint_eviction.go:281] "Starting" controller="taint-eviction-controller"
2025-01-29 17:04:58,229 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="selinux-warning-controller" requiredFeatureGates=["SELinuxChangePolicy"]
2025-01-29 17:04:58,229 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [taint_eviction.go:287] "Sending events to api server"
2025-01-29 17:04:58,248 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 17:04:58,379 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="replicationcontroller-controller"
2025-01-29 17:04:58,379 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:217] "Starting controller" name="replicationcontroller"
2025-01-29 17:04:58,438 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 17:04:58,525 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 17:04:58,526 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 17:04:58,526 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:102] "Unhandled Error" err=<
2025-01-29 17:04:58,526 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 17:04:58,526 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 17:04:58,530 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="daemonset-controller"
2025-01-29 17:04:58,530 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [daemon_controller.go:294] "Starting daemon sets controller"
2025-01-29 17:04:58,610 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:160] Version: v1.32.1+k3s1
2025-01-29 17:04:58,612 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
2025-01-29 17:04:58,612 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-01-29 17:04:58,612 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-01-29 17:04:58,612 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:10258
2025-01-29 17:04:58,612 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 17:04:58,615 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Creating service-lb-controller event broadcaster
2025-01-29 17:04:58,685 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="cronjob-controller"
2025-01-29 17:04:58,685 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [cronjob_controllerv2.go:145] "Starting cronjob controller v2"
2025-01-29 17:04:58,728 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Node controller
2025-01-29 17:04:58,729 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:432] "Controller will reconcile labels"
2025-01-29 17:04:58,729 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="node-lifecycle-controller"
2025-01-29 17:04:58,729 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:717] "Controller is disabled by a feature gate" controller="volumeattributesclass-protection-controller" requiredFeatureGates=["VolumeAttributesClass"]
2025-01-29 17:04:58,729 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:466] "Sending events to api server"
2025-01-29 17:04:58,729 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:477] "Starting node controller"
2025-01-29 17:04:58,730 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting /v1, Kind=Pod controller
2025-01-29 17:04:58,733 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting apps/v1, Kind=DaemonSet controller
2025-01-29 17:04:58,736 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting discovery.k8s.io/v1, Kind=EndpointSlice controller
2025-01-29 17:04:58,736 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:329] Started "cloud-node-controller"
2025-01-29 17:04:58,736 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_controller.go:176] Sending events to api server.
2025-01-29 17:04:58,736 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_controller.go:185] Waiting for informer caches to sync
2025-01-29 17:04:58,737 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:329] Started "cloud-node-lifecycle-controller"
2025-01-29 17:04:58,737 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:112] Sending events to api server
2025-01-29 17:04:58,737 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:329] Started "service-lb-controller"
2025-01-29 17:04:58,737 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:306] "node-route-controller" is disabled
2025-01-29 17:04:58,738 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:234] Starting service controller
2025-01-29 17:04:58,837 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_controller.go:429] Initializing node e992ce4f7863 with cloud provider
2025-01-29 17:04:58,843 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_controller.go:474] Successfully initialized node e992ce4f7863 with cloud provider
2025-01-29 17:04:58,843 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="e992ce4f7863" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="Synced" message="Node synced successfully"
2025-01-29 17:04:58,848 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Updated coredns NodeHosts entry for e992ce4f7863
2025-01-29 17:04:58,929 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controllermanager.go:765] "Started controller" controller="validatingadmissionpolicy-status-controller"
2025-01-29 17:04:58,967 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [serving.go:392] Generated self-signed cert in-memory
2025-01-29 17:04:59,084 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [actual_state_of_world.go:541] "Failed to update statusUpdateNeeded field in actual state of world" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"e992ce4f7863\" does not exist"
2025-01-29 17:04:59,129 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:1234] "Initializing eviction metric for zone" zone=""
2025-01-29 17:04:59,129 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:886] "Missing timestamp for Node. Assuming now as a timestamp" node="e992ce4f7863"
2025-01-29 17:04:59,130 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [node_lifecycle_controller.go:1080] "Controller detected that zone is now in new state" zone="" newState="Normal"
2025-01-29 17:04:59,150 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Started tunnel to 172.17.0.3:6443
2025-01-29 17:04:59,151 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Stopped tunnel to 127.0.0.1:6443
2025-01-29 17:04:59,151 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Connecting to proxy" url="wss://172.17.0.3:6443/v1-k3s/connect
2025-01-29 17:04:59,151 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Proxy done" err="context canceled" url="wss://127.0.0.1:6443/v1-k3s/connect
2025-01-29 17:04:59,151 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] error in remotedialer server [400]: websocket: close 1006 (abnormal closure): unexpected EOF
2025-01-29 17:04:59,153 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Handling backend connection request [e992ce4f7863]
2025-01-29 17:04:59,153 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Remotedialer connected to proxy" url="wss://172.17.0.3:6443/v1-k3s/connect
2025-01-29 17:04:59,183 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:177] "Sending events to api server"
2025-01-29 17:04:59,184 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:183] "Starting range CIDR allocator"
2025-01-29 17:04:59,188 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:428] "Set node PodCIDR" node="e992ce4f7863" podCIDRs=["10.42.0.0/24"]
2025-01-29 17:04:59,188 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="e992ce4f7863"
2025-01-29 17:04:59,191 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Flannel found PodCIDR assigned for node e992ce4f7863
2025-01-29 17:04:59,191 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="e992ce4f7863"
2025-01-29 17:04:59,191 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] The interface eth0 with ipv4 address 172.17.0.3 will be used by flannel
2025-01-29 17:04:59,191 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:139] Waiting 10m0s for node controller to sync
2025-01-29 17:04:59,191 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:469] Starting kube subnet manager
2025-01-29 17:04:59,276 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:164] "Starting Kubernetes Scheduler" version="v1.32.1+k3s1"
2025-01-29 17:04:59,276 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [server.go:166] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
2025-01-29 17:04:59,281 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [secure_serving.go:213] Serving securely on 127.0.0.1:10259
2025-01-29 17:04:59,282 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
2025-01-29 17:04:59,282 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [tlsconfig.go:243] "Starting DynamicServingCertificateController"
2025-01-29 17:04:59,282 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2025-01-29 17:04:59,283 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2025-01-29 17:04:59,297 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Starting network policy controller version v2.2.1, built on 2025-01-28T18:27:08Z, go1.23.4
2025-01-29 17:04:59,297 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [network_policy_controller.go:164] Starting network policy controller
2025-01-29 17:04:59,329 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [network_policy_controller.go:176] Starting network policy controller full sync goroutine
2025-01-29 17:04:59,585 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 17:04:59,586 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:146] "Unhandled Error" err=<
2025-01-29 17:04:59,586 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 17:04:59,586 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 17:04:59,586 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:143] error resolving kube-system/metrics-server: no endpoints available for service "metrics-server"
2025-01-29 17:04:59,733 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="e992ce4f7863"
2025-01-29 17:04:59,842 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="406.563938ms"
2025-01-29 17:04:59,850 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reflector.go:569] object-"kube-system"/"coredns": failed to list *v1.ConfigMap: configmaps "coredns" is forbidden: User "system:node:e992ce4f7863" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'e992ce4f7863' and this object
2025-01-29 17:04:59,850 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reflector.go:166] "Unhandled Error" err="object-\"kube-system\"/\"coredns\": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps \"coredns\" is forbidden: User \"system:node:e992ce4f7863\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'e992ce4f7863' and this object"
2025-01-29 17:04:59,852 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reflector.go:569] object-"kube-system"/"kube-root-ca.crt": failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:e992ce4f7863" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'e992ce4f7863' and this object
2025-01-29 17:04:59,852 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reflector.go:166] "Unhandled Error" err="object-\"kube-system\"/\"kube-root-ca.crt\": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps \"kube-root-ca.crt\" is forbidden: User \"system:node:e992ce4f7863\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'e992ce4f7863' and this object"
2025-01-29 17:04:59,852 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reflector.go:569] object-"kube-system"/"coredns-custom": failed to list *v1.ConfigMap: configmaps "coredns-custom" is forbidden: User "system:node:e992ce4f7863" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'e992ce4f7863' and this object
2025-01-29 17:04:59,852 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reflector.go:166] "Unhandled Error" err="object-\"kube-system\"/\"coredns-custom\": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps \"coredns-custom\" is forbidden: User \"system:node:e992ce4f7863\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'e992ce4f7863' and this object"
2025-01-29 17:04:59,852 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [status_manager.go:890] "Failed to get status for pod" podUID="48d320be-4c5e-4b15-8133-857f02e070dd" pod="kube-system/coredns-ff8999cc5-bp2kh" err="pods \"coredns-ff8999cc5-bp2kh\" is forbidden: User \"system:node:e992ce4f7863\" cannot get resource \"pods\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'e992ce4f7863' and this object"
2025-01-29 17:04:59,852 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reflector.go:569] object-"kube-system"/"local-path-config": failed to list *v1.ConfigMap: configmaps "local-path-config" is forbidden: User "system:node:e992ce4f7863" cannot list resource "configmaps" in API group "" in the namespace "kube-system": no relationship found between node 'e992ce4f7863' and this object
2025-01-29 17:04:59,852 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reflector.go:166] "Unhandled Error" err="object-\"kube-system\"/\"local-path-config\": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps \"local-path-config\" is forbidden: User \"system:node:e992ce4f7863\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'e992ce4f7863' and this object"
2025-01-29 17:04:59,852 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="416.852528ms"
2025-01-29 17:04:59,853 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="416.569229ms"
2025-01-29 17:04:59,860 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="8.511197ms"
2025-01-29 17:04:59,861 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="9.799446ms"
2025-01-29 17:04:59,862 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="19.861835ms"
2025-01-29 17:04:59,864 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="25.767s"
2025-01-29 17:04:59,875 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="14.590569ms"
2025-01-29 17:04:59,875 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="28.703s"
2025-01-29 17:04:59,878 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="24.366s"
2025-01-29 17:04:59,878 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="16.396183ms"
2025-01-29 17:04:59,878 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="84.447s"
2025-01-29 17:04:59,888 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="36.277s"
2025-01-29 17:04:59,894 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="32.19s"
2025-01-29 17:04:59,948 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/42b63ef1-74d7-4a7e-acdc-750819f6bbfd-config-volume\") pod \"local-path-provisioner-698b58967b-5nfw9\" (UID: \"42b63ef1-74d7-4a7e-acdc-750819f6bbfd\") " pod="kube-system/local-path-provisioner-698b58967b-5nfw9"
2025-01-29 17:04:59,948 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-trzbk\" (UniqueName: \"kubernetes.io/projected/42b63ef1-74d7-4a7e-acdc-750819f6bbfd-kube-api-access-trzbk\") pod \"local-path-provisioner-698b58967b-5nfw9\" (UID: \"42b63ef1-74d7-4a7e-acdc-750819f6bbfd\") " pod="kube-system/local-path-provisioner-698b58967b-5nfw9"
2025-01-29 17:04:59,948 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp-dir\" (UniqueName: \"kubernetes.io/empty-dir/ea1b6d19-b228-449b-843b-eff01af40bc7-tmp-dir\") pod \"metrics-server-8584b5786c-4tb6m\" (UID: \"ea1b6d19-b228-449b-843b-eff01af40bc7\") " pod="kube-system/metrics-server-8584b5786c-4tb6m"
2025-01-29 17:04:59,948 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-dm9vg\" (UniqueName: \"kubernetes.io/projected/ea1b6d19-b228-449b-843b-eff01af40bc7-kube-api-access-dm9vg\") pod \"metrics-server-8584b5786c-4tb6m\" (UID: \"ea1b6d19-b228-449b-843b-eff01af40bc7\") " pod="kube-system/metrics-server-8584b5786c-4tb6m"
2025-01-29 17:04:59,948 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/48d320be-4c5e-4b15-8133-857f02e070dd-config-volume\") pod \"coredns-ff8999cc5-bp2kh\" (UID: \"48d320be-4c5e-4b15-8133-857f02e070dd\") " pod="kube-system/coredns-ff8999cc5-bp2kh"
2025-01-29 17:04:59,948 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"custom-config-volume\" (UniqueName: \"kubernetes.io/configmap/48d320be-4c5e-4b15-8133-857f02e070dd-custom-config-volume\") pod \"coredns-ff8999cc5-bp2kh\" (UID: \"48d320be-4c5e-4b15-8133-857f02e070dd\") " pod="kube-system/coredns-ff8999cc5-bp2kh"
2025-01-29 17:04:59,948 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-sztvw\" (UniqueName: \"kubernetes.io/projected/48d320be-4c5e-4b15-8133-857f02e070dd-kube-api-access-sztvw\") pod \"coredns-ff8999cc5-bp2kh\" (UID: \"48d320be-4c5e-4b15-8133-857f02e070dd\") " pod="kube-system/coredns-ff8999cc5-bp2kh"
2025-01-29 17:05:00,190 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:146] Node controller sync successful
2025-01-29 17:05:00,190 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [vxlan.go:141] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false
2025-01-29 17:05:00,193 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:636] List of node(e992ce4f7863) annotations: map[string]string{"alpha.kubernetes.io/provided-node-ip":"172.17.0.3", "k3s.io/hostname":"e992ce4f7863", "k3s.io/internal-ip":"172.17.0.3", "k3s.io/node-args":"[\"server\",\"--disable\",\"traefik\",\"--tls-san\",\"localhost\"]", "k3s.io/node-config-hash":"JO7YSLDHXFTIIPZLLVI7GVGPULZK5EY6PYXUBKR6RNNG4QMX5FBQ====", "k3s.io/node-env":"{}", "node.alpha.kubernetes.io/ttl":"0", "volumes.kubernetes.io/controller-managed-attach-detach":"true"}
2025-01-29 17:05:00,198 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="e992ce4f7863"
2025-01-29 17:05:00,198 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:51] Starting flannel in iptables mode...
2025-01-29 17:05:00,198 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_NETWORK in file: /run/flannel/subnet.env
2025-01-29 17:05:00,198 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_SUBNET in file: /run/flannel/subnet.env
2025-01-29 17:05:00,198 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_IPV6_NETWORK in file: /run/flannel/subnet.env
2025-01-29 17:05:00,198 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kube.go:490] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.0.0/24]
2025-01-29 17:05:00,198 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [WARNING] no subnet found for key: FLANNEL_IPV6_SUBNET in file: /run/flannel/subnet.env
2025-01-29 17:05:00,198 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:115] Current network or subnet (10.42.0.0/16, 10.42.0.0/24) is not equal to previous one (0.0.0.0/0, 0.0.0.0/0), trying to recycle old iptables rules
2025-01-29 17:05:00,205 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:125] Setting up masking rules
2025-01-29 17:05:00,207 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:226] Changing default FORWARD chain policy to ACCEPT
2025-01-29 17:05:00,208 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Wrote flannel subnet file to /run/flannel/subnet.env
2025-01-29 17:05:00,208 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [INFO] Running flannel backend.
2025-01-29 17:05:00,208 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [vxlan_network.go:65] watching for new subnet leases
2025-01-29 17:05:00,217 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:372] bootstrap done
2025-01-29 17:05:00,221 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [iptables.go:372] bootstrap done
2025-01-29 17:05:00,587 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 17:05:00,587 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [handler_proxy.go:99] no RequestInfo found in the context
2025-01-29 17:05:00,587 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [controller.go:102] "Unhandled Error" err=<
2025-01-29 17:05:00,587 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 	, Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
2025-01-29 17:05:00,587 INFO c.h.h.t.OperatorHelmChartContainer - [K3S]  >
2025-01-29 17:05:01,049 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [configmap.go:193] Couldn't get configMap kube-system/coredns-custom: failed to sync configmap cache: timed out waiting for the condition
2025-01-29 17:05:01,049 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/configmap/48d320be-4c5e-4b15-8133-857f02e070dd-custom-config-volume podName:48d320be-4c5e-4b15-8133-857f02e070dd nodeName:}" failed. No retries permitted until 2025-01-29 17:05:01.549284866 +0000 UTC m=+10.961063174 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "custom-config-volume" (UniqueName: "kubernetes.io/configmap/48d320be-4c5e-4b15-8133-857f02e070dd-custom-config-volume") pod "coredns-ff8999cc5-bp2kh" (UID: "48d320be-4c5e-4b15-8133-857f02e070dd") : failed to sync configmap cache: timed out waiting for the condition
2025-01-29 17:05:03,594 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kuberuntime_manager.go:1702] "Updating runtime config through cri with podcidr" CIDR="10.42.0.0/24"
2025-01-29 17:05:03,594 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.42.0.0/24"
2025-01-29 17:05:03,601 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="e992ce4f7863"
2025-01-29 17:05:06,246 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="43.481s"
2025-01-29 17:05:06,275 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="16.308917ms"
2025-01-29 17:05:06,277 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-ff8999cc5" duration="54.861s"
2025-01-29 17:05:06,295 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="15.353624ms"
2025-01-29 17:05:06,299 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/local-path-provisioner-698b58967b" duration="28.683s"
2025-01-29 17:05:06,301 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="47.348s"
2025-01-29 17:05:15,646 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="default/local-hivemq-hivemq-operator-operator" clusterIPs={"IPv4":"10.43.180.98"}
2025-01-29 17:05:15,672 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-hivemq-operator-operator-6b564f6db4" duration="16.744758ms"
2025-01-29 17:05:15,676 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-hivemq-operator-operator-6b564f6db4" duration="4.341779ms"
2025-01-29 17:05:15,677 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-hivemq-operator-operator-6b564f6db4" duration="26.79s"
2025-01-29 17:05:15,690 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-hivemq-operator-operator-6b564f6db4" duration="121.256s"
2025-01-29 17:05:15,751 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"templates\" (UniqueName: \"kubernetes.io/configmap/39cba609-b66c-4fd3-889e-38d2a4a15aaf-templates\") pod \"local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm\" (UID: \"39cba609-b66c-4fd3-889e-38d2a4a15aaf\") " pod="default/local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm"
2025-01-29 17:05:15,752 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-hf6tj\" (UniqueName: \"kubernetes.io/projected/39cba609-b66c-4fd3-889e-38d2a4a15aaf-kube-api-access-hf6tj\") pod \"local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm\" (UID: \"39cba609-b66c-4fd3-889e-38d2a4a15aaf\") " pod="default/local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm"
2025-01-29 17:05:15,760 DEBUG c.h.h.t.OperatorHelmChartContainer - Chart 'local-hivemq' installed or upgraded
2025-01-29 17:05:18,266 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-hivemq-operator-operator-6b564f6db4" duration="6.671809ms"
2025-01-29 17:05:18,267 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-hivemq-operator-operator-6b564f6db4" duration="32.831s"
2025-01-29 17:05:23,259 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="14.436111ms"
2025-01-29 17:05:23,262 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-8584b5786c" duration="41.998s"
2025-01-29 17:05:23,788 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="e992ce4f7863"
2025-01-29 17:05:24,878 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="default/hivemq-local-hivemq-cc" clusterIPs={"IPv4":"10.43.91.114"}
2025-01-29 17:05:24,964 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [alloc.go:330] "allocated clusterIPs" service="default/hivemq-local-hivemq-mqtt" clusterIPs={"IPv4":"10.43.151.32"}
2025-01-29 17:05:24,968 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-local-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="EnsuringLoadBalancer" message="Ensuring load balancer"
2025-01-29 17:05:24,985 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-local-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="AppliedDaemonSet" message="Applied LoadBalancer DaemonSet kube-system/svclb-hivemq-local-hivemq-mqtt-92e61add"
2025-01-29 17:05:27,281 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-local-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="UpdatedLoadBalancer" message="Updated LoadBalancer with new IPs: [] -> [172.17.0.3]"
2025-01-29 17:05:27,391 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Pending and waiting for Running
2025-01-29 17:05:27,579 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Pending and waiting for Running
2025-01-29 17:05:28,684 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Pending and waiting for Running
2025-01-29 17:05:28,987 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Pending and waiting for Running
2025-01-29 17:05:29,370 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:05:29,811 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="34.127037ms"
2025-01-29 17:05:29,851 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="39.568392ms"
2025-01-29 17:05:29,902 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:05:29,912 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="53.754648ms"
2025-01-29 17:05:29,912 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="106.026s"
2025-01-29 17:05:29,927 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"dns-wait-config\" (UniqueName: \"kubernetes.io/configmap/fda69973-7c0a-46fb-b9e7-a9c51a187665-dns-wait-config\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:29,928 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"live-info\" (UniqueName: \"kubernetes.io/configmap/fda69973-7c0a-46fb-b9e7-a9c51a187665-live-info\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:29,928 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"data\" (UniqueName: \"kubernetes.io/empty-dir/fda69973-7c0a-46fb-b9e7-a9c51a187665-data\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:29,928 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"log\" (UniqueName: \"kubernetes.io/empty-dir/fda69973-7c0a-46fb-b9e7-a9c51a187665-log\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:29,928 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"heap-dumps\" (UniqueName: \"kubernetes.io/empty-dir/fda69973-7c0a-46fb-b9e7-a9c51a187665-heap-dumps\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:29,928 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"shared-data\" (UniqueName: \"kubernetes.io/empty-dir/fda69973-7c0a-46fb-b9e7-a9c51a187665-shared-data\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:29,928 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"backup\" (UniqueName: \"kubernetes.io/empty-dir/fda69973-7c0a-46fb-b9e7-a9c51a187665-backup\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:29,928 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"conf-override\" (UniqueName: \"kubernetes.io/empty-dir/fda69973-7c0a-46fb-b9e7-a9c51a187665-conf-override\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:29,928 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"audit\" (UniqueName: \"kubernetes.io/empty-dir/fda69973-7c0a-46fb-b9e7-a9c51a187665-audit\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:29,928 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-x4b7t\" (UniqueName: \"kubernetes.io/projected/fda69973-7c0a-46fb-b9e7-a9c51a187665-kube-api-access-x4b7t\") pod \"local-hivemq-6f4d548d79-cp8pw\" (UID: \"fda69973-7c0a-46fb-b9e7-a9c51a187665\") " pod="default/local-hivemq-6f4d548d79-cp8pw"
2025-01-29 17:05:30,175 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:05:30,272 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:05:30,591 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="40.755s"
2025-01-29 17:05:30,693 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:05:32,301 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="57.577s"
2025-01-29 17:05:32,317 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-local-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="UpdatedLoadBalancer" message="Updated LoadBalancer with new IPs: [172.17.0.3] -> [172.17.0.3]"
2025-01-29 17:05:33,297 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="47.648s"
2025-01-29 17:05:34,294 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="47.448s"
2025-01-29 17:05:44,310 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="81.06s"
2025-01-29 17:05:45,311 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="55.553s"
2025-01-29 17:05:54,353 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [range_allocator.go:247] "Successfully synced" key="e992ce4f7863"
2025-01-29 17:06:16,349 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="10.063192ms"
2025-01-29 17:06:16,350 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="42.82s"
2025-01-29 17:06:16,350 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [event.go:389] "Event occurred" object="default/hivemq-local-hivemq-mqtt" fieldPath="" kind="Service" apiVersion="v1" type="Normal" reason="UpdatedLoadBalancer" message="Updated LoadBalancer with new IPs: [172.17.0.3] -> [172.17.0.3]"
2025-01-29 17:06:46,355 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="6.347295ms"
2025-01-29 17:06:46,355 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [replica_set.go:679] "Finished syncing" kind="ReplicaSet" key="default/local-hivemq-6f4d548d79" duration="53.059s"
2025-01-29 17:06:46,388 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:06:46,684 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:06:46,781 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:06:46,875 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http2: stream closed"
2025-01-29 17:06:46,875 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [wrap.go:53] "Timeout or abort while handling" method="PATCH" URI="/apis/hivemq.com/v1/namespaces/default/hivemq-clusters/local-hivemq/status" auditID="f4fb395e-176f-4e98-8e1e-964c7c43079d"
2025-01-29 17:06:46,876 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:06:46,877 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http2: stream closed\"}: http2: stream closed"
2025-01-29 17:06:46,877 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout"
2025-01-29 17:06:46,878 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] [timeout.go:140] "Post-timeout activity" timeElapsed="3.914625ms" method="PATCH" path="/apis/hivemq.com/v1/namespaces/default/hivemq-clusters/local-hivemq/status" result=null
2025-01-29 17:06:46,974 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:06:47,075 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:06:47,093 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Updating and waiting for Running
2025-01-29 17:06:47,279 DEBUG com.hivemq.helmcharts.util.K8sUtil - State to compare Running and waiting for Running
2025-01-29 17:06:47,379 INFO t.localhost/testcontainers/z6wwrsag35yrdxlc:latest - Container localhost/testcontainers/z6wwrsag35yrdxlc:latest started in PT1M57.196147991S
2025-01-29 17:06:47,448 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Starting] Starting kubelet. [null:e992ce4f7863]
2025-01-29 17:06:47,449 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Warning [InvalidDiskCapacity] invalid capacity 0 on image filesystem [null:e992ce4f7863]
2025-01-29 17:06:47,450 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeHasSufficientMemory] Node e992ce4f7863 status is now: NodeHasSufficientMemory [null:e992ce4f7863]
2025-01-29 17:06:47,450 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeHasNoDiskPressure] Node e992ce4f7863 status is now: NodeHasNoDiskPressure [null:e992ce4f7863]
2025-01-29 17:06:47,451 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeHasSufficientPID] Node e992ce4f7863 status is now: NodeHasSufficientPID [null:e992ce4f7863]
2025-01-29 17:06:47,451 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeAllocatableEnforced] Updated Node Allocatable limit across pods [null:e992ce4f7863]
2025-01-29 17:06:47,451 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodeReady] Node e992ce4f7863 status is now: NodeReady [null:e992ce4f7863]
2025-01-29 17:06:47,451 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [NodePasswordValidationComplete] Deferred node password secret validation complete [null:e992ce4f7863]
2025-01-29 17:06:47,452 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Synced] Node synced successfully [null:e992ce4f7863]
2025-01-29 17:06:47,454 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [RegisteredNode] Node e992ce4f7863 event: Registered Node e992ce4f7863 in Controller [null:e992ce4f7863]
2025-01-29 17:06:47,454 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [EnsuringLoadBalancer] Ensuring load balancer [default:hivemq-local-hivemq-mqtt]
2025-01-29 17:06:47,454 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [AppliedDaemonSet] Applied LoadBalancer DaemonSet kube-system/svclb-hivemq-local-hivemq-mqtt-92e61add [default:hivemq-local-hivemq-mqtt]
2025-01-29 17:06:47,454 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [UpdatedLoadBalancer] Updated LoadBalancer with new IPs: [] -> [172.17.0.3] [default:hivemq-local-hivemq-mqtt]
2025-01-29 17:06:47,454 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [UpdatedLoadBalancer] Updated LoadBalancer with new IPs: [172.17.0.3] -> [172.17.0.3] [default:hivemq-local-hivemq-mqtt]
2025-01-29 17:06:47,456 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned default/local-hivemq-6f4d548d79-cp8pw to e992ce4f7863 [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,456 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulling] Pulling image "busybox:latest" [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,456 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulled] Successfully pulled image "busybox:latest" in 1.915s (1.915s including waiting). Image size: 2167089 bytes. [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,457 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Created] Created container: init-shared [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,457 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Started] Started container init-shared [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,457 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulled] Container image "hivemq/init-dns-wait:snapshot" already present on machine [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,457 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Created] Created container: dns-wait [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,457 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Started] Started container dns-wait [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,457 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulled] Container image "hivemq/hivemq4:k8s-4.36.0" already present on machine [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,457 INFO c.h.h.t.OperatorHelmChartContainer - Received Pulled event for container hivemq in pod local-hivemq-6f4d548d79-cp8pw [fda69973-7c0a-46fb-b9e7-a9c51a187665]
2025-01-29 17:06:47,460 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Created] Created container: hivemq [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,460 INFO c.h.h.t.OperatorHelmChartContainer - Received Created event for container hivemq in pod local-hivemq-6f4d548d79-cp8pw [fda69973-7c0a-46fb-b9e7-a9c51a187665]
2025-01-29 17:06:47,491 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Started] Started container hivemq [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,491 INFO c.h.h.t.OperatorHelmChartContainer - Received Started event for container hivemq in pod local-hivemq-6f4d548d79-cp8pw [fda69973-7c0a-46fb-b9e7-a9c51a187665]
2025-01-29 17:06:47,494 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Warning [Unhealthy] Readiness probe failed: Log statement not present (yet)
 [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,494 INFO c.h.h.t.OperatorHelmChartContainer - Received Unhealthy event for container hivemq in pod local-hivemq-6f4d548d79-cp8pw [fda69973-7c0a-46fb-b9e7-a9c51a187665]
2025-01-29 17:06:47,494 INFO c.h.h.t.OperatorHelmChartContainer - Started log watcher for hivemq in pod local-hivemq-6f4d548d79-cp8pw [fda69973-7c0a-46fb-b9e7-a9c51a187665]
2025-01-29 17:06:47,494 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Warning [Unhealthy] Liveness probe failed: dial tcp 10.42.0.7:1883: connect: connection refused [default:local-hivemq-6f4d548d79-cp8pw]
2025-01-29 17:06:47,495 INFO c.h.h.t.OperatorHelmChartContainer - Received Unhealthy event for container hivemq in pod local-hivemq-6f4d548d79-cp8pw [fda69973-7c0a-46fb-b9e7-a9c51a187665]
2025-01-29 17:06:47,497 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: local-hivemq-6f4d548d79-cp8pw [default:local-hivemq-6f4d548d79]
2025-01-29 17:06:47,497 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Scheduled] Successfully assigned default/local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm to e992ce4f7863 [default:local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm]
2025-01-29 17:06:47,497 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Pulled] Container image "hivemq/hivemq-operator:snapshot" already present on machine [default:local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm]
2025-01-29 17:06:47,497 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Copying external files
2025-01-29 17:06:47,498 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Rewriting config.xml...
2025-01-29 17:06:47,498 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Creating initial lastUpdate files...
2025-01-29 17:06:47,498 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Disabling Prometheus
2025-01-29 17:06:47,498 INFO c.h.h.t.OperatorHelmChartContainer - Received Pulled event for container operator in pod local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm [39cba609-b66c-4fd3-889e-38d2a4a15aaf]
2025-01-29 17:06:47,498 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Pod info:
2025-01-29 17:06:47,498 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] extension-names=hivemq-kafka-extension hivemq-google-cloud-pubsub-extension hivemq-bridge-extension hivemq-enterprise-security-extension hivemq-distributed-tracing-extension hivemq-amazon-kinesis-extension
2025-01-29 17:06:47,498 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] extension-uris=preinstalled preinstalled preinstalled preinstalled preinstalled preinstalled
2025-01-29 17:06:47,499 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Created] Created container: operator [default:local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm]
2025-01-29 17:06:47,499 INFO c.h.h.t.OperatorHelmChartContainer - Received Created event for container operator in pod local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm [39cba609-b66c-4fd3-889e-38d2a4a15aaf]
2025-01-29 17:06:47,498 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] extension-states=false false false false false false
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] extensions-static=false false false false false false
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Installing extension #0 with name: hivemq-kafka-extension, URI: preinstalled, enabled state: false
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ 3 != 3 ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_URI=preinstalled
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-kafka-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_STATE=false
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-kafka-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] ++ mktemp -d
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + install_dir=/tmp/tmp.eYKOeMuxL7
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set +e
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /opt/hivemq/extensions/hivemq-kafka-extension/DISABLED ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set -e
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ false == \f\a\l\s\e ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + touch /opt/hivemq/extensions/hivemq-kafka-extension/DISABLED
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + /opt/hivemq/bin/run_initialization.sh hivemq-kafka-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-kafka-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-kafka-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + cd /opt/hivemq/extensions/hivemq-kafka-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f init_tmp ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /etc/podinfo/init-extension-hivemq-kafka-extension ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Installing extension #1 with name: hivemq-google-cloud-pubsub-extension, URI: preinstalled, enabled state: false
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ 3 != 3 ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_URI=preinstalled
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-google-cloud-pubsub-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_STATE=false
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] ++ mktemp -d
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + install_dir=/tmp/tmp.IRWTJ6pzQ7
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set +e
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension/DISABLED ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set -e
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ false == \f\a\l\s\e ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + touch /opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension/DISABLED
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + /opt/hivemq/bin/run_initialization.sh hivemq-google-cloud-pubsub-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-google-cloud-pubsub-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + cd /opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f init_tmp ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /etc/podinfo/init-extension-hivemq-google-cloud-pubsub-extension ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Installing extension #2 with name: hivemq-bridge-extension, URI: preinstalled, enabled state: false
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ 3 != 3 ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_URI=preinstalled
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-bridge-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_STATE=false
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-bridge-extension
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] ++ mktemp -d
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + install_dir=/tmp/tmp.AIAc2x5Chl
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set +e
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /opt/hivemq/extensions/hivemq-bridge-extension/DISABLED ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set -e
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ false == \f\a\l\s\e ]]
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + touch /opt/hivemq/extensions/hivemq-bridge-extension/DISABLED
2025-01-29 17:06:47,502 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + /opt/hivemq/bin/run_initialization.sh hivemq-bridge-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-bridge-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-bridge-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + cd /opt/hivemq/extensions/hivemq-bridge-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f init_tmp ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /etc/podinfo/init-extension-hivemq-bridge-extension ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Installing extension #3 with name: hivemq-enterprise-security-extension, URI: preinstalled, enabled state: false
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ 3 != 3 ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_URI=preinstalled
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-enterprise-security-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_STATE=false
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-enterprise-security-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] ++ mktemp -d
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + install_dir=/tmp/tmp.lvGQAZv8gg
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set +e
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /opt/hivemq/extensions/hivemq-enterprise-security-extension/DISABLED ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set -e
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ false == \f\a\l\s\e ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + touch /opt/hivemq/extensions/hivemq-enterprise-security-extension/DISABLED
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + /opt/hivemq/bin/run_initialization.sh hivemq-enterprise-security-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-enterprise-security-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-enterprise-security-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + cd /opt/hivemq/extensions/hivemq-enterprise-security-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f init_tmp ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /etc/podinfo/init-extension-hivemq-enterprise-security-extension ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + echo 'Using init script from config map'
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Using init script from config map
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + cat /etc/podinfo/init-extension-hivemq-enterprise-security-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + echo 'Executing initialization script'
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + chmod +x init
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Executing initialization script
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + ./init
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]                                  Dload  Upload   Total   Spent    Left  Speed
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 100  910k  100  910k    0     0  1497k      0 --:--:-- --:--:-- --:--:-- 1498k
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Installing extension #4 with name: hivemq-distributed-tracing-extension, URI: preinstalled, enabled state: false
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ 3 != 3 ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_URI=preinstalled
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-distributed-tracing-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_STATE=false
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-distributed-tracing-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] ++ mktemp -d
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + install_dir=/tmp/tmp.iri5GhRP22
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set +e
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /opt/hivemq/extensions/hivemq-distributed-tracing-extension/DISABLED ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set -e
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ false == \f\a\l\s\e ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + touch /opt/hivemq/extensions/hivemq-distributed-tracing-extension/DISABLED
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + /opt/hivemq/bin/run_initialization.sh hivemq-distributed-tracing-extension
2025-01-29 17:06:47,503 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-distributed-tracing-extension
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-distributed-tracing-extension
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + cd /opt/hivemq/extensions/hivemq-distributed-tracing-extension
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f init_tmp ]]
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /etc/podinfo/init-extension-hivemq-distributed-tracing-extension ]]
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] Installing extension #5 with name: hivemq-amazon-kinesis-extension, URI: preinstalled, enabled state: false
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ 3 != 3 ]]
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_URI=preinstalled
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-amazon-kinesis-extension
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_STATE=false
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-amazon-kinesis-extension
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] ++ mktemp -d
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + install_dir=/tmp/tmp.6sVJydl6c5
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set +e
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /opt/hivemq/extensions/hivemq-amazon-kinesis-extension/DISABLED ]]
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + set -e
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ false == \f\a\l\s\e ]]
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + touch /opt/hivemq/extensions/hivemq-amazon-kinesis-extension/DISABLED
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + was_enabled=0
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ preinstalled != \p\r\e\i\n\s\t\a\l\l\e\d ]]
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + /opt/hivemq/bin/run_initialization.sh hivemq-amazon-kinesis-extension
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + EXTENSION_NAME=hivemq-amazon-kinesis-extension
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + TARGET_DIR=/opt/hivemq/extensions/hivemq-amazon-kinesis-extension
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + cd /opt/hivemq/extensions/hivemq-amazon-kinesis-extension
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f init_tmp ]]
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] + [[ -f /etc/podinfo/init-extension-hivemq-amazon-kinesis-extension ]]
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] -------------------------------------------------------------------------
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]                   _    _  _              __  __   ____
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]                  | |  | |(_)            |  \/  | / __ \
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]                  | |__| | _ __   __ ___ | \  / || |  | |
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]                  |  __  || |\ \ / // _ \| |\/| || |  | |
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]                  | |  | || | \ V /|  __/| |  | || |__| |
2025-01-29 17:06:47,504 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]                  |_|  |_||_|  \_/  \___||_|  |_| \___\_\
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] -------------------------------------------------------------------------
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]   HiveMQ Start Script for Linux/Unix v1.14
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] -------------------------------------------------------------------------
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]   HIVEMQ_HOME: /opt/hivemq
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]   JAVA_OPTS: -XX:+UnlockExperimentalVMOptions -XX:InitialRAMPercentage=40 -XX:MaxRAMPercentage=50 -XX:MinRAMPercentage=30 -Djava.net.preferIPv4Stack=true --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.nio=ALL-UNNAMED --add-opens java.base/sun.nio.ch=ALL-UNNAMED --add-opens jdk.management/com.sun.management.internal=ALL-UNNAMED --add-exports java.base/jdk.internal.misc=ALL-UNNAMED -Djava.security.egd=file:/dev/./urandom -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9010 -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Duser.language=en -Duser.region=US -XX:+CrashOnOutOfMemoryError -XX:+HeapDumpOnOutOfMemoryError
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973]   JAVA_VERSION: 21
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] -------------------------------------------------------------------------
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] 
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Starting HiveMQ Enterprise Server
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - HiveMQ version: 4.36.0
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - HiveMQ home directory: /opt/hivemq
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Log Configuration was overridden by /opt/hivemq/conf/logback.xml
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Adding TCP Listener on bind address 0.0.0.0 and port 1883. Name: tcp-listener-1883. Proxy Protocol supported: false
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting retained messages enabled to true
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting wildcard subscriptions enabled to true
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting subscription identifier enabled to true
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting shared subscriptions enabled to true
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting maximum qos to EXACTLY_ONCE 
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting topic alias enabled to true
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting topic alias maximum per client to 5
2025-01-29 17:06:47,505 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting the number of max queued messages  per client to 1000 entries
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting queued messages strategy for each client to DISCARD
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting the expiry interval for client sessions to 4294967295 seconds
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting the expiry interval for publish messages to 4294967296 seconds
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting the server receive maximum to 10
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting keep alive maximum to 65535 seconds
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting keep alive allow zero to true
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting the maximum packet size for mqtt messages 268435460 bytes
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting global maximum allowed connections to -1
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting the maximum client id length to 65535
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting the timeout for disconnecting idle tcp connections before a connect message was received to 10000 milliseconds
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Throttling the global incoming traffic limit 0 bytes/second
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting the maximum topic length to 65535
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting allow server assigned client identifier to true
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting validate UTF-8 to true
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting payload format validation to false
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting allow-problem-information to true
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting control-center audit log enabled to true
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting rest-api audit log enabled to true
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting HiveMQ Control Center enabled to true 
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting HiveMQ Control Center default login enabled to true 
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting HiveMQ Control Center session idle time to 14400 seconds
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Adding Http-Listener to HiveMQ Control Center Config
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Set TLS to disabled for cluster TCP transport
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting replica count to 2 
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting cluster TCP health-check enabled
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting cluster TCP health-check bind-address to 10.42.0.7
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting cluster TCP health-check bind-address to 9000
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting cluster TCP health-check bind-port to 9000
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting cluster TCP health-check external-address to default
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting cluster TCP health-check external-port to 0
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting cluster heartbeat enabled
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting cluster heartbeat interval to 4000 ms
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting the cluster heartbeat timeout to 30000 ms
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting HiveMQ REST API enabled to false 
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting HiveMQ REST API authentication enabled to false 
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting HiveMQ Health API enabled to false 
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting client event history enabled to false
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting client event history lifetime to 604800000 ms
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting overload protection enabled to true 
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting anonymous usage statistics enabled to false 
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting expired messages topic enabled to false
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting dropped messages topic enabled to false
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Setting dead messages topic enabled to false
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Successfully loaded configuration from '/opt/hivemq/conf/config.xml'.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Performing sanity checks.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Soft limit for open files (1048576) satisfies the recommended limit (1000000).
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Hard limit for open files (1048576) satisfies the recommended limit (1000000).
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - HiveMQ license directory (/opt/hivemq/license) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - HiveMQ data directory (/opt/hivemq/data) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - HiveMQ log directory (/opt/hivemq/log) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - HiveMQ backup directory (/opt/hivemq/backup) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - HiveMQ audit directory (/opt/hivemq/audit) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - HiveMQ extensions directory (/opt/hivemq/extensions) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-allow-all-extension (/opt/hivemq/extensions/hivemq-allow-all-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-google-cloud-pubsub-extension (/opt/hivemq/extensions/hivemq-google-cloud-pubsub-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-enterprise-security-extension (/opt/hivemq/extensions/hivemq-enterprise-security-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-bridge-extension (/opt/hivemq/extensions/hivemq-bridge-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-kafka-extension (/opt/hivemq/extensions/hivemq-kafka-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-distributed-tracing-extension (/opt/hivemq/extensions/hivemq-distributed-tracing-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-prometheus-extension (/opt/hivemq/extensions/hivemq-prometheus-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-amazon-kinesis-extension (/opt/hivemq/extensions/hivemq-amazon-kinesis-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-k8s-sync-extension (/opt/hivemq/extensions/hivemq-k8s-sync-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-dns-cluster-discovery (/opt/hivemq/extensions/hivemq-dns-cluster-discovery) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-snowflake-extension (/opt/hivemq/extensions/hivemq-snowflake-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-postgresql-extension (/opt/hivemq/extensions/hivemq-postgresql-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-mysql-extension (/opt/hivemq/extensions/hivemq-mysql-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-mongodb-extension (/opt/hivemq/extensions/hivemq-mongodb-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,507 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-data-lake-extension (/opt/hivemq/extensions/hivemq-data-lake-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Extension directory hivemq-microsoft-sql-server-extension (/opt/hivemq/extensions/hivemq-microsoft-sql-server-extension) satisfies all required file-system permissions.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Temporary directory (/tmp) satisfies all required file-system permissions.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Heap dump directory (/opt/hivemq/dumps) satisfies all required file-system permissions.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Performed all sanity checks in 44ms. All sanity checks passed successfully.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - This node's ID is TMJLw
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Clustering is enabled
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Configured WriteBufferManager with size for memtables 311023370 and for the block cache 466535055
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Starting RocksDBMemoryUsageWatchdog.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - RocksDBMemoryUsageWatchdog is running.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Created folder /opt/hivemq/data
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/publish_payload_store/040500_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/client_queue/042800_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/client_session_store/040100_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/client_session_subscriptions/043200_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/retained_messages/040800_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/attribute/043100_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/incoming_message_flow/043000_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/data_hub_modules/043000_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/data_hub_schemas/042000_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/data_hub_scripts/042300_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Folder /opt/hivemq/data/persistence/data_hub_policies/042000_R does not exist, trying to create it
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Diagnostic mode is disabled
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - No valid license file found. Using trial license, restricted to 25 connections.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Native Epoll is available on this platform
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Set extension executor thread pool size to 1
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Set extension executor thread pool keep-alive to 30 seconds
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - initializing RSA key
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - finished initializing RSA key in 989ms
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Unable to provide size and free metrics for disk /dev/sdb: Could not find the corresponding FileStore (OSHI/Java).
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Unable to provide size and free metrics for disk /dev/sda: Could not find the corresponding FileStore (OSHI/Java).
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Throttling incoming traffic to 0 B/s
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Throttling outgoing traffic to 0 B/s
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - No valid license file for Data Hub found. Using free license, restricted to 1 policy.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Building initial topic tree
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Started JMX Metrics Reporting.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Registered JVM metrics with prefix com.hivemq.jvm.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Registered HiveMQ Health API metrics.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Audit Logger started.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - This node uses '1' CPU cores.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Starting HiveMQ extension system.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Starting extension with id "hivemq-dns-cluster-discovery" at /opt/hivemq/extensions/hivemq-dns-cluster-discovery
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - HiveMQ DNS Cluster Discovery Extension: No DNS server address was set in the configuration file or environment variable.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - HiveMQ DNS Cluster Discovery Extension: No reload interval was set in the configuration file or environment variable. Defaulting to 30.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Extension "DNS Cluster Discovery Extension" version 4.3.3 started successfully.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Starting extension with id "hivemq-k8s-sync-extension" at /opt/hivemq/extensions/hivemq-k8s-sync-extension
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Using TCP cluster transport on address 10.42.0.7 and port 7000
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Using extension cluster discovery
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Could not get configMap modification timestamp for source /hivemq-data/conf/..data, likely no ConfigMap mounted
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Could not get configMap modification timestamp for source /hivemq-data/extensions/..data, likely no ConfigMap mounted
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Could not get configMap modification timestamp for source /hivemq-data/bin/..data, likely no ConfigMap mounted
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Started HiveMQ Kubernetes State Synchronization Extension:1.0.3
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Extension "HiveMQ Kubernetes State Synchronization Extension" version 1.0.3 started successfully.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Starting extension with id "hivemq-allow-all-extension" at /opt/hivemq/extensions/hivemq-allow-all-extension
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] WARN  - 
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] ################################################################################################################
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] # This HiveMQ deployment is not secure! You are lacking Authentication and Authorization.                      #
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] # Right now any MQTT client can connect to the broker with a full set of permissions.                          #
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] # For production usage, add an appropriate security extension and remove the hivemq-allow-all extension.       #
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] # You can download security extensions from the HiveMQ Marketplace (https://www.hivemq.com/extensions/).       #
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] ################################################################################################################
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - Simple authenticator added by extension 'hivemq-allow-all-extension'.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Extension "Allow All Extension" version 1.1.1 started successfully.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - HiveMQ DNS Cluster Discovery Extension: Discovered new address '10.42.0.7'.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - TMJLw: no members discovered after 2220 ms: creating cluster as first member
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Cluster nodes found by discovery: [TMJLw|0] (1) [TMJLw].
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - State of node TMJLw changed to UNKNOWN was null. Current cluster node states: {TMJLw=UNKNOWN}
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] DEBUG - State of node TMJLw set to RUNNING. Current cluster node states: {TMJLw=RUNNING}
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] WARN  - No user for HiveMQ Control Center configured. Starting with default user
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Starting HiveMQ Control Center on address 0.0.0.0 and port 8080
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Mounting HiveMQ Control Center V2 Preview
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Started HiveMQ Control Center in 1361ms
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Starting TCP listener on address 0.0.0.0 and port 1883
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Started TCP Listener on address 0.0.0.0 and on port 1883.
2025-01-29 17:06:47,508 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-6f4d548d79] [hivemq] [fda69973] INFO  - Started HiveMQ in 25005ms
2025-01-29 17:06:47,513 INFO c.h.h.t.OperatorHelmChartContainer - [POD] local-hivemq-6f4d548d79-cp8pw [fda69973-7c0a-46fb-b9e7-a9c51a187665] in default was ADDED
2025-01-29 17:06:47,513 INFO c.h.h.t.OperatorHelmChartContainer - [POD] local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm [39cba609-b66c-4fd3-889e-38d2a4a15aaf] in default was ADDED
2025-01-29 17:06:47,515 INFO c.h.h.t.OperatorHelmChartContainer - [POD] coredns-ff8999cc5-bp2kh [48d320be-4c5e-4b15-8133-857f02e070dd] in kube-system was ADDED
2025-01-29 17:06:47,516 INFO c.h.h.t.OperatorHelmChartContainer - [POD] local-path-provisioner-698b58967b-5nfw9 [42b63ef1-74d7-4a7e-acdc-750819f6bbfd] in kube-system was ADDED
2025-01-29 17:06:47,516 INFO c.h.h.t.OperatorHelmChartContainer - [POD] metrics-server-8584b5786c-4tb6m [ea1b6d19-b228-449b-843b-eff01af40bc7] in kube-system was ADDED
2025-01-29 17:06:47,521 INFO c.h.h.t.OperatorHelmChartContainer - [POD] svclb-hivemq-local-hivemq-mqtt-92e61add-27k59 [9b68f8e5-d7b6-42bb-b40e-f8166f1c499a] in kube-system was ADDED
2025-01-29 17:06:47,528 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [Started] Started container operator [default:local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm]
2025-01-29 17:06:47,528 INFO c.h.h.t.OperatorHelmChartContainer - Received Started event for container operator in pod local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm [39cba609-b66c-4fd3-889e-38d2a4a15aaf]
2025-01-29 17:06:47,528 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [SuccessfulCreate] Created pod: local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm [default:local-hivemq-hivemq-operator-operator-6b564f6db4]
2025-01-29 17:06:47,528 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [ScalingReplicaSet] Scaled up replica set local-hivemq-hivemq-operator-operator-6b564f6db4 from 0 to 1 [default:local-hivemq-hivemq-operator-operator]
2025-01-29 17:06:47,528 INFO c.h.h.t.OperatorHelmChartContainer - Started log watcher for operator in pod local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm [39cba609-b66c-4fd3-889e-38d2a4a15aaf]
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] Picked up JAVA_TOOL_OPTIONS: -XX:+UnlockExperimentalVMOptions -XX:InitialRAMPercentage=75 -XX:MaxRAMPercentage=75
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609]  __  __ _                                  _   
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] |  \/  (_) ___ _ __ ___  _ __   __ _ _   _| |_ 
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] | |\/| | |/ __| '__/ _ \| '_ \ / _` | | | | __|
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] | |  | | | (__| | | (_) | | | | (_| | |_| | |_ 
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] |_|  |_|_|\___|_|  \___/|_| |_|\__,_|\__,_|\__|
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609]   Micronaut (v3.5.2)
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] 
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:05:21.263?[0;39m ?[1;30m[main]?[0;39m ?[34mINFO ?[0;39m ?[35mio.micronaut.runtime.Micronaut?[0;39m - Startup completed in 2185ms. Server Running: http://local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm:8443
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:05:22.268?[0;39m ?[1;30m[main]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Initializing HiveMQ operator
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:05:23.371?[0;39m ?[1;30m[main]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Operating from namespace 'default'
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:05:23.558?[0;39m ?[1;30m[pool-3-thread-1]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.AbstractWatcher?[0;39m - CustomResource watcher running for kinds HiveMQCluster
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:05:24.224?[0;39m ?[1;30m[main]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Operator started in 1956ms
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:05:24.570?[0;39m ?[1;30m[pool-3-thread-2]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Syncing state for cluster 'local-hivemq' in namespace 'default'
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:05:28.873?[0;39m ?[1;30m[pool-3-thread-7]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - Syncing state for cluster 'local-hivemq' in namespace 'default'
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:05:29.772?[0;39m ?[1;30m[pool-3-thread-2]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.util.DeploymentUtil?[0;39m - Waiting for deployment local-hivemq to roll out...
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:05:30.658?[0;39m ?[1;30m[pool-3-thread-7]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.util.DeploymentUtil?[0;39m - Waiting for deployment local-hivemq to roll out...
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:06:47.276?[0;39m ?[1;30m[pool-3-thread-2]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - State synchronization complete for cluster 'local-hivemq' in namespace 'default' in 82706ms
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [local-hivemq-hivemq-operator] [operator] [39cba609] ?[36m17:06:47.374?[0;39m ?[1;30m[pool-3-thread-7]?[0;39m ?[34mINFO ?[0;39m ?[35mcom.hivemq.Operator?[0;39m - State synchronization complete for cluster 'local-hivemq' in namespace 'default' in 78501ms
2025-01-29 17:06:47,529 INFO c.h.h.t.OperatorHelmChartContainer - [EVENT] Normal [ScalingReplicaSet] Scaled up replica set local-hivemq-6f4d548d79 from 0 to 1 [default:local-hivemq]
2025-01-29 17:06:48,198 INFO c.h.h.t.OperatorHelmChartContainer - Stopped log watcher for hivemq in pod local-hivemq-6f4d548d79-cp8pw [fda69973-7c0a-46fb-b9e7-a9c51a187665]
2025-01-29 17:06:48,198 INFO c.h.h.t.OperatorHelmChartContainer - Stopped log watcher for operator in pod local-hivemq-hivemq-operator-operator-6b564f6db4-rd2bm [39cba609-b66c-4fd3-889e-38d2a4a15aaf]
2025-01-29 17:06:48,374 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 
2025-01-29 17:06:48,374 INFO c.h.h.t.OperatorHelmChartContainer - [K3S] 
]]></system-out>
  </testcase>
  <system-out><![CDATA[2025-01-29 17:04:50,138 INFO o.t.i.builder.ImageFromDockerfile - Pre-emptively checking local images for 'ubuntu:noble-20241118.1@sha256:80dd3c3b9c6cecb9f1667e9290b3bc61b78c2678c02cbdae5f0fea92cc6734ab', referenced via a Dockerfile. If not available, it will be pulled.
2025-01-29 17:04:50,138 INFO o.t.i.builder.ImageFromDockerfile - Pre-emptively checking local images for 'rancher/k3s:v1.32.1-k3s1', referenced via a Dockerfile. If not available, it will be pulled.
2025-01-29 17:04:50,140 INFO o.t.i.builder.ImageFromDockerfile - Transferred 0 bytes to Docker daemon
]]></system-out>
  <system-err><![CDATA[]]></system-err>
</testsuite>
